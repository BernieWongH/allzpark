{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Allzpark Powerful application launcher with reproducible software environments , for visual effects, feature animation and triple-A game productions. Learn more Download Blog Package Based Works on your machine? Allzpark is a package-based launcher, which means that everything related to a project is encapsulated into individual, version controlled and dependency managed \"packages\". Each coming together to form an environment identical across your development machine and anywhere your software is used. # A package definition name = \"blender\" version = \"2.80\" def commands (): global env env[ \"PATH\" ] . append( \"{root}/bin\" ) env[ \"PYTHONPATH\" ] . prepend( \"{root}/python\" ) Establish complex relationships between software, applications and projects with bleeding-rez , the underlying framework powering Allzpark. Dual Representation Allzpark is but a shell. Anything done via the GUI is available via the command-line, using standard Rez commands. powershell bash PS> rez env alita maya -q > PS> echo \"Hello Rez!\" > # Hello Rez! $ rez env alita maya -q > $ echo \"Hello Rez!\" # Hello Rez! Environment Management Preview the environment, prior to launching an application. Make changes interactively as you develop or debug complex dependency chains. Customisation Full theming support with pre-made color palettes to choose from. Interactively edit the underlying CSS and store them as your own. Drag panels around, establish a super-layout with everything visible at once. Allzpark Allzpark is free and open source (LGPL) Let's get this show on the road Learn more Download","title":"Home"},{"location":"about/","text":"This section outlines the rationale behind Allzpark, to help you determine whether or not it is of use to you. Background Allzpark (a.k.a. LaunchApp2) started as a 4-month commission for the Japanese Studio Anima . Time was divided into roughly these parts. Week 0-0 Tour of physical building, infrastructure and crew Week 1-2 Requirements gathering, an evaluation if current system Week 3-4 Evaluation of off-the-shelf options, e.g. Rez Week 5-6 Evaluation of studio, system and personnel resources Week 7-8 Integration and testing of fundamental infrastucture software, Ansible Week 9-10 Research and development of Rez to fit the criteria and initial prototype Week 11-12 Conversion of existing package repository Week 13-14 Implementation of graphical user interface, LaunchApp2 Week 15-16 Refinement of features, including localisation Week 17-18 Final integration and training of staff Journal Allzpark was initially an internal project, never intended to be open sourced. As a result, the first 2 months of development are locked away behind an internal journal for the company (due to disclosure of sensitive information). Luckily, it was around this time that Allzpark got approved for open source and when I was able to start sharing its development publicly, so that you are able to take part in the design decisions made, the why and how. This way, you're able to accurately determine whether a solution to a new problem takes the original requirements into consideration; something all too often lost in software projects. Journal Story time When Hannah - working at a digital production company like Framestore or ILM - arrives at work in the morning, she typically types something like this into her console. go gravity maya What this does is put Hannah in the \"context\" of the gravity project. The subsequent call to maya then launches a given application, in this case Autodesk Maya. But which version? And why does it matter? A closer look To better understand what's happening here, let's take a closer look at what these commands do. Following the command go gravity , a few things happen. The argument gravity is correlated to a project (either on disk or database) The project is associated with metadata, detailing what software and versions are in use maya-2015 arnold-4.12 mgear-2.4 fbake-4.1 fasset-1.14 ... The associated software is loaded into command-line environment At this point, the subsequent command maya unambiguously refers to maya-2015 , which is how Framestore - and virtually every visual effects, feature animation, commercial and games facility - is able to tie a specific version of each set of software to a given project. Why is this important? The answer lies in interoperability . You see, whatever comes out of Hannah's department must interoperate with subsequent departments. Like an assembly line, the pace of the line remains consistent till the end, and every tool depends on the output of whatever came before it. This holds true for individual applications, like Maya or Visual Studio, but also sub-components of applications - plug-ins. Take arnold-4.12 as an example. This particular version needs to interoperate with maya-2015 . 2015 2016 2017 2018 2019 maya |--------------------------| arnold-1 |-------| arnold-2 |-----------| arnold-3 |-----------| arnold-4 |----------| In order to leverage maya-2015 for a given project, your choice of arnold is limited to those that support it, or vice versa. interoperable slice maya |-----------------|------|---| arnold-1 |-------| | | arnold-2 |-----------| | | arnold-3 |------|------| arnold-4 |-|------|---| | | This issue is compounded by the number of libraries and plug-ins you use for a given project. Consider openimageio , qt , ilmbase and other off-the-shelf projects you may want to employ in a given project, and you can start to get some idea of how narrow It is then further compounded by in-house development projects, such as your pipeline . None of this would have been a problem, if you were able to say: We will ever only work on a single project at a time We know which versions to use We don't develop any new software ourselves In which case you could simply install each of these applications and get to work. But more often than not, things change. And in order to facilitate this change, there needs to be a system in place to help manage the combinatorial complexity of applications, software, and projects. Rez Users Here are some of the studios using Rez today, along with some approximate numbers (sources linked). Studio Active People Disk Packages Versions Frequency Source Anima 2019- 100 30 GB 199 2133 5 / day - RodeoFX 2019- 200 223 GB 400 6732 - a Animal Logic 2018- 999 2 TB 1552 44939 20 / day a Mackievision 2019- 500 - Imageworks 2019- 999 - Puppetworks 2019- 200 - ToonBox 2017- f Pixomondo 2019- b Freefolk 2019- b MPC 2019- b Squeeze Studio 2019- c Mikros 2019- c Brunch Studio 2019- d WWFX 2019- e","title":"About"},{"location":"about/#background","text":"Allzpark (a.k.a. LaunchApp2) started as a 4-month commission for the Japanese Studio Anima . Time was divided into roughly these parts. Week 0-0 Tour of physical building, infrastructure and crew Week 1-2 Requirements gathering, an evaluation if current system Week 3-4 Evaluation of off-the-shelf options, e.g. Rez Week 5-6 Evaluation of studio, system and personnel resources Week 7-8 Integration and testing of fundamental infrastucture software, Ansible Week 9-10 Research and development of Rez to fit the criteria and initial prototype Week 11-12 Conversion of existing package repository Week 13-14 Implementation of graphical user interface, LaunchApp2 Week 15-16 Refinement of features, including localisation Week 17-18 Final integration and training of staff","title":"Background"},{"location":"about/#journal","text":"Allzpark was initially an internal project, never intended to be open sourced. As a result, the first 2 months of development are locked away behind an internal journal for the company (due to disclosure of sensitive information). Luckily, it was around this time that Allzpark got approved for open source and when I was able to start sharing its development publicly, so that you are able to take part in the design decisions made, the why and how. This way, you're able to accurately determine whether a solution to a new problem takes the original requirements into consideration; something all too often lost in software projects. Journal","title":"Journal"},{"location":"about/#story-time","text":"When Hannah - working at a digital production company like Framestore or ILM - arrives at work in the morning, she typically types something like this into her console. go gravity maya What this does is put Hannah in the \"context\" of the gravity project. The subsequent call to maya then launches a given application, in this case Autodesk Maya. But which version? And why does it matter?","title":"Story time"},{"location":"about/#a-closer-look","text":"To better understand what's happening here, let's take a closer look at what these commands do. Following the command go gravity , a few things happen. The argument gravity is correlated to a project (either on disk or database) The project is associated with metadata, detailing what software and versions are in use maya-2015 arnold-4.12 mgear-2.4 fbake-4.1 fasset-1.14 ... The associated software is loaded into command-line environment At this point, the subsequent command maya unambiguously refers to maya-2015 , which is how Framestore - and virtually every visual effects, feature animation, commercial and games facility - is able to tie a specific version of each set of software to a given project. Why is this important? The answer lies in interoperability . You see, whatever comes out of Hannah's department must interoperate with subsequent departments. Like an assembly line, the pace of the line remains consistent till the end, and every tool depends on the output of whatever came before it. This holds true for individual applications, like Maya or Visual Studio, but also sub-components of applications - plug-ins. Take arnold-4.12 as an example. This particular version needs to interoperate with maya-2015 . 2015 2016 2017 2018 2019 maya |--------------------------| arnold-1 |-------| arnold-2 |-----------| arnold-3 |-----------| arnold-4 |----------| In order to leverage maya-2015 for a given project, your choice of arnold is limited to those that support it, or vice versa. interoperable slice maya |-----------------|------|---| arnold-1 |-------| | | arnold-2 |-----------| | | arnold-3 |------|------| arnold-4 |-|------|---| | | This issue is compounded by the number of libraries and plug-ins you use for a given project. Consider openimageio , qt , ilmbase and other off-the-shelf projects you may want to employ in a given project, and you can start to get some idea of how narrow It is then further compounded by in-house development projects, such as your pipeline . None of this would have been a problem, if you were able to say: We will ever only work on a single project at a time We know which versions to use We don't develop any new software ourselves In which case you could simply install each of these applications and get to work. But more often than not, things change. And in order to facilitate this change, there needs to be a system in place to help manage the combinatorial complexity of applications, software, and projects.","title":"A closer look"},{"location":"about/#rez-users","text":"Here are some of the studios using Rez today, along with some approximate numbers (sources linked). Studio Active People Disk Packages Versions Frequency Source Anima 2019- 100 30 GB 199 2133 5 / day - RodeoFX 2019- 200 223 GB 400 6732 - a Animal Logic 2018- 999 2 TB 1552 44939 20 / day a Mackievision 2019- 500 - Imageworks 2019- 999 - Puppetworks 2019- 200 - ToonBox 2017- f Pixomondo 2019- b Freefolk 2019- b MPC 2019- b Squeeze Studio 2019- c Mikros 2019- c Brunch Studio 2019- d WWFX 2019- e","title":"Rez Users"},{"location":"examples/","text":"Learn Allzpark by example. This assumes you've already accumulated the knowledge from the guides chapter. Examples This page contains a series of solutions to specific problems. Command Shorthand Use rez env to establish a context, and --command to immediately run a command within that context. rez env --command= \"echo Hello\" Instead of using --command , you can also use -- . rez env -- echo Hello Note that you didn't need quotation marks or an = sign for this to work, and that it's a little easier on the eyes. We use this syntax extensively throughout this guide. External Packages With Rez you can package almost anything, but sometimes there are packages already made for you to benefit from. Install from PyPI Managing external projects is no fun unless you can benefit from what package authors in neighboring ecosystems have been working on. PyPI is such an ecosystem and you can install any package from PyPI as a Rez package using rez-pipz . git clone https://github.com/mottosso/rez-pipz.git cd rez-pipz rez build --install Here's how you use it. rez env pipz -- install six And here's how you install binary packages, specifically for the platform you are on. rez env pipz -- install sqlalchemy To install for a particular version of Python, include it in the initial request. rez env python-2 pipz -- install sqlalchemy See rez-pipz for details. Install from Scoop Scoop is a package manager for Windows. It's akin to Chocolatey , except packages are portable and doesn't require adminstrative access, which makes it a perfect fit for Rez. git clone https://github.com/mottosso/rez-scoopz.git cd rez-scoopz rez build --install Here's how you use it. rez env scoopz -- install python See rez-scoopz for details. Package version and Python Every package containing a payload typically involves two version numbers. Version of the package Version of the payload Preferably, these would always line up, but how can you expose the version of a package to Python? package.py name = \"my_library\" version = \"1.0\" my_library/python/my_library.py version = \"?\" 1. Package to Python What if Python was the one defining a version, and package.py picking this up instead? You certainly can, except it moves complexity away from your library and into your package.py , which is generally not a good idea. package.py Option 1, plain-text name = \"my_library\" with open( \"python\\my_library.py\" ) as f: for line in f: if line . startswith( \"version = \" ): _, version = line . rstrip() . split( \" = \" ) break This works, but makes a few fragile assumptions about how the version is formatted in the file. Option 2. import os name = \"my_library\" cwd = os . getcwd() os . chmod( \"python\" ) import my_library version = my_library . version This is a little ugly, but works. The assumption made is that whatever is being executed in the imported module doesn't have any side effects or negatively impacts performance. Some modules, for example, establish database connections or temporary directories on import. 2. Embedded This next approach addresses the above concerns in a more compact manner. In order to use a package, it must first be built. We can leverage this build step to modify a Python library and embed the package version. my_library/ init .py try : from . import __version__ version = __version__ . version except ImportError : version = \"dev\" At this point, version will read \"dev\" until the module __version__.py has been written into the library. We can write this file during build. package.py name = \"my_library\" version = \"1.0\" build_command = \"python {root}/install.py\" install.py import os import shutil root = os . path . dirname(__file__) build_dir = os . environ[ \"REZ_BUILD_PATH\" ] # Copy library shutil . copytree(os . path . join(root, \"my_library\" ), os . path . join(build_dir, \"my_library\" )) # Inject version version_fname = os . path . join(build_dir, \"my_library\" , \"__version__.py\" ) version = os . getenv( \"REZ_BUILD_PROJECT_VERSION\" ) with open(version_fname, \"w\" ) as f: f . write( \"version = \\\" %s \\\" \" % version) And there you go. Now the version will read \"dev\" unless the package has been built, in which case it would read \"1.0\" .","title":"Examples"},{"location":"examples/#examples","text":"This page contains a series of solutions to specific problems.","title":"Examples"},{"location":"examples/#command-shorthand","text":"Use rez env to establish a context, and --command to immediately run a command within that context. rez env --command= \"echo Hello\" Instead of using --command , you can also use -- . rez env -- echo Hello Note that you didn't need quotation marks or an = sign for this to work, and that it's a little easier on the eyes. We use this syntax extensively throughout this guide.","title":"Command Shorthand"},{"location":"examples/#external-packages","text":"With Rez you can package almost anything, but sometimes there are packages already made for you to benefit from.","title":"External Packages"},{"location":"examples/#install-from-pypi","text":"Managing external projects is no fun unless you can benefit from what package authors in neighboring ecosystems have been working on. PyPI is such an ecosystem and you can install any package from PyPI as a Rez package using rez-pipz . git clone https://github.com/mottosso/rez-pipz.git cd rez-pipz rez build --install Here's how you use it. rez env pipz -- install six And here's how you install binary packages, specifically for the platform you are on. rez env pipz -- install sqlalchemy To install for a particular version of Python, include it in the initial request. rez env python-2 pipz -- install sqlalchemy See rez-pipz for details.","title":"Install from PyPI"},{"location":"examples/#install-from-scoop","text":"Scoop is a package manager for Windows. It's akin to Chocolatey , except packages are portable and doesn't require adminstrative access, which makes it a perfect fit for Rez. git clone https://github.com/mottosso/rez-scoopz.git cd rez-scoopz rez build --install Here's how you use it. rez env scoopz -- install python See rez-scoopz for details.","title":"Install from Scoop"},{"location":"examples/#package-version-and-python","text":"Every package containing a payload typically involves two version numbers. Version of the package Version of the payload Preferably, these would always line up, but how can you expose the version of a package to Python? package.py name = \"my_library\" version = \"1.0\" my_library/python/my_library.py version = \"?\"","title":"Package version and Python"},{"location":"examples/#1-package-to-python","text":"What if Python was the one defining a version, and package.py picking this up instead? You certainly can, except it moves complexity away from your library and into your package.py , which is generally not a good idea. package.py Option 1, plain-text name = \"my_library\" with open( \"python\\my_library.py\" ) as f: for line in f: if line . startswith( \"version = \" ): _, version = line . rstrip() . split( \" = \" ) break This works, but makes a few fragile assumptions about how the version is formatted in the file. Option 2. import os name = \"my_library\" cwd = os . getcwd() os . chmod( \"python\" ) import my_library version = my_library . version This is a little ugly, but works. The assumption made is that whatever is being executed in the imported module doesn't have any side effects or negatively impacts performance. Some modules, for example, establish database connections or temporary directories on import.","title":"1. Package to Python"},{"location":"examples/#2-embedded","text":"This next approach addresses the above concerns in a more compact manner. In order to use a package, it must first be built. We can leverage this build step to modify a Python library and embed the package version. my_library/ init .py try : from . import __version__ version = __version__ . version except ImportError : version = \"dev\" At this point, version will read \"dev\" until the module __version__.py has been written into the library. We can write this file during build. package.py name = \"my_library\" version = \"1.0\" build_command = \"python {root}/install.py\" install.py import os import shutil root = os . path . dirname(__file__) build_dir = os . environ[ \"REZ_BUILD_PATH\" ] # Copy library shutil . copytree(os . path . join(root, \"my_library\" ), os . path . join(build_dir, \"my_library\" )) # Inject version version_fname = os . path . join(build_dir, \"my_library\" , \"__version__.py\" ) version = os . getenv( \"REZ_BUILD_PROJECT_VERSION\" ) with open(version_fname, \"w\" ) as f: f . write( \"version = \\\" %s \\\" \" % version) And there you go. Now the version will read \"dev\" unless the package has been built, in which case it would read \"1.0\" .","title":"2. Embedded"},{"location":"getting-started/","text":"This page carries on from a successful \ud83d\udc48 quickstart into making it relevant to your usecase. What is Allzpark? It's an application launcher , similar to the one on the home screen of your phone or in the Start menu on Windows. The difference is that before actually launching the application, you are able to tailor the associated environment within which the applicatuon runs. For example... Let's say you're working on a project using (1) Autodesk Maya, (2) Adobe Photoshop and (3) Pixologic Zbrush. For Maya, you'd like to use various software libraries, Python scripts and binary plug-ins like Solid Angle's Arnold and Ziva Dynamics. However, each plug-in need to be of a particular version in order to play ball this version of Maya. Over time, the number of projects grow, as do the individual requirements of each application, and many of the plug-ins and libraries end up sharing dependencies with each other. So now you've got a network of interdependencies that all need to work with each other and wonder.. \"How can I write my own software that run in this environment?\" \"How can I make sure my software runs once deployed?\" That's where reproducible enironments come in handy and Allzpark can do for you. Rez - an industry standard used by studios large and small - is the framwork with which you design this network and Allzpark is the shiny front-end your artists uses interface with it. Studios using Rez Studio Anima Animal Logic Sony Imageworks Moving Picture Company Mikros Image And many more What are some similar projects? Have a look at these, they solve a similar problem to Allzpark. Shotgun Launcher ftrack Connect Mango Software Launcher So then, why should you choose Allzpark? Odds are you already have most of what these solutions offer and aren't ready for a complete swap. Allzpark integrates with existing pipelines and works standalone. It'll also work the day you decide to transition from e.g. Shotgun to ftrack, safeguarding your investment in each individual component of your pipeline. Here's how you would typically use Allzpark. Boot machine Boot Allzpark Select profile Boot application For the purposes of this quick walkthrough, I'll assume you are part of a visual effects studio whereby \"profile\" means e.g. Alita and \"application\" means e.g. Blender. What is a \"profile\"? alita is the name given to a profile within which work is performed by multiple stakeholders towards a common goal. It typically consists of these components. Name Version Requirements Environment Applications Whereby an \"application\" is the software used within this profile, such as blender , photoshop and sublimetext . The \"requirements\" indicate what software or libraries your profile depend on, such as python-3 or git-2.21 or arnold-6 . The \"environment\" are hand-crafted variables stored in the launched application. Variables you can later refer back to in the software you write to run within the context of that application. For example, PROJECT_NAME=alita is a relevant variable to add, to allow for the application and your software to identify which profile an application was launched in. As you might have guessed, projects are versioned and we'll get into more about this and \"packages\" in general a little later. What is an \"application\"? blender is an application within which work is performed. In Allzpark, the profile dictates what applications are available to the user, in order to faciliate a \"data pipeline\" being built around a pre-determined set of software and libraries. Data pipeline? A kind of \"codified\" workflow. For example, you use the same settings for whenever you export an image from Photoshop to your game engine. Rather than explicitly setting those each time, you make a script to turn the process into a single click. The same then applies to any kind of export and import of data in various applications, to and from various stakeholders in your company. These are some examples of pre-made \"scripts\" - in the form of frameworks - suitable for use with Allzpark. Avalon Kabaret Piper Mango Pipeline AnimationDNA Tik Manager An application typically consists of these components. Name Version Requirements Environment Notice that it isn't unlike a profile, and in fact not unlike any other software you'll encounter later on. These are both \"packages\" and we'll talk a lot more about what that is as we progress through this guide. What is an \"package\"? I've talked a lot about \"packages\" and how great they are, but what exactly are they and why should you care? Without Rez and without Allzpark, software is typically installed \"system-wide\". That is, your Python install resides somewhere on your system and is automatically added to your system PATH , such that when you type.. python From either Bash or PowerShell, this is the version of Python picked up. A \"package\" is this, except rather than installing, in this case, Python onto your system, and adding it to your system PATH , it is installed into a portable folder which is added to PATH only when referenced. rez env python > python A package can contain both files, environment variables but also arbitrary commands that execute whenever the package is referenced, which is how you distribute both applications like Python and libraries and, in the case of Allzpark, profiles. Your first profile You and I are going to embark on a new profile. Let's call it kingkong Command Line The way we'll establish this profile, and packages like it, is going to involve the command-line, so let's get comfortable with how it works. I'll provide command-line instructions for both powershell and bash , to cover both Windows, Linux and MacOS users. You can follow along using either of the two flavours, but odds are the one pre-selected is the one you'll want to use. powershell bash $env:POWERSHELL= \"These lines are for powershell\" $var = \"If you are on Windows, this is where we'll spend most of our time. It also applies to pwsh, the cross-platform PowerShell 6+.\" echo These lines are for bash echo typically used in MacOS and Linux Now select a shell of your choice and let's get going. JavaScript If you aren't seeing any code, make sure you have JavaScript enabled. If this is a problem for you, let me know . King Kong Each profile requires a folder and a file called package.py . powershell bash mkdir ~/kingkong cd ~/kingkong @\" name = \"kingkong\" version = \"1.0.0\" build_command = False \"@ | Add-Content package.py rez build --install mkdir ~/kingkong cd ~/kingkong echo name = \"kingkong\" >> package.py echo version = \"1.0.0\" >> package.py echo build_command = False >> package.py rez build --install That's it, we've now got a brand new profile. Let's add it to Allzpark and see what it looks like. powershell bash $env:MY_PROFILES= \"kingkong\" allzpark --demo export MY_PROFILES = \"kingkong\" allzpark --demo We'll do a lot more of this as we go along, so don't worry if it doesn't quite make sense just yet. Regarding MY_PROFILES I've programmed this demo to take the environment variable MY_PROFILES into account, but we'll have a look later at how you can customise how projects are actually discovered either from disk, a production tracking system like Shotgun or arbitrary function you provide. What we've learned Let's take a moment to reflect on what we've accomplished so far. We've gotten familiar with the rez command We've authored a new Rez package from scratch We've used rez build , one of many Rez sub-commands, to build and install a package We've made Allzpark aware of this new profile package, via the MY_PROFILES environment variable. Next we'll have a look at how to add an application to your profile, and how to actually make a new application from scratch. Your first application There isn't much we can do with a profile unless we've got an application, so let's add one. Open kingkong/package.py in your favourite text editor Edit it as follows. name = \"kingkong\" version = \"1.0.1\" build_command = False requires = [ \"~maya==2018.0.6\" , \"~blender==2.80.0\" , ] As you may have guessed, these are the requirements of this profile. That little squiggly ~ character ahead of maya indicates that this is a \"weak\" reference, which Allzpark interprets as application in this profile. Protip If you're already familiar with Rez and think to yourself \"This isn't very flexible\", you're right. Looking for applications in the requirements section of a package is a default you can customise later via the allzparkconfig.py:applications_from_package() function. We'll talk more about requirements next, let's install this package and launch Allzpark. cd kingkong rez build --install allzpark --demo Protip You'll notice the order in which you specified the applications are respected in the GUI. An application package Ok, but we didn't really create an application so much as just add an existing one to the profile. Let's create a new application from your OS and add that to the profile too. You can pick any application you'd like, for the purposes of this guide I'll make a package for a text editor. powershell bash mkdir ~/texteditor cd ~/texteditor @\" name = \"texteditor\" version = \"1.5.0\" build_command = False \"@ | Add-Content package.py rez build --install mkdir ~/texteditor cd ~/texteditor echo name = \"texteditor\" >> package.py echo version = \"1.5.0\" >> package.py echo build_command = False >> package.py rez build --install You'll notice the similarity to creating a profile and that's no coincidence. These are both Rez \"packages\". But there's something missing. Unlike a profile, an application must either reference an executable on disk, or encapsulate this executable into the package. We'll get into encapsulating files with a package a little later, for now let's have a look at how to reference a file on disk. texteditor/package.py name = \"texteditor\" version = \"1.5.1\" build_command = False def commands (): import os global alias if os . name == \"nt\" : alias( \"texteditor\" , r\"notepad\" ) elif os . name == \"darwin\" : alias( \"texteditor\" , r\"textedit\" ) else : alias( \"texteditor\" , r\"gedit\" ) The commands() function is called whenever your package is referenced, and alias() creates a command you can use from within a context. We're able to leverage regular Python imports and commands here as well, which is how we detect the running operating system. About assumptions One of the issues with referencing system software like this is, well, how can we be sure these actually exist on the target operating system? For Windows it's a given, but what about Linux? We'll see this problem crop up again later, and is in fact already an issue with the pre-existing demo packages for Maya and Blender. For the purposes of this guide, these assumptions are fine and I'll show you later how you can avoid making them, and at what cost. Let's try this out. cd texteditor rez build --install rez env texteditor --paths $( allzparkdemo --packages ) > texteditor This is the equivalent command-line procedure to what Allzpark is doing when you launch an application. Don't worry too much about what rez env actually does right now, we'll talk a lot more about it later. Let's try this out in Allzpark too. kingkong/package.py name = \"kingkong\" version = \"1.0.2\" build_command = False requires = [ \"~maya==2018.0.6\" , \"~blender==2.80.0\" , \"~texteditor==1.5.1\" , ] cd kingkong rez build --install allzpark --demo And presto! Protip Notice that our terminal doesn't yet have an icon, and its name is all lowercase and plain. We'll address this next, in the Payload chapter. What we've learned You made it! Let's reflect on what we've learned so far. Creating a new application is not unlike creating a new profile Packages have a commands() function you can use to \"bootstrap\" an environment with custom commands There's pros and cons to referencing system software, like a text editor. Your first payload We've managed to make a new profile, and an application and we're just about ready to start developing the next King Kong movie. But there is something else missing. For the purposes of this chapter, I will assume you are developing King Kong using Autodesk Maya, but the same applies to just about any application. Let's start by adding some files to your package. kingkong/ resources/ icon.png I'm going to use this image, but you can use anything you've got lying around, so long as it's a .png file of reasonable size and aspect ratio. Then I'll update our package.py as well. package.py name = \"kingkong\" version = \"1.0.3\" build_command = \"python {root}/install.py\" # 1 _data = { # 2 \"label\" : \"King Kong\" , \"icon\" : \"{root}/resources/icon.png\" , } requires = [ \"python-2.7,<4\" , # 3 \"~maya==2018.0.6\" , \"~blender==2.80.0\" , \"~texteditor==1.5.1\" , ] Let's walk through these changes. We first update out build_command to call on a script, the script we'll use to copy files from your package folder to the build/ folder which is later installed. Next we add _data which isn't related to Rez, but rather arbitrary data provided to a package. You can add any number of variables, but it is good practice to avoid clashing with built-in variables by prefixing it with _ . In this case, Allzpark is programmed to look for this variable to find label and icon . We add python-2.7,<4 to our list of requirements, without ~ this time. Here's what the files look like. install.py # This script is called on `rez build` import os import shutil print ( \"Running install.py...\" ) root = os . path . dirname(__file__) build_dir = os . environ[ \"REZ_BUILD_PATH\" ] install_dir = os . environ[ \"REZ_BUILD_INSTALL_PATH\" ] print ( \"Copying payload to %s..\" % build_dir) shutil . copytree( os . path . join(root, \"resources\" ), os . path . join(build_dir, \"resources\" ), ignore = shutil . ignore_patterns( \"*.pyc\" , \"__pycache__\" ) ) if int(os . getenv( \"REZ_BUILD_INSTALL\" )): # This part is called with `rez build --install` print ( \"Installing payload to %s...\" % install_dir) shutil . copytree( os . path . join(build_dir, \"resources\" ), os . path . join(install_dir, \"resources\" ), ) Now let's try and build our package once more. cd kingkong rez build --install --clean allzpark --demo --clean will erase any existing build/ directory, such that you can build over and over and over. New version Make sure you increment your version each time you install, or implement the appropriate clean-up functionality in your install.py script, as otherwise it may throw an exception about not being able to write into a directory that already has files in it. Generally, it's fine to overwrite packages you install locally; we'll talk about how local differs from a \"release\" a little later, and how you can employ continuous integration and write-protect your public release folder for an additional level of security. What we've learned High five! You've now learnt how to include files with your package, this is what we'll use to distribute software like Python libraries along with profile-specific files like the icon we've seen but also files related to potential applications you use, such as Maya script files or shelves. But what if you wanted to include a Python library and call that from an application? How can the application be made aware of what you've included in your package? This is where the environment comes in, and we'll have a look at that next. Your first environment So your profile has got some custom data, that's perfect. Now let's add some metadata as well. name = \"kingkong\" version = \"1.0.2\" build_command = False requires = [ \"~maya==2018.0.6\" , \"~blender==2.80.0\" , \"~texteditor==1.5.1\" , ] def commands (): global env env[ \"PROJECT_ID\" ] = \"12\" env[ \"PROJECT_NAME\" ] = \"kingkong\" env[ \"PROJECT_FRAMERATE\" ] = \"25\" env[ \"PROJECT_TAGS\" ] = \"awesome,great,best\" In Development Congratulations, you made it this far! I'm still working on this next bit, so stay tuned to this page for updates, or monitor the GitHub repo for changes as that's where these are coming from.","title":"Getting Started"},{"location":"getting-started/#what-is-allzpark","text":"It's an application launcher , similar to the one on the home screen of your phone or in the Start menu on Windows. The difference is that before actually launching the application, you are able to tailor the associated environment within which the applicatuon runs. For example... Let's say you're working on a project using (1) Autodesk Maya, (2) Adobe Photoshop and (3) Pixologic Zbrush. For Maya, you'd like to use various software libraries, Python scripts and binary plug-ins like Solid Angle's Arnold and Ziva Dynamics. However, each plug-in need to be of a particular version in order to play ball this version of Maya. Over time, the number of projects grow, as do the individual requirements of each application, and many of the plug-ins and libraries end up sharing dependencies with each other. So now you've got a network of interdependencies that all need to work with each other and wonder.. \"How can I write my own software that run in this environment?\" \"How can I make sure my software runs once deployed?\" That's where reproducible enironments come in handy and Allzpark can do for you. Rez - an industry standard used by studios large and small - is the framwork with which you design this network and Allzpark is the shiny front-end your artists uses interface with it. Studios using Rez Studio Anima Animal Logic Sony Imageworks Moving Picture Company Mikros Image And many more What are some similar projects? Have a look at these, they solve a similar problem to Allzpark. Shotgun Launcher ftrack Connect Mango Software Launcher So then, why should you choose Allzpark? Odds are you already have most of what these solutions offer and aren't ready for a complete swap. Allzpark integrates with existing pipelines and works standalone. It'll also work the day you decide to transition from e.g. Shotgun to ftrack, safeguarding your investment in each individual component of your pipeline. Here's how you would typically use Allzpark. Boot machine Boot Allzpark Select profile Boot application For the purposes of this quick walkthrough, I'll assume you are part of a visual effects studio whereby \"profile\" means e.g. Alita and \"application\" means e.g. Blender.","title":"What is Allzpark?"},{"location":"getting-started/#what-is-a-profile","text":"alita is the name given to a profile within which work is performed by multiple stakeholders towards a common goal. It typically consists of these components. Name Version Requirements Environment Applications Whereby an \"application\" is the software used within this profile, such as blender , photoshop and sublimetext . The \"requirements\" indicate what software or libraries your profile depend on, such as python-3 or git-2.21 or arnold-6 . The \"environment\" are hand-crafted variables stored in the launched application. Variables you can later refer back to in the software you write to run within the context of that application. For example, PROJECT_NAME=alita is a relevant variable to add, to allow for the application and your software to identify which profile an application was launched in. As you might have guessed, projects are versioned and we'll get into more about this and \"packages\" in general a little later.","title":"What is a \"profile\"?"},{"location":"getting-started/#what-is-an-application","text":"blender is an application within which work is performed. In Allzpark, the profile dictates what applications are available to the user, in order to faciliate a \"data pipeline\" being built around a pre-determined set of software and libraries. Data pipeline? A kind of \"codified\" workflow. For example, you use the same settings for whenever you export an image from Photoshop to your game engine. Rather than explicitly setting those each time, you make a script to turn the process into a single click. The same then applies to any kind of export and import of data in various applications, to and from various stakeholders in your company. These are some examples of pre-made \"scripts\" - in the form of frameworks - suitable for use with Allzpark. Avalon Kabaret Piper Mango Pipeline AnimationDNA Tik Manager An application typically consists of these components. Name Version Requirements Environment Notice that it isn't unlike a profile, and in fact not unlike any other software you'll encounter later on. These are both \"packages\" and we'll talk a lot more about what that is as we progress through this guide.","title":"What is an \"application\"?"},{"location":"getting-started/#what-is-an-package","text":"I've talked a lot about \"packages\" and how great they are, but what exactly are they and why should you care? Without Rez and without Allzpark, software is typically installed \"system-wide\". That is, your Python install resides somewhere on your system and is automatically added to your system PATH , such that when you type.. python From either Bash or PowerShell, this is the version of Python picked up. A \"package\" is this, except rather than installing, in this case, Python onto your system, and adding it to your system PATH , it is installed into a portable folder which is added to PATH only when referenced. rez env python > python A package can contain both files, environment variables but also arbitrary commands that execute whenever the package is referenced, which is how you distribute both applications like Python and libraries and, in the case of Allzpark, profiles.","title":"What is an \"package\"?"},{"location":"getting-started/#your-first-profile","text":"You and I are going to embark on a new profile. Let's call it kingkong","title":"Your first profile"},{"location":"getting-started/#command-line","text":"The way we'll establish this profile, and packages like it, is going to involve the command-line, so let's get comfortable with how it works. I'll provide command-line instructions for both powershell and bash , to cover both Windows, Linux and MacOS users. You can follow along using either of the two flavours, but odds are the one pre-selected is the one you'll want to use. powershell bash $env:POWERSHELL= \"These lines are for powershell\" $var = \"If you are on Windows, this is where we'll spend most of our time. It also applies to pwsh, the cross-platform PowerShell 6+.\" echo These lines are for bash echo typically used in MacOS and Linux Now select a shell of your choice and let's get going. JavaScript If you aren't seeing any code, make sure you have JavaScript enabled. If this is a problem for you, let me know .","title":"Command Line"},{"location":"getting-started/#king-kong","text":"Each profile requires a folder and a file called package.py . powershell bash mkdir ~/kingkong cd ~/kingkong @\" name = \"kingkong\" version = \"1.0.0\" build_command = False \"@ | Add-Content package.py rez build --install mkdir ~/kingkong cd ~/kingkong echo name = \"kingkong\" >> package.py echo version = \"1.0.0\" >> package.py echo build_command = False >> package.py rez build --install That's it, we've now got a brand new profile. Let's add it to Allzpark and see what it looks like. powershell bash $env:MY_PROFILES= \"kingkong\" allzpark --demo export MY_PROFILES = \"kingkong\" allzpark --demo We'll do a lot more of this as we go along, so don't worry if it doesn't quite make sense just yet. Regarding MY_PROFILES I've programmed this demo to take the environment variable MY_PROFILES into account, but we'll have a look later at how you can customise how projects are actually discovered either from disk, a production tracking system like Shotgun or arbitrary function you provide.","title":"King Kong"},{"location":"getting-started/#what-weve-learned","text":"Let's take a moment to reflect on what we've accomplished so far. We've gotten familiar with the rez command We've authored a new Rez package from scratch We've used rez build , one of many Rez sub-commands, to build and install a package We've made Allzpark aware of this new profile package, via the MY_PROFILES environment variable. Next we'll have a look at how to add an application to your profile, and how to actually make a new application from scratch.","title":"What we've learned"},{"location":"getting-started/#your-first-application","text":"There isn't much we can do with a profile unless we've got an application, so let's add one. Open kingkong/package.py in your favourite text editor Edit it as follows. name = \"kingkong\" version = \"1.0.1\" build_command = False requires = [ \"~maya==2018.0.6\" , \"~blender==2.80.0\" , ] As you may have guessed, these are the requirements of this profile. That little squiggly ~ character ahead of maya indicates that this is a \"weak\" reference, which Allzpark interprets as application in this profile. Protip If you're already familiar with Rez and think to yourself \"This isn't very flexible\", you're right. Looking for applications in the requirements section of a package is a default you can customise later via the allzparkconfig.py:applications_from_package() function. We'll talk more about requirements next, let's install this package and launch Allzpark. cd kingkong rez build --install allzpark --demo Protip You'll notice the order in which you specified the applications are respected in the GUI.","title":"Your first application"},{"location":"getting-started/#an-application-package","text":"Ok, but we didn't really create an application so much as just add an existing one to the profile. Let's create a new application from your OS and add that to the profile too. You can pick any application you'd like, for the purposes of this guide I'll make a package for a text editor. powershell bash mkdir ~/texteditor cd ~/texteditor @\" name = \"texteditor\" version = \"1.5.0\" build_command = False \"@ | Add-Content package.py rez build --install mkdir ~/texteditor cd ~/texteditor echo name = \"texteditor\" >> package.py echo version = \"1.5.0\" >> package.py echo build_command = False >> package.py rez build --install You'll notice the similarity to creating a profile and that's no coincidence. These are both Rez \"packages\". But there's something missing. Unlike a profile, an application must either reference an executable on disk, or encapsulate this executable into the package. We'll get into encapsulating files with a package a little later, for now let's have a look at how to reference a file on disk. texteditor/package.py name = \"texteditor\" version = \"1.5.1\" build_command = False def commands (): import os global alias if os . name == \"nt\" : alias( \"texteditor\" , r\"notepad\" ) elif os . name == \"darwin\" : alias( \"texteditor\" , r\"textedit\" ) else : alias( \"texteditor\" , r\"gedit\" ) The commands() function is called whenever your package is referenced, and alias() creates a command you can use from within a context. We're able to leverage regular Python imports and commands here as well, which is how we detect the running operating system. About assumptions One of the issues with referencing system software like this is, well, how can we be sure these actually exist on the target operating system? For Windows it's a given, but what about Linux? We'll see this problem crop up again later, and is in fact already an issue with the pre-existing demo packages for Maya and Blender. For the purposes of this guide, these assumptions are fine and I'll show you later how you can avoid making them, and at what cost. Let's try this out. cd texteditor rez build --install rez env texteditor --paths $( allzparkdemo --packages ) > texteditor This is the equivalent command-line procedure to what Allzpark is doing when you launch an application. Don't worry too much about what rez env actually does right now, we'll talk a lot more about it later. Let's try this out in Allzpark too. kingkong/package.py name = \"kingkong\" version = \"1.0.2\" build_command = False requires = [ \"~maya==2018.0.6\" , \"~blender==2.80.0\" , \"~texteditor==1.5.1\" , ] cd kingkong rez build --install allzpark --demo And presto! Protip Notice that our terminal doesn't yet have an icon, and its name is all lowercase and plain. We'll address this next, in the Payload chapter.","title":"An application package"},{"location":"getting-started/#what-weve-learned_1","text":"You made it! Let's reflect on what we've learned so far. Creating a new application is not unlike creating a new profile Packages have a commands() function you can use to \"bootstrap\" an environment with custom commands There's pros and cons to referencing system software, like a text editor.","title":"What we've learned"},{"location":"getting-started/#your-first-payload","text":"We've managed to make a new profile, and an application and we're just about ready to start developing the next King Kong movie. But there is something else missing. For the purposes of this chapter, I will assume you are developing King Kong using Autodesk Maya, but the same applies to just about any application. Let's start by adding some files to your package. kingkong/ resources/ icon.png I'm going to use this image, but you can use anything you've got lying around, so long as it's a .png file of reasonable size and aspect ratio. Then I'll update our package.py as well. package.py name = \"kingkong\" version = \"1.0.3\" build_command = \"python {root}/install.py\" # 1 _data = { # 2 \"label\" : \"King Kong\" , \"icon\" : \"{root}/resources/icon.png\" , } requires = [ \"python-2.7,<4\" , # 3 \"~maya==2018.0.6\" , \"~blender==2.80.0\" , \"~texteditor==1.5.1\" , ] Let's walk through these changes. We first update out build_command to call on a script, the script we'll use to copy files from your package folder to the build/ folder which is later installed. Next we add _data which isn't related to Rez, but rather arbitrary data provided to a package. You can add any number of variables, but it is good practice to avoid clashing with built-in variables by prefixing it with _ . In this case, Allzpark is programmed to look for this variable to find label and icon . We add python-2.7,<4 to our list of requirements, without ~ this time. Here's what the files look like. install.py # This script is called on `rez build` import os import shutil print ( \"Running install.py...\" ) root = os . path . dirname(__file__) build_dir = os . environ[ \"REZ_BUILD_PATH\" ] install_dir = os . environ[ \"REZ_BUILD_INSTALL_PATH\" ] print ( \"Copying payload to %s..\" % build_dir) shutil . copytree( os . path . join(root, \"resources\" ), os . path . join(build_dir, \"resources\" ), ignore = shutil . ignore_patterns( \"*.pyc\" , \"__pycache__\" ) ) if int(os . getenv( \"REZ_BUILD_INSTALL\" )): # This part is called with `rez build --install` print ( \"Installing payload to %s...\" % install_dir) shutil . copytree( os . path . join(build_dir, \"resources\" ), os . path . join(install_dir, \"resources\" ), ) Now let's try and build our package once more. cd kingkong rez build --install --clean allzpark --demo --clean will erase any existing build/ directory, such that you can build over and over and over. New version Make sure you increment your version each time you install, or implement the appropriate clean-up functionality in your install.py script, as otherwise it may throw an exception about not being able to write into a directory that already has files in it. Generally, it's fine to overwrite packages you install locally; we'll talk about how local differs from a \"release\" a little later, and how you can employ continuous integration and write-protect your public release folder for an additional level of security.","title":"Your first payload"},{"location":"getting-started/#what-weve-learned_2","text":"High five! You've now learnt how to include files with your package, this is what we'll use to distribute software like Python libraries along with profile-specific files like the icon we've seen but also files related to potential applications you use, such as Maya script files or shelves. But what if you wanted to include a Python library and call that from an application? How can the application be made aware of what you've included in your package? This is where the environment comes in, and we'll have a look at that next.","title":"What we've learned"},{"location":"getting-started/#your-first-environment","text":"So your profile has got some custom data, that's perfect. Now let's add some metadata as well. name = \"kingkong\" version = \"1.0.2\" build_command = False requires = [ \"~maya==2018.0.6\" , \"~blender==2.80.0\" , \"~texteditor==1.5.1\" , ] def commands (): global env env[ \"PROJECT_ID\" ] = \"12\" env[ \"PROJECT_NAME\" ] = \"kingkong\" env[ \"PROJECT_FRAMERATE\" ] = \"25\" env[ \"PROJECT_TAGS\" ] = \"awesome,great,best\" In Development Congratulations, you made it this far! I'm still working on this next bit, so stay tuned to this page for updates, or monitor the GitHub repo for changes as that's where these are coming from.","title":"Your first environment"},{"location":"gui/","text":"Preferences This tab contains preferences about the application and relevant information for where packages are found. Advanced Controls In the Preferences you'll find an option to enable \"Advanced Controls\". These are designed to separate what is useful to an artist versus a developer.","title":"Gui"},{"location":"gui/#preferences","text":"This tab contains preferences about the application and relevant information for where packages are found.","title":"Preferences"},{"location":"gui/#advanced-controls","text":"In the Preferences you'll find an option to enable \"Advanced Controls\". These are designed to separate what is useful to an artist versus a developer.","title":"Advanced Controls"},{"location":"guides/","text":"The starting point to using and understanding Allzpark. Goal Estimated reading time: 20 mins By the time you're done with this chapter, you'll be able to call the below command, and understand what it does. rez env allzpark bleeding_rez-2.31+ pyside2 python-3 -- allzpark Package Management Allzpark isn't just a pretty face, it's the backbone of any competent production studio working in visual effects, feature animation, commercials or games. That backbone is made up of packages . What is a package? A package is a group of files with some metadata attached, declaring a name, version and its relationship to other packages. When one package requires another, a requirement hierarchy is formed. For example, consider this requirement. requires = [\"maya-2019\", \"arnold\", \"cmuscle\"] From looking at this, you'd expect a version of arnold and cmuscle compatible with maya-2019 (note that we didn't request a particular version of these). Because only a subset of versions of arnold are compatible with maya-2019 what happens is a resolve . Resolve Resolving a request means solving the equation of a requirements hierarchy until exact versions of each package in a request is found, and goes something like this. iteration 01 # maya-2019 arnold cmuscle iteration 02 # maya-2019.0.3 arnold-4.12 cmuscle-1.4 iteration 03 # maya-2019.0.3 arnold-4.12 cmuscle-1.4 libpng-12 libtiff-1 qt-5.12 iteration 04 # maya-2019.0.3 arnold-4.9 cmuscle-1.4 libpng-12 libtiff-1 qt-5.12 qtbase-5.12 qtgui-5-12 openiio-3.41 complete In this example, the first iteration is your original request. The second iteration expands on this request to include specific versions of arnold and cmuscle ; both of which are deemed compatible with maya-2019 . Now things start to get interesting, where did libpng-12 come from?! Well, that's a requirement of arnold-4.12 , so if we want arnold we're going to have to get its other requirements too. But see, now things get even more interesting. arnold-4.12 was just downgraded to arnold-4.9 ! That's because openiio was a requirement of qt and conflicts with arnold-4.12 . As a result, an older version of arnold was picked, one that is compatible with openiio-3.41 . Fun fact That last step is one of the thing that separates Rez from package managers like pip and conda ; the retroactive downgrading of a version to conform to a given constraint. This is one of the things that makes Rez more capable and safer than your typical resolver. As you can see, the number of iterations and complexity therein can grow significantly. It is not uncommon for the number of packages involved to grow into the hundreds and run for dozens to hundreds of iterations per solve, with both off-the-shelf software like above and internally developed projects intermingled. Think about what you would have to go through to solve such a hierarchy yourself - which many do. Prerequisities To resolve requirements, we'll utilise bleeding-rez . pip install bleeding-rez rez bind --quickstart rez --version # bleeding-rez 2.33.1 Troubleshooting pip not found It's possible you have pip installed, just not on your PATH . Try this. python -m pip install bleeding-rez If this doesn't work, let's install pip. Reference curl https://bootstrap.pypa.io/get-pip.py -o get-pip.py python get-pip.py Permission denied The above command assumes admin/sudo access to your machine which isn't always the case. If so, you can install Rez using a virtual environment. $ python -m pip install virtualenv $ python -m virtualenv rez-install $ rez-install \\S cripts \\a ctivate ( rez-install ) $ pip install bleeding-rez rez not found If installation went successfully, but you aren't able to call rez then odds are the Python executable path isn't on your PATH . On Windows, this directory is typically at c:\\python37\\scripts but may vary depending on how Python was installed, and varies across platforms. Following the installation of rez , you should have gotten a message about which path was missing from your PATH , you can either add this yourself, or use the virtualenv method from the above Permission denied box. This will make rez available via the command-line and establish a few default \"packages\" in your ~/packages directory, which we'll talk about later. Your first project In order launch an application in the context of a project using Allzpark, we must create one. Spiderman Your project will be a directory with a file inside called package.py . mkdir spiderman cd spiderman touch package.py This will create a new file called package.py in your newly created spiderman directory. Edit this file with the following. package.py name = \"spiderman\" version = \"1.0\" build_command = False Now we can \"build\" and make use of it. rez build --install $ rez env spiderman > $ The > character denotes that you are in a Rez \"context\", which is its virtual environment. Environment Let's keep going package.py name = \"spiderman\" version = \"1.1\" build_command = False def commands (): global env env[ \"PROJECT_NAME\" ] = \"Spiderman\" Now what happens? > $ exit $ rez build --install $ rez env spiderman > $ Write-Host $env:PROJECT_NAME Spiderman Requirements Great, we're now in control over the environment of this package. What about requirements? package.py name = \"spiderman\" version = \"1.2\" build_command = False requires = [ \"texteditor\" ] def commands (): global env env[ \"PROJECT_NAME\" ] = \"Spiderman\" Now spiderman requires texteditor in order to run. Let's build it. > $ exit $ rez build --install 09 :15:46 ERROR PackageFamilyNotFoundError: package family not found: texteditor Your first application Woops! We haven't got a package for texteditor , let's make one. > $ exit $ cd .. $ mkdir texteditor $ cd texteditor $ touch package.py texteditor/package.py name = \"texteditor\" version = \"1.0\" build_command = False def commands (): import os global alias if os . name == \"nt\" : alias( \"texteditor\" , \"notepad\" ) else : alias( \"texteditor\" , \"nano\" ) Now let's build and use this package. $ rez build --install $ rez env spiderman > $ texteditor Viola, a platform-dependent text editor, tied to a given project. This is one way of tying applications to a project, but we'll look at some more as we go along. In general, you'll want to keep packages self-contained and portable, such that you can deploy them elsewhere. In this case, we utilised a widely accessible application we can expect to exist on almost any workstation. But we aren't always so lucky. Another application Let's make another one to illustrate this point. > $ exit $ cd .. $ mkdir maya $ cd maya $ touch package.py maya/package.py name = \"maya\" version = \"2018.0\" build_command = False def commands (): import os global alias if os . name == \"nt\" : alias( \"maya\" , r\"c:\\program files\\autodesk\\maya2018\\bin\\maya.exe\" ) else : alias( \"maya\" , \"/usr/autodesk/maya2018/bin/maya.bin\" ) In this example, we're making some assumptions that may or may not be appropriate for your environment. If you are in control over workstations and installation paths, then this is fine. But if you can't make that guarantee, you'll care about portability which we'll cover a little later. Exercise Before we move on, make another package for maya-2019 as well in a similar fashion. We'll need this for later. Weak References Let's now update our project to require maya and see what we end up with. spiderman/package.py name = \"spiderman\" version = \"1.3\" build_command = False requires = [ \"texteditor-1\" , \"maya-2018\" ] def commands (): global env env[ \"PROJECT_NAME\" ] = \"Spiderman\" To run it.. $ rez env spiderman > $ maya > $ texteditor As you can see, you now have both maya and texteditor available, at the same time. This typically is not what you want, and comes with a few gotchas. Consider for example if texteditor had a requirement for another project, such as msvcrt<=2011 , and that maya has a similar but conflicting requirement, such as msvcrt>=2013 . In isolation, this isn't a problem, because you can happily run texteditor without requiring maya and vice versa. But because these are both requirements of spiderman , you've now made spiderman impossible to use. To account for this, we need to use \"weak\" references for both texteditor and maya . spiderman/package.py name = \"spiderman\" version = \"1.4\" build_command = False requires = [ \"~texteditor-1\" , \"~maya-2018\" ] def commands (): global env env[ \"PROJECT_NAME\" ] = \"Spiderman\" Now when spiderman is requested, neither maya nor texteditor is included. ~/spiderman $ rez build --install ~/spiderman $ rez env spiderman > ~/spiderman $ maya # Unrecognised command Instead, you ask for them as part of your request. > spiderman/ $ exit spiderman/ $ rez env spiderman maya # resolved packages: # maya-2018.0 ~\\packages\\maya\\2018.0 But then, what was the point of making these requirements of spiderman if they weren't going to become part of the resolve unless? Surely you can just leave them out, and include maya in the request? If you notice above, the resolved package was maya-2018 . If it wasn't for this weak reference, Rez would have picked the latest version, maya-2019 . This is how you can tie applications to your project, without including each of them into the same context. Think about how chaotic this would be if your project involved dozens of applications! Allzpark So you've made a project and given it a unique environment and applications. What's stopping you from launching these applications directly from the command-line? Why do you need Allzpark? You don't! Every command we've typed so far has been entirely in the hands of Rez and you can safely run productions in this way. What Allzpark does is put a face on this system, something for the less technical-minded artists to wrap their heads around, and establish a few ground-rules about how to make the most out of Rez. We'll get into these rules a little later, but for now, let's see what Allzpark looks like on your machine. For this next part, we'll need git . git --version # git version 2.16.1 git not found Git is required in later chapters, so you may as well get it up and running right away. https://git-scm.com/ Allzpark is a Python package, and whilst we could install it like any other Python package, what we're going to do instead is install it as another Rez package. For that, we'll need pipz . git clone https : //github.com/mottosso/rez-pipz.git cd rez-pipz rez build --install pipz is a wrapper around pip for use with Rez. It can take any request pip can, and turn it into a Rez package. This saves from having to create a Rez package ourselves, when it's already a Python package. Neat! To test out the installation, let's install six as Rez package. rez env pipz -- install six -y This is the equivalent of pip install six . Now let's try it with Allzpark. git clone https : //github.com/mottosso/allzpark.git rez env pipz -- install ./allzpark In this case, we'll install Allzpark from the cloned repository directly (as it isn't yet on PyPI). We'll also need a Qt binding. Any binding will do, in this example we'll use PySide2. rez env pipz -- install pyside2 -y And there you have it. We are now ready to launch Allzpark. rez env allzpark python pyside2 -- allzpark --root ~/packages Under Development Shared Packages One of the thing that separates Res from other package managers like virtualenv and conda is that packages you install are shared . Not only can they be shared across multiple machines, but also across multiple operating systems. Once a package has been installed, you'll never have to install it again. It is permanent, immutable in fact. This is how you can build up a personal- or studio-repository of packages that you can build a pipeline upon, making strong and controlled assumptions about what packages are available, which version they are at, and that they are compatible with each other. So far, we've installed all packages into their default location, which is ~/packages . ls $env :USERPROFILE/packages # With PowerShell ls $HOME /packages # With Bash Loading Order If your graphical application depends on Qt.py, then Qt.py needs to be loaded before your application. This is where loading order comes in. By establishing a requirements hierarchy, the order in which libraries load is included for free. Package Path The recommended layout for Rez packages are as follows. int/ Internal projects, such as core_pipeline . You develop and release new versions internally. ext/ External projects, such as pyblish and Qt.py , you typically install these with rez env pipz -- install td/ Packages developed by TDs themselves, such as small utility scripts proj/ Project such as ATC and MST3 app/ Applications, such as maya and nuke converted/ Automatically converted packages from the old Template-based system There are two additional paths. ~/packages Your local development packages, from your home directory ~/.packages Your localised packages Pip Any package from PyPI can be installed using a utility package called pipz . $ rez env pipz -- install pyblish-base --release See rez-pipz for details. Scoop Any package from Scoop can be installed using another utility package called scoopz . $ rez env scoopz -- install python python27 git See rez-scoopz for details. Localisation For greater performance, any package may be localised to your local disk. See rez-localz for details. Example $ rez env pyside2 allzpark bleeding_rez -- python -m allzpark ============================== allzpark (1.1.79) ============================== - Loading Rez.. ok - 0.75s - Loading Qt.. ok - 6.14s - Loading allzpark.. ok - 0.53s - Loading preferences.. ok - 0.00s ------------------------------ Notice how long it took to load Qt , let's localise this. $ rez env localz -- localise PySide2 Now try launching again. $ rez env pyside2 allzpark bleeding_rez -- python -m allzpark rez env pyside2 allzpark bleeding_rez -- python -m allzpark ============================== allzpark (1.1.79) ============================== - Loading Rez.. ok - 0.91s - Loading Qt.. ok - 0.36s - Loading allzpark.. ok - 0.70s - Loading preferences.. ok - 0.00s ------------------------------ That's much better. Disk Space To save disk space, you can delete any or all localised packages from your ~/.packages path. start % USERPROFILE%\\.packages Overrides Packages, like Python modules, are discovered from a list of paths. If there are identical packages on two or more paths, the first one is picked. We can leverage this behavior to override one package with another. Requirements Overriding requirements enable you to test new packages, or packages of different versions, in an existing project and works like this. Copy project onto local development directory Edit Install If the version remains the same or higher then your edited project is now picked up in place of the original, providing final control over which packages are used in a given project. Environment Overriding environment variables can be achieved in a similar fashion to requirements , but is even more flexible. Packages with regards to environment variables act akin to CSS, or Cascading Style Sheets, from the world wide web in that every change augments - or cascades - a previous change. a/package.py def commands (): global env env[ \"PYTHONPATH\" ] . append( \"/a\" ) b/package.py requires = [ \"a\" ] def commands (): global env env[ \"PYTHONPATH\" ] . append( \"/b\" ) In this example, the package b augments an existing PYTHONPATH created by package a . It does so by appending the value \"/b\" . You can also prepend and overwrite by assigning it directly. env[].append(\"\") env[].prepend(\"\") env[] = \"\" Example - Legacy Viewport We can leverage this behavior to override the behavior of a program using dedicated \"override packages\". maya_legacy_viewport/package.py name = \"maya_legacy_viewport\" version = \"1.0\" requires = [ \"maya\" ] def commands (): global env env[ \"MAYA_ENABLE_LEGACY_VIEWPORT\" ] = \"1\" Including this package in your resolve results in Maya exposing the Legacy Viewport option, to circumvent that pesky Viewport 2.0. Performance Rez is heavily dependent on a server-side application called memcached , which as the name suggests is a cache for queries involving the filesystem. Without it, resolving new environments can take seconds to minutes compared to milliseconds, so it's recommended that you set it up. With Docker If you've got access to Docker, then this is the simplest option for both a local and distributed install. docker run -ti --rm -p 11211 :11211 memcached This will expose memcached to its default port 11211. With RaspberryPi Memcached isn't particularly memory intensive (>=32 mb of RAM) and can run on low-end hardware like a Pi, and should keep you covered up to 500 versions or so. apt-get install memcached This will expose memcached to its default port 11211. Bare metal You can also install onto your local machine, however it requires a Linux or MacOS operating system for that. https://www.memcached.org/downloads","title":"Guides"},{"location":"guides/#goal","text":"Estimated reading time: 20 mins By the time you're done with this chapter, you'll be able to call the below command, and understand what it does. rez env allzpark bleeding_rez-2.31+ pyside2 python-3 -- allzpark","title":"Goal"},{"location":"guides/#package-management","text":"Allzpark isn't just a pretty face, it's the backbone of any competent production studio working in visual effects, feature animation, commercials or games. That backbone is made up of packages .","title":"Package Management"},{"location":"guides/#what-is-a-package","text":"A package is a group of files with some metadata attached, declaring a name, version and its relationship to other packages. When one package requires another, a requirement hierarchy is formed. For example, consider this requirement. requires = [\"maya-2019\", \"arnold\", \"cmuscle\"] From looking at this, you'd expect a version of arnold and cmuscle compatible with maya-2019 (note that we didn't request a particular version of these). Because only a subset of versions of arnold are compatible with maya-2019 what happens is a resolve .","title":"What is a package?"},{"location":"guides/#resolve","text":"Resolving a request means solving the equation of a requirements hierarchy until exact versions of each package in a request is found, and goes something like this. iteration 01 # maya-2019 arnold cmuscle iteration 02 # maya-2019.0.3 arnold-4.12 cmuscle-1.4 iteration 03 # maya-2019.0.3 arnold-4.12 cmuscle-1.4 libpng-12 libtiff-1 qt-5.12 iteration 04 # maya-2019.0.3 arnold-4.9 cmuscle-1.4 libpng-12 libtiff-1 qt-5.12 qtbase-5.12 qtgui-5-12 openiio-3.41 complete In this example, the first iteration is your original request. The second iteration expands on this request to include specific versions of arnold and cmuscle ; both of which are deemed compatible with maya-2019 . Now things start to get interesting, where did libpng-12 come from?! Well, that's a requirement of arnold-4.12 , so if we want arnold we're going to have to get its other requirements too. But see, now things get even more interesting. arnold-4.12 was just downgraded to arnold-4.9 ! That's because openiio was a requirement of qt and conflicts with arnold-4.12 . As a result, an older version of arnold was picked, one that is compatible with openiio-3.41 . Fun fact That last step is one of the thing that separates Rez from package managers like pip and conda ; the retroactive downgrading of a version to conform to a given constraint. This is one of the things that makes Rez more capable and safer than your typical resolver. As you can see, the number of iterations and complexity therein can grow significantly. It is not uncommon for the number of packages involved to grow into the hundreds and run for dozens to hundreds of iterations per solve, with both off-the-shelf software like above and internally developed projects intermingled. Think about what you would have to go through to solve such a hierarchy yourself - which many do.","title":"Resolve"},{"location":"guides/#prerequisities","text":"To resolve requirements, we'll utilise bleeding-rez . pip install bleeding-rez rez bind --quickstart rez --version # bleeding-rez 2.33.1 Troubleshooting pip not found It's possible you have pip installed, just not on your PATH . Try this. python -m pip install bleeding-rez If this doesn't work, let's install pip. Reference curl https://bootstrap.pypa.io/get-pip.py -o get-pip.py python get-pip.py Permission denied The above command assumes admin/sudo access to your machine which isn't always the case. If so, you can install Rez using a virtual environment. $ python -m pip install virtualenv $ python -m virtualenv rez-install $ rez-install \\S cripts \\a ctivate ( rez-install ) $ pip install bleeding-rez rez not found If installation went successfully, but you aren't able to call rez then odds are the Python executable path isn't on your PATH . On Windows, this directory is typically at c:\\python37\\scripts but may vary depending on how Python was installed, and varies across platforms. Following the installation of rez , you should have gotten a message about which path was missing from your PATH , you can either add this yourself, or use the virtualenv method from the above Permission denied box. This will make rez available via the command-line and establish a few default \"packages\" in your ~/packages directory, which we'll talk about later.","title":"Prerequisities"},{"location":"guides/#your-first-project","text":"In order launch an application in the context of a project using Allzpark, we must create one.","title":"Your first project"},{"location":"guides/#spiderman","text":"Your project will be a directory with a file inside called package.py . mkdir spiderman cd spiderman touch package.py This will create a new file called package.py in your newly created spiderman directory. Edit this file with the following. package.py name = \"spiderman\" version = \"1.0\" build_command = False Now we can \"build\" and make use of it. rez build --install $ rez env spiderman > $ The > character denotes that you are in a Rez \"context\", which is its virtual environment.","title":"Spiderman"},{"location":"guides/#environment","text":"Let's keep going package.py name = \"spiderman\" version = \"1.1\" build_command = False def commands (): global env env[ \"PROJECT_NAME\" ] = \"Spiderman\" Now what happens? > $ exit $ rez build --install $ rez env spiderman > $ Write-Host $env:PROJECT_NAME Spiderman","title":"Environment"},{"location":"guides/#requirements","text":"Great, we're now in control over the environment of this package. What about requirements? package.py name = \"spiderman\" version = \"1.2\" build_command = False requires = [ \"texteditor\" ] def commands (): global env env[ \"PROJECT_NAME\" ] = \"Spiderman\" Now spiderman requires texteditor in order to run. Let's build it. > $ exit $ rez build --install 09 :15:46 ERROR PackageFamilyNotFoundError: package family not found: texteditor","title":"Requirements"},{"location":"guides/#your-first-application","text":"Woops! We haven't got a package for texteditor , let's make one. > $ exit $ cd .. $ mkdir texteditor $ cd texteditor $ touch package.py texteditor/package.py name = \"texteditor\" version = \"1.0\" build_command = False def commands (): import os global alias if os . name == \"nt\" : alias( \"texteditor\" , \"notepad\" ) else : alias( \"texteditor\" , \"nano\" ) Now let's build and use this package. $ rez build --install $ rez env spiderman > $ texteditor Viola, a platform-dependent text editor, tied to a given project. This is one way of tying applications to a project, but we'll look at some more as we go along. In general, you'll want to keep packages self-contained and portable, such that you can deploy them elsewhere. In this case, we utilised a widely accessible application we can expect to exist on almost any workstation. But we aren't always so lucky.","title":"Your first application"},{"location":"guides/#another-application","text":"Let's make another one to illustrate this point. > $ exit $ cd .. $ mkdir maya $ cd maya $ touch package.py maya/package.py name = \"maya\" version = \"2018.0\" build_command = False def commands (): import os global alias if os . name == \"nt\" : alias( \"maya\" , r\"c:\\program files\\autodesk\\maya2018\\bin\\maya.exe\" ) else : alias( \"maya\" , \"/usr/autodesk/maya2018/bin/maya.bin\" ) In this example, we're making some assumptions that may or may not be appropriate for your environment. If you are in control over workstations and installation paths, then this is fine. But if you can't make that guarantee, you'll care about portability which we'll cover a little later. Exercise Before we move on, make another package for maya-2019 as well in a similar fashion. We'll need this for later.","title":"Another application"},{"location":"guides/#weak-references","text":"Let's now update our project to require maya and see what we end up with. spiderman/package.py name = \"spiderman\" version = \"1.3\" build_command = False requires = [ \"texteditor-1\" , \"maya-2018\" ] def commands (): global env env[ \"PROJECT_NAME\" ] = \"Spiderman\" To run it.. $ rez env spiderman > $ maya > $ texteditor As you can see, you now have both maya and texteditor available, at the same time. This typically is not what you want, and comes with a few gotchas. Consider for example if texteditor had a requirement for another project, such as msvcrt<=2011 , and that maya has a similar but conflicting requirement, such as msvcrt>=2013 . In isolation, this isn't a problem, because you can happily run texteditor without requiring maya and vice versa. But because these are both requirements of spiderman , you've now made spiderman impossible to use. To account for this, we need to use \"weak\" references for both texteditor and maya . spiderman/package.py name = \"spiderman\" version = \"1.4\" build_command = False requires = [ \"~texteditor-1\" , \"~maya-2018\" ] def commands (): global env env[ \"PROJECT_NAME\" ] = \"Spiderman\" Now when spiderman is requested, neither maya nor texteditor is included. ~/spiderman $ rez build --install ~/spiderman $ rez env spiderman > ~/spiderman $ maya # Unrecognised command Instead, you ask for them as part of your request. > spiderman/ $ exit spiderman/ $ rez env spiderman maya # resolved packages: # maya-2018.0 ~\\packages\\maya\\2018.0 But then, what was the point of making these requirements of spiderman if they weren't going to become part of the resolve unless? Surely you can just leave them out, and include maya in the request? If you notice above, the resolved package was maya-2018 . If it wasn't for this weak reference, Rez would have picked the latest version, maya-2019 . This is how you can tie applications to your project, without including each of them into the same context. Think about how chaotic this would be if your project involved dozens of applications!","title":"Weak References"},{"location":"guides/#allzpark","text":"So you've made a project and given it a unique environment and applications. What's stopping you from launching these applications directly from the command-line? Why do you need Allzpark? You don't! Every command we've typed so far has been entirely in the hands of Rez and you can safely run productions in this way. What Allzpark does is put a face on this system, something for the less technical-minded artists to wrap their heads around, and establish a few ground-rules about how to make the most out of Rez. We'll get into these rules a little later, but for now, let's see what Allzpark looks like on your machine. For this next part, we'll need git . git --version # git version 2.16.1 git not found Git is required in later chapters, so you may as well get it up and running right away. https://git-scm.com/ Allzpark is a Python package, and whilst we could install it like any other Python package, what we're going to do instead is install it as another Rez package. For that, we'll need pipz . git clone https : //github.com/mottosso/rez-pipz.git cd rez-pipz rez build --install pipz is a wrapper around pip for use with Rez. It can take any request pip can, and turn it into a Rez package. This saves from having to create a Rez package ourselves, when it's already a Python package. Neat! To test out the installation, let's install six as Rez package. rez env pipz -- install six -y This is the equivalent of pip install six . Now let's try it with Allzpark. git clone https : //github.com/mottosso/allzpark.git rez env pipz -- install ./allzpark In this case, we'll install Allzpark from the cloned repository directly (as it isn't yet on PyPI). We'll also need a Qt binding. Any binding will do, in this example we'll use PySide2. rez env pipz -- install pyside2 -y And there you have it. We are now ready to launch Allzpark. rez env allzpark python pyside2 -- allzpark --root ~/packages","title":"Allzpark"},{"location":"guides/#under-development","text":"","title":"Under Development"},{"location":"guides/#shared-packages","text":"One of the thing that separates Res from other package managers like virtualenv and conda is that packages you install are shared . Not only can they be shared across multiple machines, but also across multiple operating systems. Once a package has been installed, you'll never have to install it again. It is permanent, immutable in fact. This is how you can build up a personal- or studio-repository of packages that you can build a pipeline upon, making strong and controlled assumptions about what packages are available, which version they are at, and that they are compatible with each other. So far, we've installed all packages into their default location, which is ~/packages . ls $env :USERPROFILE/packages # With PowerShell ls $HOME /packages # With Bash","title":"Shared Packages"},{"location":"guides/#loading-order","text":"If your graphical application depends on Qt.py, then Qt.py needs to be loaded before your application. This is where loading order comes in. By establishing a requirements hierarchy, the order in which libraries load is included for free.","title":"Loading Order"},{"location":"guides/#package-path","text":"The recommended layout for Rez packages are as follows. int/ Internal projects, such as core_pipeline . You develop and release new versions internally. ext/ External projects, such as pyblish and Qt.py , you typically install these with rez env pipz -- install td/ Packages developed by TDs themselves, such as small utility scripts proj/ Project such as ATC and MST3 app/ Applications, such as maya and nuke converted/ Automatically converted packages from the old Template-based system There are two additional paths. ~/packages Your local development packages, from your home directory ~/.packages Your localised packages","title":"Package Path"},{"location":"guides/#pip","text":"Any package from PyPI can be installed using a utility package called pipz . $ rez env pipz -- install pyblish-base --release See rez-pipz for details.","title":"Pip"},{"location":"guides/#scoop","text":"Any package from Scoop can be installed using another utility package called scoopz . $ rez env scoopz -- install python python27 git See rez-scoopz for details.","title":"Scoop"},{"location":"guides/#localisation","text":"For greater performance, any package may be localised to your local disk. See rez-localz for details. Example $ rez env pyside2 allzpark bleeding_rez -- python -m allzpark ============================== allzpark (1.1.79) ============================== - Loading Rez.. ok - 0.75s - Loading Qt.. ok - 6.14s - Loading allzpark.. ok - 0.53s - Loading preferences.. ok - 0.00s ------------------------------ Notice how long it took to load Qt , let's localise this. $ rez env localz -- localise PySide2 Now try launching again. $ rez env pyside2 allzpark bleeding_rez -- python -m allzpark rez env pyside2 allzpark bleeding_rez -- python -m allzpark ============================== allzpark (1.1.79) ============================== - Loading Rez.. ok - 0.91s - Loading Qt.. ok - 0.36s - Loading allzpark.. ok - 0.70s - Loading preferences.. ok - 0.00s ------------------------------ That's much better. Disk Space To save disk space, you can delete any or all localised packages from your ~/.packages path. start % USERPROFILE%\\.packages","title":"Localisation"},{"location":"guides/#overrides","text":"Packages, like Python modules, are discovered from a list of paths. If there are identical packages on two or more paths, the first one is picked. We can leverage this behavior to override one package with another.","title":"Overrides"},{"location":"guides/#requirements_1","text":"Overriding requirements enable you to test new packages, or packages of different versions, in an existing project and works like this. Copy project onto local development directory Edit Install If the version remains the same or higher then your edited project is now picked up in place of the original, providing final control over which packages are used in a given project.","title":"Requirements"},{"location":"guides/#environment_1","text":"Overriding environment variables can be achieved in a similar fashion to requirements , but is even more flexible. Packages with regards to environment variables act akin to CSS, or Cascading Style Sheets, from the world wide web in that every change augments - or cascades - a previous change. a/package.py def commands (): global env env[ \"PYTHONPATH\" ] . append( \"/a\" ) b/package.py requires = [ \"a\" ] def commands (): global env env[ \"PYTHONPATH\" ] . append( \"/b\" ) In this example, the package b augments an existing PYTHONPATH created by package a . It does so by appending the value \"/b\" . You can also prepend and overwrite by assigning it directly. env[].append(\"\") env[].prepend(\"\") env[] = \"\"","title":"Environment"},{"location":"guides/#example-legacy-viewport","text":"We can leverage this behavior to override the behavior of a program using dedicated \"override packages\". maya_legacy_viewport/package.py name = \"maya_legacy_viewport\" version = \"1.0\" requires = [ \"maya\" ] def commands (): global env env[ \"MAYA_ENABLE_LEGACY_VIEWPORT\" ] = \"1\" Including this package in your resolve results in Maya exposing the Legacy Viewport option, to circumvent that pesky Viewport 2.0.","title":"Example - Legacy Viewport"},{"location":"guides/#performance","text":"Rez is heavily dependent on a server-side application called memcached , which as the name suggests is a cache for queries involving the filesystem. Without it, resolving new environments can take seconds to minutes compared to milliseconds, so it's recommended that you set it up. With Docker If you've got access to Docker, then this is the simplest option for both a local and distributed install. docker run -ti --rm -p 11211 :11211 memcached This will expose memcached to its default port 11211. With RaspberryPi Memcached isn't particularly memory intensive (>=32 mb of RAM) and can run on low-end hardware like a Pi, and should keep you covered up to 500 versions or so. apt-get install memcached This will expose memcached to its default port 11211. Bare metal You can also install onto your local machine, however it requires a Linux or MacOS operating system for that. https://www.memcached.org/downloads","title":"Performance"},{"location":"localisation/","text":"Shared packages","title":"Localisation"},{"location":"quickstart/","text":"This page will get you up and running with Allzpark in less than 2 minutes. Quickstart The below commands will install Allzpark and its dependencies, including Rez. python -m pip install allzpark --upgrade rez bind --quickstart allzpark --demo --clean Skip the --clean flag to preserve preferences, such as window layout, between runs. Troubleshooting Everything ok? No module named pip For this to work, we'll need pip. Reference curl https://bootstrap.pypa.io/get-pip.py -o get-pip.py python get-pip.py If that didn't work, have a look at to install pip for your platform. Examples CentOS 7 - yum install python-pip Ubuntu 18 - apt install python3-pip Permission denied The above command assumes admin/sudo access to your machine which isn't always the case. If so, you can install Allzpark into a virtual environment. Python 3 $ python -m venv allzpark-venv $ allzpark-venv \\S cripts \\a ctivate ( allzpark-venv ) $ pip install allzpark Python 2 $ python -m pip install virtualenv $ python -m virtualenv allzpark-venv $ allzpark-venv \\S cripts \\a ctivate ( allzpark-venv ) $ pip install allzpark rez not found If installation went successfully, but you aren't able to call rez then odds are the Python executable path isn't on your PATH . On Windows, this directory is typically at c:\\python37\\scripts but may vary depending on how Python was installed, and varies across platforms. Following the installation of rez , you should have gotten a message about which path was missing from your PATH , you can either add this yourself, or use the virtualenv method from the above Permission denied box. Example message The script allzpark.exe and azp.exe are installed in 'C:\\Python37\\Scripts' which is not on PATH Consider adding this directory to PATH Something else happened Oh no! I'd like to know about what happened, please let me know here . Result If everything went well, you should now be presented with this! Next Steps From here, try launching your favourite application, navigate the interface and make yourself at home. Then have a look at these to learn more. Note that the applications provided are examples and may not work as-is on your system. Create a new profile Create a new application","title":"Quickstart"},{"location":"quickstart/#quickstart","text":"The below commands will install Allzpark and its dependencies, including Rez. python -m pip install allzpark --upgrade rez bind --quickstart allzpark --demo --clean Skip the --clean flag to preserve preferences, such as window layout, between runs.","title":"Quickstart"},{"location":"quickstart/#troubleshooting","text":"Everything ok? No module named pip For this to work, we'll need pip. Reference curl https://bootstrap.pypa.io/get-pip.py -o get-pip.py python get-pip.py If that didn't work, have a look at to install pip for your platform. Examples CentOS 7 - yum install python-pip Ubuntu 18 - apt install python3-pip Permission denied The above command assumes admin/sudo access to your machine which isn't always the case. If so, you can install Allzpark into a virtual environment. Python 3 $ python -m venv allzpark-venv $ allzpark-venv \\S cripts \\a ctivate ( allzpark-venv ) $ pip install allzpark Python 2 $ python -m pip install virtualenv $ python -m virtualenv allzpark-venv $ allzpark-venv \\S cripts \\a ctivate ( allzpark-venv ) $ pip install allzpark rez not found If installation went successfully, but you aren't able to call rez then odds are the Python executable path isn't on your PATH . On Windows, this directory is typically at c:\\python37\\scripts but may vary depending on how Python was installed, and varies across platforms. Following the installation of rez , you should have gotten a message about which path was missing from your PATH , you can either add this yourself, or use the virtualenv method from the above Permission denied box. Example message The script allzpark.exe and azp.exe are installed in 'C:\\Python37\\Scripts' which is not on PATH Consider adding this directory to PATH Something else happened Oh no! I'd like to know about what happened, please let me know here .","title":"Troubleshooting"},{"location":"quickstart/#result","text":"If everything went well, you should now be presented with this!","title":"Result"},{"location":"quickstart/#next-steps","text":"From here, try launching your favourite application, navigate the interface and make yourself at home. Then have a look at these to learn more. Note that the applications provided are examples and may not work as-is on your system. Create a new profile Create a new application","title":"Next Steps"},{"location":"reference/","text":"Short bite-sized snippets of information. This builds on information provided in the guides chapter. allzparkconfig.py Configure allzpark using the allzparkconfig.py , which it will look for in these three locations, first one found wins. Your home directory, e.g. ~/allzparkonfig.py Passed via command-line, e.g. allzpark --config-file path/to/allzparkconfig.py Or the environment, ALLZPARK_CONFIG_FILE=/full/path/to/allzparkconfig.py All available keys and their default values can be found here. allzparkconfig.py And an example can be found here: rez-for-projects Styling All of the Allzpark graphical user interface can be styled interactively using CSS. Custom styles are stored on the local machine, and can be shared and saved with copy/paste over e.g. chat or email. See style.css for examples and documentation Naming Convention Requests are split between name<operator><version> Where <operator> is e.g. - or == or >= And <version> is an alphanumeric string, e.g. 1.0 or latest or 2.b2 Example rez env my_package-1 # package `my_package`, version `1` or above rez env my-package-1 # package `my`, version `package-1` or above rez env my_package_1 # package `my_package_1`, latest version rez env my_package == 1 # package `my_package_1`, version `1` exactly See wiki for details. Automatic Environment Variables Every package part of a resolve is given a series of environment variables. REZ_(PKG)_BASE REZ_(PKG)_ROOT REZ_(PKG)_VERSION REZ_(PKG)_MAJOR_VERSION REZ_(PKG)_MINOR_VERSION REZ_(PKG)_PATCH_VERSION You can reference these from other packages, using the {env.NAME} notation, where env refers to the system environment, prior to packages having an effect. Example # package.py name = \"my_package\" version = \"1.0\" requires = [ \"my_package-1.0\" ] def commands (): global env env[ \"MY_VARIABLE\" ] = r\"c:\\path\\{env.REZ_MY_PACKAGE_VERSION}\\scripts\" See wiki for details. Platform Specific Packages A package can target a given platform using \"variants\". my_package/package.py name = \"my_package\" version = \"1.0\" build_command = False variants = [ [ \"platform-windows\" ], [ \"platform-linux\" ], ] Requesting this package on windows would result in a version specific to Windows, and likewise for Linux. Building of this package happens twice ; once per \"variant\". Building Per Platform $ cd my_package $ rez build Building variant 0 ( 1 /2 ) ... Invoking custom build system... Building variant 0 ( 2 /2 ) ... The following package conflicts occurred: ( platform-linux <--!--> ~platform == windows ) Since you cannot build a Linux package from Windows, nor vice versa, you can specify which variant to build using the --variants argument. $ rez build --variants 0 Where 0 indicates the 0 th index in the package.py:variants = [] list. See wiki for details See rez build --help for details Options You can reference any package and version as a variant, but generally you'll only need the platform specific ones, which come defined in rezconfig.py per default. rezconfig.py implicit_packages = [ \"~platform=={system.platform}\" , \"~arch=={system.arch}\" , \"~os=={system.os}\" , ] See rez config implicit_packages for available options along with their values. rez config implicit_packages - ~platform == windows - ~arch == AMD64 - ~os == windows-10 Multiple Application Versions Applications such as Python, Autodesk Maya and Adobe Photoshop can get packaged in one of two ways. maya-2018.1.0 i.e. \"Serial\" maya2018-1.0 i.e. \"Parallel\" Let's refer to these as \"serial\" and \"parallel\" respectively. Which should you use, and why? Uniform In this example, there is only one package \"family\" for the Autodesk Maya software, whereby every revision of Maya is released as a new Rez package version; including \"service packs\" and \"hotfixes\" etc. The advantage is that a package can then create a requirement on a range of maya versions. name = \"mgear\" version = \"1.0.0\" requires = [ \"maya>=2015,<2020\" ] The disadvantage however is that you cannot resolve an environment with both maya-2018 and maya-2019 , as one would conflict with the other. Furthermore, if you did force this resolve, what should you expect to have happen in a situation like this? $ rez env python-2 python-3 > $ python --version Python ?.?.? Parallel Conversely, you can perform a \"parallel\" version. maya2018/package.py name = \"maya2018\" version = \"1.0\" maya2019/package.py name = \"maya2019\" version = \"1.0\" In which case you are able to resolve an environment like this. $ rez env maya2018 maya2019-1.0 > $ To work around the aforementioned issue of knowing which python - or in this case maya - is actually called, you can use an alias() . maya2019/package.py name = \"maya2019\" version = \"1.0\" def commands (): global alias alias( \"maya2019\" , \"{root}/bin/maya.exe\" ) At which point you can call.. $ rez env maya2018 maya2019 > $ maya2018 # Launching Maya 2018.. However it isn't clear how you can make a requirement on a range of Maya versions with a parallel package. Consider the mgear package. mgear/package.py name = \"mgear\" version = \"1.0\" requires = [ \"maya2018-1.0\" ] # What about Maya 2019? :( Rez currently does not support optional or \"any\"-style packages and so this approach would not be well suited for these types of requirements. Packages and Version Control Work in progress If you got this far, and know more or want more, feel free to submit an issue . Release with GitLab Once you've created a package, it's often a good idea to version control it. mkdir my_package cd my_package echo \"name = `\" my_package `\" \" >> package.py echo \"version = `\" 1.0.0 `\" \" >> package.py echo \"build_command = False\" >> package.py git init git add --all git commit -m \"Initial version\" git remote add-url https : //gitlab.mycompany.com/username/my_package.git git push Next we'll configure GitLab to release a package alongside a new tag being made. .gitlab-ci.yml release: environment: - REZ_CONFIG_FILE=/packages/rezconfig.py script: - rez build --release only: - tags Work in progress If you got this far, and know more or want more, feel free to submit an issue . Multiple Packages in a Single Git Repository Sometimes, dedicating a Git repository or GitLab project for every package is too heavy-handed. Sometimes you have many small packages that all need version control, but not necessarily independently, such as project packages. In this example, we'll create a Git repository containing 3 projects. Alita Spiderman Hulk These projects are all released as individual Rez packages, but are managed in one Git repository. mkdir my_projects cd my_projects mkdir alita mkdir spiderman mkdir hulk Create a package.py in each project subdirectory, with something along the lines of: name = \"alita\" version = \"1.0.0\" build_command = False Now we can commit and push these to, for example, your locally hosted GitLab instance. git init git add --all git commit -m \"Initial version\" git remote add-url https://gitlab.mycompany.com/username/my_projects.git git push When it's time to release, simply cd into a package of interest, and --release . cd alita rez build --install --release --clean Render on Farm Typically, a context is resolved locally and work performed therein, and then further computation is submitted to a remote destination, such as a \"render farm\" or distributed compute network. In this case, it can be necessary to replicate a context remotely, in exactly the same configuration as locally. But, you cannot assume: Where packages are stored, because a remote computer may have different mount points What OS the remote destination is running, because it may be e.g. Windows or Linux Raw Environment Because of the above, simply saving the environment as-is and restoring it elsewhere is rarely enough. import os import json # Not enough.. with open( \"environment.json\" , \"w\" ) as f: json . dump(f, dict(os . environ)) RXT You may consider storing the resolved context to a file, for example.. rez env packageA packageB --output context.rxt # Machine A rez env --input context.rxt # Machine B Alternatively.. rez env packageA packageB > Get-Content $env :REZ_RXT_FILE > context.rxt > exit rez env --input context.rxt But an exported context embeds absolute paths to where packages can be found, which may not be true on the remote end - such as a local render farm or remote cloud. REZ_USED_RESOLVE In this case, you may consider exporting the exact request, like this. rez env packageA packageB --exclude *.beta > $env :REZ_USED_RESOLVE # packageA-2.33.3 packageB-5.12.3 However this may not be precise enough. The - indicator locks the included parts of a version, such as 5.12.3 , but doesn't exclude the possibility of a 5.12.3.beta package, which takes precendence over 5.12.3 . rez env packageA-2.33.3 packageB-5.12.3 > $env :REZ_USED_RESOLVE # packageA-2.33.3 packageB-5.12.3.beta Notice the .beta towards the end. Here's another example. rez env packageA # packageA-1.0.0.beta rez env packageA-1.0.0 # packageA-1.0.0.beta rez env packageA-1.0.0.beta # packageA-1.0.0.beta For that reason, passing REZ_USED_RESOLVE to rez env may not be enough to accurately reproduce a given environment. Inherit Filter So then what you could do, is pass along whatever filer you used to the remote end. Local rez env packageA packageB --exclude *.beta -- echo $env :REZ_USED_RESOLVE # packageA-2.33.3 packageB-5.12.3 Remote rez env packageA-2.33.3 packageB-5.12.3 --exclude *.beta And presto, an identical environment.. but wait! What about --patch ed environments. rez env packageA packageB --exclude *.beta > rez env packageB-5.12.3.beta >> $env :REZ_USED_RESOLVE # packageA-2.33.3 packageB-5.12.3.beta Now the final \"used resolve\" is incompatible with this filter, as --exclude *.beta would hide the beta version of packageB , resulting in.. 12 :18:12 ERROR PackageNotFoundError: Package could not be found: packageB == 5 .12.3.beta resolved_packages So what is the solution? In a nutshell.. Resolve a context Serialise ResolvedContext.resolved_packages to {name}=={version} used_resolve.py from rez.status import status # Use `status` to fetch an instance of ResolvedContext # from within our current environment. print ( \" \" . join([ \"%s==%s\" % (pkg . name, pkg . version) for pkg in status . context . resolved_packages ])) Resulting in.. rez env python packageA packageB --exclude *.beta -- python used_resolve.py # packageA==2.33.3 packageB==5.12.3 And presto, an accurate depiction of a given context, suitable for use again on the same machine, on a local render farm or remote cloud rendering environment. requested_packages What that last method doesn't do however is guarantee that one resolve to work across platforms. Take this package for example. name = \"processmanager\" variants = [ [ \"platform-windows\" , \"win32all\" ], [ \"platform-linux\" , \"unix-process-tool\" ], ] On Windows, this would result in a list of resolved packages including win32all which isn't available on Linux, thus making the resulting request invalid. In this case, you could instead use the resolved_packages variable. used_request.py from rez.status import status # Use `status` to fetch an instance of ResolvedContext # from within our current environment. print ( \" \" . join([ \"%s==%s\" % (pkg . name, pkg . version) for pkg in status . context . requested_packages() ])) However this has a number of gotchas as well. For example, if the request was alita==1.1 maya==2018 you would expect the resulting resolve to be identical, no matter where or when it's called. It would even accommodate for the problem is Linux versus Windows variants. What it wouldn't do however is protect against later versions of indirectly required packages from getting picked up. For example. Artist launches Maya session with rez env alita==1.1 maya==2018 , resulting in [\"packageA-1.1\"] Shortly thereafter, Developer releases package-1.2 From the same Maya session, artist submits job to a remote computer The remote computer re-runs rez env alita==1.1 maya==2018 but this time gets [\"package-1.2\"] instead, resulting in a different environment than what was provided for the artist. One solution to this problem is including a time stamp. Alongside every resolve is a REZ_USED_TIMESTAMP environment variable which keeps track of when a request was resolved. If you include this in your re-resolve, you'll be more likely to get what was requested at that point in time elsewhere. rez env alita == 1 .1 maya == 2018 --time $env :REZ_USED_TIMESTAMP And presto, a cross-platform reproducible request! Conversation As you can tell, there are many ways to skin this cat. The following is a conversation about the various pros and cons and what to look out for. Slack Conversation Testing Packages Like any software projects, you need good tests. Software packaged with Rez is no exception, and doesn't necessarily change how you normally approach test. There are a few ways to exercise your package. Local Build and Run The most useful and common approach is to build and run your package locally. cd my_package rez build --install This will install the package into your local ~/packages directory, overridden by REZ_LOCAL_PACKAGES_PATH . From there, you can test a package as though it was deployed globally, until it's ready for an audience. rez build --install --release This command on the other hand installs a package into ~/.rez , overridden by REZ_RELEASE_PACKAGES_PATH . Test on Release The above is a good start, but it's still possible for bugs to make their way into a deployed package unless you have a solid test suite. cd my_package nosetests2 # Testing.. For a Python project, tests can be written as though Rez was not involved, using any relevant test framework. But having tests means nothing unless they are actually exercised, and that's when setting up a \"release hook\" can help maintain consistency. Work in progress If you got this far, and know more or want more, feel free to submit an issue . Hidden Applications Allzpark serves two audiences - artists and developers. Developers want more customisation and control than the average artists, such as having additional debug or testing applications made available. To address both of these audiences, there is a toggle called \"Show Hidden Apps\" which enables the package author to expose application packages with hidden=True . maya_dev/package.py name = \"maya_dev\" version = \"2018.0\" build_command = False # This is it _data = { \"hidden\" : True, } Now when this application is associated with a project, it is hidden per default, unless.. All Applications Each project specifies what applications to make available to the artist and developer. But sometimes, you don't care about that and just want to run Application X in a particular project environment. Work in progress If you got this far, and know more or want more, feel free to submit an issue . Opt-out Environment Per default, the parent environment is inherited by a Rez context, unless one or more packages reference it internally. $env :MY_PATH = \"path1;path2\" rez env > $env :MY_PATH # path1;path2 Note the inheritance there. However, if any package references MY_PATH then it will automatically clear itself prior to being re-added by the package. package.py name = \"my_package\" version = \"1.0\" def commands (): env[ \"MY_PATH\" ] . append( \"path1\" ) # Clearing existing PATH If we include this package, the variable now looks like this. rez env my_package > $env :MY_PATH # path1 This is considered a bug in the underlying bleeding-rez library, and is being addressed here. See also https://github.com/mottosso/bleeding-rez/issues/70 Graph Allzpark is able to visualise a resolved context as a graph. Prerequisities In order to enable graph drawing, you need the following package(s). graphviz-2+ Usage To make Allzpark aware of graphviz , simply include it in your request prior to launching. rez env graphviz pyside2 python-3 bleeding_rez -- python -m allzpark Localisation Users are able to interactively localize packages from the Packages tab, to save on performance or to work offline. Prerequisities In order to enable localization, you'll need the following package(s). localz-1+ Usage Make Allzpark aware of localz by including it in your request. rez env localz pyside2 python3 bleeding_rez -- python -m allzpark Allzpark Performance Considerations Use of the Allzpark can be divided into roughly three parts. Time taken to load libraries such as PySide2 - you should be seeing timings in the console Can be resolved by localizing packages, primarily python and PySide Time taken to get the window open Is actual building of the Allzpark and difficult to avoid Time taken to when applications, like Maya, actually show up This is the actual Rez resolves taking place. It will vary depending on whether the contexts can be found in memcached or not, which is about 90% of the time. From there most things are stored in-memory and won't perform many if any IO or CPU intensive calls, with a few exceptions like generating the resolve graph in the Context tab.","title":"Reference"},{"location":"reference/#allzparkconfigpy","text":"Configure allzpark using the allzparkconfig.py , which it will look for in these three locations, first one found wins. Your home directory, e.g. ~/allzparkonfig.py Passed via command-line, e.g. allzpark --config-file path/to/allzparkconfig.py Or the environment, ALLZPARK_CONFIG_FILE=/full/path/to/allzparkconfig.py All available keys and their default values can be found here. allzparkconfig.py And an example can be found here: rez-for-projects","title":"allzparkconfig.py"},{"location":"reference/#styling","text":"All of the Allzpark graphical user interface can be styled interactively using CSS. Custom styles are stored on the local machine, and can be shared and saved with copy/paste over e.g. chat or email. See style.css for examples and documentation","title":"Styling"},{"location":"reference/#naming-convention","text":"Requests are split between name<operator><version> Where <operator> is e.g. - or == or >= And <version> is an alphanumeric string, e.g. 1.0 or latest or 2.b2 Example rez env my_package-1 # package `my_package`, version `1` or above rez env my-package-1 # package `my`, version `package-1` or above rez env my_package_1 # package `my_package_1`, latest version rez env my_package == 1 # package `my_package_1`, version `1` exactly See wiki for details.","title":"Naming Convention"},{"location":"reference/#automatic-environment-variables","text":"Every package part of a resolve is given a series of environment variables. REZ_(PKG)_BASE REZ_(PKG)_ROOT REZ_(PKG)_VERSION REZ_(PKG)_MAJOR_VERSION REZ_(PKG)_MINOR_VERSION REZ_(PKG)_PATCH_VERSION You can reference these from other packages, using the {env.NAME} notation, where env refers to the system environment, prior to packages having an effect. Example # package.py name = \"my_package\" version = \"1.0\" requires = [ \"my_package-1.0\" ] def commands (): global env env[ \"MY_VARIABLE\" ] = r\"c:\\path\\{env.REZ_MY_PACKAGE_VERSION}\\scripts\" See wiki for details.","title":"Automatic Environment Variables"},{"location":"reference/#platform-specific-packages","text":"A package can target a given platform using \"variants\". my_package/package.py name = \"my_package\" version = \"1.0\" build_command = False variants = [ [ \"platform-windows\" ], [ \"platform-linux\" ], ] Requesting this package on windows would result in a version specific to Windows, and likewise for Linux. Building of this package happens twice ; once per \"variant\".","title":"Platform Specific Packages"},{"location":"reference/#building-per-platform","text":"$ cd my_package $ rez build Building variant 0 ( 1 /2 ) ... Invoking custom build system... Building variant 0 ( 2 /2 ) ... The following package conflicts occurred: ( platform-linux <--!--> ~platform == windows ) Since you cannot build a Linux package from Windows, nor vice versa, you can specify which variant to build using the --variants argument. $ rez build --variants 0 Where 0 indicates the 0 th index in the package.py:variants = [] list. See wiki for details See rez build --help for details","title":"Building Per Platform"},{"location":"reference/#options","text":"You can reference any package and version as a variant, but generally you'll only need the platform specific ones, which come defined in rezconfig.py per default. rezconfig.py implicit_packages = [ \"~platform=={system.platform}\" , \"~arch=={system.arch}\" , \"~os=={system.os}\" , ] See rez config implicit_packages for available options along with their values. rez config implicit_packages - ~platform == windows - ~arch == AMD64 - ~os == windows-10","title":"Options"},{"location":"reference/#multiple-application-versions","text":"Applications such as Python, Autodesk Maya and Adobe Photoshop can get packaged in one of two ways. maya-2018.1.0 i.e. \"Serial\" maya2018-1.0 i.e. \"Parallel\" Let's refer to these as \"serial\" and \"parallel\" respectively. Which should you use, and why?","title":"Multiple Application Versions"},{"location":"reference/#uniform","text":"In this example, there is only one package \"family\" for the Autodesk Maya software, whereby every revision of Maya is released as a new Rez package version; including \"service packs\" and \"hotfixes\" etc. The advantage is that a package can then create a requirement on a range of maya versions. name = \"mgear\" version = \"1.0.0\" requires = [ \"maya>=2015,<2020\" ] The disadvantage however is that you cannot resolve an environment with both maya-2018 and maya-2019 , as one would conflict with the other. Furthermore, if you did force this resolve, what should you expect to have happen in a situation like this? $ rez env python-2 python-3 > $ python --version Python ?.?.?","title":"Uniform"},{"location":"reference/#parallel","text":"Conversely, you can perform a \"parallel\" version. maya2018/package.py name = \"maya2018\" version = \"1.0\" maya2019/package.py name = \"maya2019\" version = \"1.0\" In which case you are able to resolve an environment like this. $ rez env maya2018 maya2019-1.0 > $ To work around the aforementioned issue of knowing which python - or in this case maya - is actually called, you can use an alias() . maya2019/package.py name = \"maya2019\" version = \"1.0\" def commands (): global alias alias( \"maya2019\" , \"{root}/bin/maya.exe\" ) At which point you can call.. $ rez env maya2018 maya2019 > $ maya2018 # Launching Maya 2018.. However it isn't clear how you can make a requirement on a range of Maya versions with a parallel package. Consider the mgear package. mgear/package.py name = \"mgear\" version = \"1.0\" requires = [ \"maya2018-1.0\" ] # What about Maya 2019? :( Rez currently does not support optional or \"any\"-style packages and so this approach would not be well suited for these types of requirements.","title":"Parallel"},{"location":"reference/#packages-and-version-control","text":"Work in progress If you got this far, and know more or want more, feel free to submit an issue .","title":"Packages and Version Control"},{"location":"reference/#release-with-gitlab","text":"Once you've created a package, it's often a good idea to version control it. mkdir my_package cd my_package echo \"name = `\" my_package `\" \" >> package.py echo \"version = `\" 1.0.0 `\" \" >> package.py echo \"build_command = False\" >> package.py git init git add --all git commit -m \"Initial version\" git remote add-url https : //gitlab.mycompany.com/username/my_package.git git push Next we'll configure GitLab to release a package alongside a new tag being made. .gitlab-ci.yml release: environment: - REZ_CONFIG_FILE=/packages/rezconfig.py script: - rez build --release only: - tags Work in progress If you got this far, and know more or want more, feel free to submit an issue .","title":"Release with GitLab"},{"location":"reference/#multiple-packages-in-a-single-git-repository","text":"Sometimes, dedicating a Git repository or GitLab project for every package is too heavy-handed. Sometimes you have many small packages that all need version control, but not necessarily independently, such as project packages. In this example, we'll create a Git repository containing 3 projects. Alita Spiderman Hulk These projects are all released as individual Rez packages, but are managed in one Git repository. mkdir my_projects cd my_projects mkdir alita mkdir spiderman mkdir hulk Create a package.py in each project subdirectory, with something along the lines of: name = \"alita\" version = \"1.0.0\" build_command = False Now we can commit and push these to, for example, your locally hosted GitLab instance. git init git add --all git commit -m \"Initial version\" git remote add-url https://gitlab.mycompany.com/username/my_projects.git git push When it's time to release, simply cd into a package of interest, and --release . cd alita rez build --install --release --clean","title":"Multiple Packages in a Single Git Repository"},{"location":"reference/#render-on-farm","text":"Typically, a context is resolved locally and work performed therein, and then further computation is submitted to a remote destination, such as a \"render farm\" or distributed compute network. In this case, it can be necessary to replicate a context remotely, in exactly the same configuration as locally. But, you cannot assume: Where packages are stored, because a remote computer may have different mount points What OS the remote destination is running, because it may be e.g. Windows or Linux","title":"Render on Farm"},{"location":"reference/#raw-environment","text":"Because of the above, simply saving the environment as-is and restoring it elsewhere is rarely enough. import os import json # Not enough.. with open( \"environment.json\" , \"w\" ) as f: json . dump(f, dict(os . environ))","title":"Raw Environment"},{"location":"reference/#rxt","text":"You may consider storing the resolved context to a file, for example.. rez env packageA packageB --output context.rxt # Machine A rez env --input context.rxt # Machine B Alternatively.. rez env packageA packageB > Get-Content $env :REZ_RXT_FILE > context.rxt > exit rez env --input context.rxt But an exported context embeds absolute paths to where packages can be found, which may not be true on the remote end - such as a local render farm or remote cloud.","title":"RXT"},{"location":"reference/#rez_used_resolve","text":"In this case, you may consider exporting the exact request, like this. rez env packageA packageB --exclude *.beta > $env :REZ_USED_RESOLVE # packageA-2.33.3 packageB-5.12.3 However this may not be precise enough. The - indicator locks the included parts of a version, such as 5.12.3 , but doesn't exclude the possibility of a 5.12.3.beta package, which takes precendence over 5.12.3 . rez env packageA-2.33.3 packageB-5.12.3 > $env :REZ_USED_RESOLVE # packageA-2.33.3 packageB-5.12.3.beta Notice the .beta towards the end. Here's another example. rez env packageA # packageA-1.0.0.beta rez env packageA-1.0.0 # packageA-1.0.0.beta rez env packageA-1.0.0.beta # packageA-1.0.0.beta For that reason, passing REZ_USED_RESOLVE to rez env may not be enough to accurately reproduce a given environment.","title":"REZ_USED_RESOLVE"},{"location":"reference/#inherit-filter","text":"So then what you could do, is pass along whatever filer you used to the remote end. Local rez env packageA packageB --exclude *.beta -- echo $env :REZ_USED_RESOLVE # packageA-2.33.3 packageB-5.12.3 Remote rez env packageA-2.33.3 packageB-5.12.3 --exclude *.beta And presto, an identical environment.. but wait! What about --patch ed environments. rez env packageA packageB --exclude *.beta > rez env packageB-5.12.3.beta >> $env :REZ_USED_RESOLVE # packageA-2.33.3 packageB-5.12.3.beta Now the final \"used resolve\" is incompatible with this filter, as --exclude *.beta would hide the beta version of packageB , resulting in.. 12 :18:12 ERROR PackageNotFoundError: Package could not be found: packageB == 5 .12.3.beta","title":"Inherit Filter"},{"location":"reference/#resolved_packages","text":"So what is the solution? In a nutshell.. Resolve a context Serialise ResolvedContext.resolved_packages to {name}=={version} used_resolve.py from rez.status import status # Use `status` to fetch an instance of ResolvedContext # from within our current environment. print ( \" \" . join([ \"%s==%s\" % (pkg . name, pkg . version) for pkg in status . context . resolved_packages ])) Resulting in.. rez env python packageA packageB --exclude *.beta -- python used_resolve.py # packageA==2.33.3 packageB==5.12.3 And presto, an accurate depiction of a given context, suitable for use again on the same machine, on a local render farm or remote cloud rendering environment.","title":"resolved_packages"},{"location":"reference/#requested_packages","text":"What that last method doesn't do however is guarantee that one resolve to work across platforms. Take this package for example. name = \"processmanager\" variants = [ [ \"platform-windows\" , \"win32all\" ], [ \"platform-linux\" , \"unix-process-tool\" ], ] On Windows, this would result in a list of resolved packages including win32all which isn't available on Linux, thus making the resulting request invalid. In this case, you could instead use the resolved_packages variable. used_request.py from rez.status import status # Use `status` to fetch an instance of ResolvedContext # from within our current environment. print ( \" \" . join([ \"%s==%s\" % (pkg . name, pkg . version) for pkg in status . context . requested_packages() ])) However this has a number of gotchas as well. For example, if the request was alita==1.1 maya==2018 you would expect the resulting resolve to be identical, no matter where or when it's called. It would even accommodate for the problem is Linux versus Windows variants. What it wouldn't do however is protect against later versions of indirectly required packages from getting picked up. For example. Artist launches Maya session with rez env alita==1.1 maya==2018 , resulting in [\"packageA-1.1\"] Shortly thereafter, Developer releases package-1.2 From the same Maya session, artist submits job to a remote computer The remote computer re-runs rez env alita==1.1 maya==2018 but this time gets [\"package-1.2\"] instead, resulting in a different environment than what was provided for the artist. One solution to this problem is including a time stamp. Alongside every resolve is a REZ_USED_TIMESTAMP environment variable which keeps track of when a request was resolved. If you include this in your re-resolve, you'll be more likely to get what was requested at that point in time elsewhere. rez env alita == 1 .1 maya == 2018 --time $env :REZ_USED_TIMESTAMP And presto, a cross-platform reproducible request!","title":"requested_packages"},{"location":"reference/#conversation","text":"As you can tell, there are many ways to skin this cat. The following is a conversation about the various pros and cons and what to look out for. Slack Conversation","title":"Conversation"},{"location":"reference/#testing-packages","text":"Like any software projects, you need good tests. Software packaged with Rez is no exception, and doesn't necessarily change how you normally approach test. There are a few ways to exercise your package.","title":"Testing Packages"},{"location":"reference/#local-build-and-run","text":"The most useful and common approach is to build and run your package locally. cd my_package rez build --install This will install the package into your local ~/packages directory, overridden by REZ_LOCAL_PACKAGES_PATH . From there, you can test a package as though it was deployed globally, until it's ready for an audience. rez build --install --release This command on the other hand installs a package into ~/.rez , overridden by REZ_RELEASE_PACKAGES_PATH .","title":"Local Build and Run"},{"location":"reference/#test-on-release","text":"The above is a good start, but it's still possible for bugs to make their way into a deployed package unless you have a solid test suite. cd my_package nosetests2 # Testing.. For a Python project, tests can be written as though Rez was not involved, using any relevant test framework. But having tests means nothing unless they are actually exercised, and that's when setting up a \"release hook\" can help maintain consistency. Work in progress If you got this far, and know more or want more, feel free to submit an issue .","title":"Test on Release"},{"location":"reference/#hidden-applications","text":"Allzpark serves two audiences - artists and developers. Developers want more customisation and control than the average artists, such as having additional debug or testing applications made available. To address both of these audiences, there is a toggle called \"Show Hidden Apps\" which enables the package author to expose application packages with hidden=True . maya_dev/package.py name = \"maya_dev\" version = \"2018.0\" build_command = False # This is it _data = { \"hidden\" : True, } Now when this application is associated with a project, it is hidden per default, unless..","title":"Hidden Applications"},{"location":"reference/#all-applications","text":"Each project specifies what applications to make available to the artist and developer. But sometimes, you don't care about that and just want to run Application X in a particular project environment. Work in progress If you got this far, and know more or want more, feel free to submit an issue .","title":"All Applications"},{"location":"reference/#opt-out-environment","text":"Per default, the parent environment is inherited by a Rez context, unless one or more packages reference it internally. $env :MY_PATH = \"path1;path2\" rez env > $env :MY_PATH # path1;path2 Note the inheritance there. However, if any package references MY_PATH then it will automatically clear itself prior to being re-added by the package. package.py name = \"my_package\" version = \"1.0\" def commands (): env[ \"MY_PATH\" ] . append( \"path1\" ) # Clearing existing PATH If we include this package, the variable now looks like this. rez env my_package > $env :MY_PATH # path1 This is considered a bug in the underlying bleeding-rez library, and is being addressed here. See also https://github.com/mottosso/bleeding-rez/issues/70","title":"Opt-out Environment"},{"location":"reference/#graph","text":"Allzpark is able to visualise a resolved context as a graph. Prerequisities In order to enable graph drawing, you need the following package(s). graphviz-2+ Usage To make Allzpark aware of graphviz , simply include it in your request prior to launching. rez env graphviz pyside2 python-3 bleeding_rez -- python -m allzpark","title":"Graph"},{"location":"reference/#localisation","text":"Users are able to interactively localize packages from the Packages tab, to save on performance or to work offline. Prerequisities In order to enable localization, you'll need the following package(s). localz-1+ Usage Make Allzpark aware of localz by including it in your request. rez env localz pyside2 python3 bleeding_rez -- python -m allzpark","title":"Localisation"},{"location":"reference/#allzpark-performance-considerations","text":"Use of the Allzpark can be divided into roughly three parts. Time taken to load libraries such as PySide2 - you should be seeing timings in the console Can be resolved by localizing packages, primarily python and PySide Time taken to get the window open Is actual building of the Allzpark and difficult to avoid Time taken to when applications, like Maya, actually show up This is the actual Rez resolves taking place. It will vary depending on whether the contexts can be found in memcached or not, which is about 90% of the time. From there most things are stored in-memory and won't perform many if any IO or CPU intensive calls, with a few exceptions like generating the resolve graph in the Context tab.","title":"Allzpark Performance Considerations"},{"location":"rez/","text":"Below you'll find a series of tutorials-by-example of increasing complexity, utilising more of Rez's functionality as we go, solving more and more specific problems. Basics Let's start with the basics. Shortest Possible Example Create and use a new package from scratch in under 40 seconds. powershell bash mkdir mypackage # Name of your Git project cd mypackage # Rez definition @\" name = \"mypackage\" # Rez package name version = \"1.0\" # Rez package version build_command = False # Called when building package \"@ | Out-File package.py rez build --install # Build package rez env mypackage # Use package > # A new environment with your package mkdir mypackage # Name of your Git project cd mypackage # Rez definition echo name = \"mypackage\" >> package.py # Rez package name echo version = \"1.0\" >> package.py # Rez package version echo build_command = False >> package.py # Called when building package rez build --install # Build package rez env mypackage # Use package > # A new environment with your package The > symbol means you are in a Rez \"context\". Type exit to exit the context. Environment Variables Most packages will modify their environment in some way. package.py name = \"mypackage\" version = \"1.1\" build_command = False def commands (): global env # Global variable available to `commands()` env[ \"MYVARIABLE\" ] = \"Yes\" This package will assign \"Yes\" to MYVARIABLE. env A global Python variable representing the environment env[\"MYVARIABLE\"] - An environment variable env.MYVARIABLE - This is also OK powershell bash rez build --install rez env mypackage > $env:MYVARIABLE # Yes rez build --install rez env mypackage > echo $MYVARIABLE # Yes Environment Paths A package can also modify paths, like PATH and PYTHONPATH , without removing what was there before. package.py name = \"mypackage\" version = \"1.2\" build_command = False def commands (): global env env[ \"PYTHONPATH\" ] . prepend( \"{root}\" ) env[ \"PYTHONPATH\" ] . prepend( \"{root}/python\" ) This package will assign \"{root}\" to PYTHONPATH . {root} expands to the absolute path to the installed package env[\"PYTHONPATH\"].prepend() - Prepend a value to this variable env[\"PYTHONPATH\"].append() - Append a value to this variable powershell bash rez build --install rez env mypackage > $env:PYTHONPATH # \\\\server\\packages\\mypackage\\1.2;\\\\server\\packages\\int\\mypackage\\1.2\\python rez build --install rez env mypackage > echo $PYTHONPATH # \\server\\packages\\mypackage\\1.2:\\server\\packages\\int\\mypackage\\1.2\\python Requirements Most packages will depend on another package. powershell bash cd mypackage cd .. mkdir mypackage2 $null >> mypackage2/package.py cd mypackage cd .. mkdir mypackage2 touch mypackage2/package.py mypackage2/package.py name = \"mypackage2\" version = \"1.0\" build_command = False requires = [ \"python-3\" , \"mypackage-1.2\" ] This package now requires python-3 and mypackage-1.2 . rez build --install rez env mypackage2 # resolved by manima@toy, on Thu Jun 27 11:12:18 2019, using Rez v2.32.1 # # requested packages: # mypackage2 # ~platform==windows (implicit) # ~arch==AMD64 (implicit) # ~os==windows-10.0.18362.SP0 (implicit) # # resolved packages: # arch-AMD64 C:\\Users\\manima\\packages\\arch\\AMD64 (local) # mypackage-1.3 C:\\Users\\manima\\packages\\mypackage\\1.3 (local) # mypackage2-1.0 C:\\Users\\manima\\packages\\mypackage2\\1.0 (local) # platform-windows C:\\Users\\manima\\packages\\platform\\windows (local) # python-3.7.3 C:\\Users\\manima\\packages\\python\\3.7.3\\platform-windows\\arch-AMD64 (local) > Payload Most packages will have additional files, such as Python modules. This is where build_command comes in. powershell bash cd mypackage $null >> install.py # Additional script for build mkdir python # Payload directory cd python # \"print('Hello World!')\" | Out-File mymodule.py # Python payload shipped alongside package cd mypackage touch install.py # Additional script for build mkdir python # Payload directory cd python # echo print ( \"Hello World!\" ) >> mymodule.py # Python payload shipped alongside package package.py name = \"mypackage\" version = \"1.3\" build_command = \"python {root}/install.py\" # Run this command on `rez build` requires = [ \"python-3\" ] def commands (): global env env[ \"PYTHONPATH\" ] . prepend( \"{root}/python\" ) # Add payload to environment install.py # This script is called on `rez build` import os import shutil print ( \"Running install.py...\" ) root = os . path . dirname(__file__) build_dir = os . environ[ \"REZ_BUILD_PATH\" ] install_dir = os . environ[ \"REZ_BUILD_INSTALL_PATH\" ] print ( \"Copying payload to %s..\" % build_dir) shutil . copytree( os . path . join(root, \"python\" ), os . path . join(build_dir, \"python\" ), ignore = shutil . ignore_patterns( \"*.pyc\" , \"__pycache__\" ) ) if int(os . getenv( \"REZ_BUILD_INSTALL\" )): # This part is called with `rez build --install` print ( \"Installing payload to %s...\" % install_dir) shutil . copytree( os . path . join(build_dir, \"python\" ), os . path . join(install_dir, \"python\" ), ) Now let's build it. rez build --install rez env mypackage > python -m mymodule # Hello World!","title":"Packaging"},{"location":"rez/#basics","text":"Let's start with the basics.","title":"Basics"},{"location":"rez/#shortest-possible-example","text":"Create and use a new package from scratch in under 40 seconds. powershell bash mkdir mypackage # Name of your Git project cd mypackage # Rez definition @\" name = \"mypackage\" # Rez package name version = \"1.0\" # Rez package version build_command = False # Called when building package \"@ | Out-File package.py rez build --install # Build package rez env mypackage # Use package > # A new environment with your package mkdir mypackage # Name of your Git project cd mypackage # Rez definition echo name = \"mypackage\" >> package.py # Rez package name echo version = \"1.0\" >> package.py # Rez package version echo build_command = False >> package.py # Called when building package rez build --install # Build package rez env mypackage # Use package > # A new environment with your package The > symbol means you are in a Rez \"context\". Type exit to exit the context.","title":"Shortest Possible Example"},{"location":"rez/#environment-variables","text":"Most packages will modify their environment in some way. package.py name = \"mypackage\" version = \"1.1\" build_command = False def commands (): global env # Global variable available to `commands()` env[ \"MYVARIABLE\" ] = \"Yes\" This package will assign \"Yes\" to MYVARIABLE. env A global Python variable representing the environment env[\"MYVARIABLE\"] - An environment variable env.MYVARIABLE - This is also OK powershell bash rez build --install rez env mypackage > $env:MYVARIABLE # Yes rez build --install rez env mypackage > echo $MYVARIABLE # Yes","title":"Environment Variables"},{"location":"rez/#environment-paths","text":"A package can also modify paths, like PATH and PYTHONPATH , without removing what was there before. package.py name = \"mypackage\" version = \"1.2\" build_command = False def commands (): global env env[ \"PYTHONPATH\" ] . prepend( \"{root}\" ) env[ \"PYTHONPATH\" ] . prepend( \"{root}/python\" ) This package will assign \"{root}\" to PYTHONPATH . {root} expands to the absolute path to the installed package env[\"PYTHONPATH\"].prepend() - Prepend a value to this variable env[\"PYTHONPATH\"].append() - Append a value to this variable powershell bash rez build --install rez env mypackage > $env:PYTHONPATH # \\\\server\\packages\\mypackage\\1.2;\\\\server\\packages\\int\\mypackage\\1.2\\python rez build --install rez env mypackage > echo $PYTHONPATH # \\server\\packages\\mypackage\\1.2:\\server\\packages\\int\\mypackage\\1.2\\python","title":"Environment Paths"},{"location":"rez/#requirements","text":"Most packages will depend on another package. powershell bash cd mypackage cd .. mkdir mypackage2 $null >> mypackage2/package.py cd mypackage cd .. mkdir mypackage2 touch mypackage2/package.py mypackage2/package.py name = \"mypackage2\" version = \"1.0\" build_command = False requires = [ \"python-3\" , \"mypackage-1.2\" ] This package now requires python-3 and mypackage-1.2 . rez build --install rez env mypackage2 # resolved by manima@toy, on Thu Jun 27 11:12:18 2019, using Rez v2.32.1 # # requested packages: # mypackage2 # ~platform==windows (implicit) # ~arch==AMD64 (implicit) # ~os==windows-10.0.18362.SP0 (implicit) # # resolved packages: # arch-AMD64 C:\\Users\\manima\\packages\\arch\\AMD64 (local) # mypackage-1.3 C:\\Users\\manima\\packages\\mypackage\\1.3 (local) # mypackage2-1.0 C:\\Users\\manima\\packages\\mypackage2\\1.0 (local) # platform-windows C:\\Users\\manima\\packages\\platform\\windows (local) # python-3.7.3 C:\\Users\\manima\\packages\\python\\3.7.3\\platform-windows\\arch-AMD64 (local) >","title":"Requirements"},{"location":"rez/#payload","text":"Most packages will have additional files, such as Python modules. This is where build_command comes in. powershell bash cd mypackage $null >> install.py # Additional script for build mkdir python # Payload directory cd python # \"print('Hello World!')\" | Out-File mymodule.py # Python payload shipped alongside package cd mypackage touch install.py # Additional script for build mkdir python # Payload directory cd python # echo print ( \"Hello World!\" ) >> mymodule.py # Python payload shipped alongside package package.py name = \"mypackage\" version = \"1.3\" build_command = \"python {root}/install.py\" # Run this command on `rez build` requires = [ \"python-3\" ] def commands (): global env env[ \"PYTHONPATH\" ] . prepend( \"{root}/python\" ) # Add payload to environment install.py # This script is called on `rez build` import os import shutil print ( \"Running install.py...\" ) root = os . path . dirname(__file__) build_dir = os . environ[ \"REZ_BUILD_PATH\" ] install_dir = os . environ[ \"REZ_BUILD_INSTALL_PATH\" ] print ( \"Copying payload to %s..\" % build_dir) shutil . copytree( os . path . join(root, \"python\" ), os . path . join(build_dir, \"python\" ), ignore = shutil . ignore_patterns( \"*.pyc\" , \"__pycache__\" ) ) if int(os . getenv( \"REZ_BUILD_INSTALL\" )): # This part is called with `rez build --install` print ( \"Installing payload to %s...\" % install_dir) shutil . copytree( os . path . join(build_dir, \"python\" ), os . path . join(install_dir, \"python\" ), ) Now let's build it. rez build --install rez env mypackage > python -m mymodule # Hello World!","title":"Payload"},{"location":"shells/","text":"Rez provides support for a number of shells on Windows, Linux and MacOS. Each of which operate almost identically, some having their own special powers. Supported shells Windows PowerShell cmd bash PowerShell On Windows, you'll likely want to use PowerShell. Note that \"Windows Powershell\" is different from PowerShell 6 and above which is cross-platform but not yet supported by Rez. Aliases are created as function () Resources Scoop Package Manager Why PowerShell Getting Started PowerShell Masterclass Process Management PowerShell, like Python, works with objects rather than text like cmd and bash . PS> $fx = get-process -name firefox PS> $fx.path # C:\\Program Files\\Mozilla Firefox\\firefox.exe PS> $fx.workingset / 1mb # 414.23828125 PS> $fx.kill() Aliases PS> ls # # Directory: C:\\Users\\marcus\\.ssh # # Mode LastWriteTime Length Name # ---- ------------- ------ ---- # -a---- 11/02/2018 15:52 1766 id_rsa # -a---- 18/02/2018 11:30 1486 id_rsa.ppk # -a---- 11/02/2018 15:52 392 id_rsa.pub # -a---- 18/03/2019 08:05 3514 known_hosts PS> get-alias clear # CommandType Name Version Source # ----------- ---- ------- ------ # Alias cls -> Clear-Host Working with processes Get-Member is akin to Python's dir() . PS> $notepad = start-process notepad -passthru PS> $notepad | get-member # TypeName: System.Diagnostics.Process # # Name MemberType Definition # ---- ---------- ---------- # ... # Name AliasProperty Name = ProcessName # Company ScriptProperty System.Object Company # {get=$this.Mainmodule.FileVersionInfo.CompanyName;} # ... # Path ScriptProperty System.Object Path {get=$this.Mainmodule.FileName;} # WorkingSet Property int WorkingSet {get;} # Kill Method void Kill() # Refresh Method void Refresh() # Start Method bool Start() # ToString Method string ToString() # ... PS> $notepad.company # Microsoft Corporation .bashrc on PowerShell Also found out that PowerShell has a startup script like Bash does; that's amazing. It means you can store not just environment variables \"globally\" but also functions and aliases like with Bash. PS> $profile # C:\\Users\\marcus\\Documents\\WindowsPowerShell\\Microsoft.PowerShell_profile.ps1 PS> echo 'set-alias -name eco -value echo' >> $profile Run with double-click Normally, .ps1 scripts, unlike .bat , open with notepad. Here's how you can change that. This time you do need to be admin, unless there's another variable for the local user? PS> reg add \"HKEY_CLASSES_ROOT\\Microsoft.PowerShellScript.1\\Shell\\Open\\Command\" /d \"\\ `\" C:\\Windows\\System32\\WindowsPowerShell\\v1.0\\powershell.exe\\ `\" -noLogo -ExecutionPolicy unrestricted -file \\ `\" %1\\ `\" \" # Value exists, overwrite(Yes/No)? yes # The operation completed successfully. The interesting bit being ExecutionPolicy unrestricted . Running PS scripts are not allowed per default on Windows. You can either allow it per invokation like this, or globally like this: Set-ExecutionPolicy unrestricted -scope CurrentUser Commands to variables Like Bash, the result of a command can be passed to a variable. PS> $cd = \" $(pwd) \" This example is particularly important, as $(pwd) in Bash returns a string (Bash doesn't have types) whereas in PS it returns an object. Wrapping it in \" is akin to str() in that it converts the object to its string representation. $ mkdir temp $ cd \" $(pwd) \\temp\" The cool thing about an object is that it's got properties and methods. :) PS> $(pwd) | Get-Member # # TypeName: System.Management.Automation.PathInfo # # Name MemberType Definition # ---- ---------- ---------- # Equals Method bool Equals(System.Object obj) # GetHashCode Method int GetHashCode() # GetType Method type GetType() # ToString Method string ToString() # Drive Property System.Management.Automation.PSDriveInfo Drive {get;} # Path Property string Path {get;} # Provider Property System.Management.Automation.ProviderInfo Provider {get;} # ProviderPath Property string ProviderPath {get;} Undo/Redo Yes, ctrl+z/ctrl+y works on the command-line, similar to a text-editor. Ctrl+Space You can list commands from a partial entry with ctrl+space. Send to Clipboard PS> get-process | clip And ctrl+v to paste. Navigate registry and environment like files Apparently, PS doesn't distinguish between what is a filesystem and what is an environment or registry, each referred to as a \"drive\". PS> cd c : PS> cd hkcu : PS> cd env : PS> pwd Path ---- Env : \\ PS> Get-PSDrive Name Used (GB) Free (GB) Provider Root ---- --------- --------- -------- ---- Alias Alias C 460.97 13.79 FileSystem C : \\ Cert Certificate \\ Env Environment Function Function HKCU Registry HKEY_CURRENT_USER HKLM Registry HKEY_LOCAL_MACHINE Variable Variable WSMan WSMan Get startup environment from running process PS> $maya = get-process -name maya PS> $si = $maya.startupinfo PS> $si.environment[ \"PATH\" ] C : \\Program Files\\Docker\\Docker\\Resources\\bin;C : \\WINDOWS\\system32;C : \\WINDOWS;C : \\WINDOWS\\System32\\Wbem;C : \\WINDOWS\\System32\\WindowsPowerShell\\v1.0\\;C : \\Program Files\\Git\\cmd;C : \\Program Files\\Git\\mingw64\\bin;C : \\Program Files\\Git\\usr\\bin;C : \\WINDOWS\\System32\\OpenSSH\\ cmd Things to be aware of when using Rez with cmd . Long Environment Variables cmd.exe is both familiar and available on every Windows machine dating back to Windows 95. It does however suffer from one major limitation; environment variables are limited in length to 2,000 characters . It isn't quite as simple as that, as there is a limit in the Windows API, another limit in conhost.exe and yet another in cmd.exe . When using Rez with cmd.exe , it is this limit you must take into consideration, and it is the most limiting of them all. Why does the cmd.exe limit apply? It's because whenever you execute_shell or enter into a context using rez env , Rez is creating a .bat script with a series of commands that look like this. set PATH = c: \\s ome \\p ath ; %PATH% set PATH = c: \\s ome \\o ther \\p ath ; %PATH% set PATH = c: \\y et \\a nother \\p ath ; %PATH% ... With one line of set for every call to env from within your package.py:commands() function. And this is where the problem lies, for you see launching cmd with a environment containing values longer than 2,000 characters work fine. import subprocess subprocess . Popen( \"cmd\" , env = { \"a\" : \"really\" , \"long\" : \"environment\" }) # Works But cmd.exe itself has issues handling anything longer than 2,000 characters which is why one of those lines of set will eventually stop growing. Command-line history A normal Rez context generates a deep process hierarchy . Under normal circumstances, Rez is made available as rez.exe , generated by pip install into a virtual environment. This executable calls another executable python.exe from that same install Which in turn calls the parent Python process from which your virtual environment was made, e.g. c:\\python37\\python.exe From here, Rez instantiates your REZ_DEFAULT_SHELL , e.g. cmd That's 4 layers of processes, one calling the next. It just so happens that 4 is the default number of buffers the windows ConHost.exe is configured to keep track of, which means that when you launch a 5 th layer you lose history. To account for this, configure your shell to keep track of 5 or more buffers. Alias The use of alias() in packages with cmd.exe has a few quicks worth considering. Utilises doskey , which works similar to alias on Linux Does not work with rez env -- arbitrary command Does not carry across shell, e.g. start Does not respect cmd.exe scope, e.g. cmd /Q /K doskey python=c:\\python27\\python.exe $* affects parent too bash The default shell on Linux and MacOS. Aliases are created as function()","title":"Shells"},{"location":"shells/#powershell","text":"On Windows, you'll likely want to use PowerShell. Note that \"Windows Powershell\" is different from PowerShell 6 and above which is cross-platform but not yet supported by Rez. Aliases are created as function () Resources Scoop Package Manager Why PowerShell Getting Started PowerShell Masterclass","title":"PowerShell"},{"location":"shells/#process-management","text":"PowerShell, like Python, works with objects rather than text like cmd and bash . PS> $fx = get-process -name firefox PS> $fx.path # C:\\Program Files\\Mozilla Firefox\\firefox.exe PS> $fx.workingset / 1mb # 414.23828125 PS> $fx.kill()","title":"Process Management"},{"location":"shells/#aliases","text":"PS> ls # # Directory: C:\\Users\\marcus\\.ssh # # Mode LastWriteTime Length Name # ---- ------------- ------ ---- # -a---- 11/02/2018 15:52 1766 id_rsa # -a---- 18/02/2018 11:30 1486 id_rsa.ppk # -a---- 11/02/2018 15:52 392 id_rsa.pub # -a---- 18/03/2019 08:05 3514 known_hosts PS> get-alias clear # CommandType Name Version Source # ----------- ---- ------- ------ # Alias cls -> Clear-Host","title":"Aliases"},{"location":"shells/#working-with-processes","text":"Get-Member is akin to Python's dir() . PS> $notepad = start-process notepad -passthru PS> $notepad | get-member # TypeName: System.Diagnostics.Process # # Name MemberType Definition # ---- ---------- ---------- # ... # Name AliasProperty Name = ProcessName # Company ScriptProperty System.Object Company # {get=$this.Mainmodule.FileVersionInfo.CompanyName;} # ... # Path ScriptProperty System.Object Path {get=$this.Mainmodule.FileName;} # WorkingSet Property int WorkingSet {get;} # Kill Method void Kill() # Refresh Method void Refresh() # Start Method bool Start() # ToString Method string ToString() # ... PS> $notepad.company # Microsoft Corporation","title":"Working with processes"},{"location":"shells/#bashrc-on-powershell","text":"Also found out that PowerShell has a startup script like Bash does; that's amazing. It means you can store not just environment variables \"globally\" but also functions and aliases like with Bash. PS> $profile # C:\\Users\\marcus\\Documents\\WindowsPowerShell\\Microsoft.PowerShell_profile.ps1 PS> echo 'set-alias -name eco -value echo' >> $profile","title":".bashrc on PowerShell"},{"location":"shells/#run-with-double-click","text":"Normally, .ps1 scripts, unlike .bat , open with notepad. Here's how you can change that. This time you do need to be admin, unless there's another variable for the local user? PS> reg add \"HKEY_CLASSES_ROOT\\Microsoft.PowerShellScript.1\\Shell\\Open\\Command\" /d \"\\ `\" C:\\Windows\\System32\\WindowsPowerShell\\v1.0\\powershell.exe\\ `\" -noLogo -ExecutionPolicy unrestricted -file \\ `\" %1\\ `\" \" # Value exists, overwrite(Yes/No)? yes # The operation completed successfully. The interesting bit being ExecutionPolicy unrestricted . Running PS scripts are not allowed per default on Windows. You can either allow it per invokation like this, or globally like this: Set-ExecutionPolicy unrestricted -scope CurrentUser","title":"Run with double-click"},{"location":"shells/#commands-to-variables","text":"Like Bash, the result of a command can be passed to a variable. PS> $cd = \" $(pwd) \" This example is particularly important, as $(pwd) in Bash returns a string (Bash doesn't have types) whereas in PS it returns an object. Wrapping it in \" is akin to str() in that it converts the object to its string representation. $ mkdir temp $ cd \" $(pwd) \\temp\" The cool thing about an object is that it's got properties and methods. :) PS> $(pwd) | Get-Member # # TypeName: System.Management.Automation.PathInfo # # Name MemberType Definition # ---- ---------- ---------- # Equals Method bool Equals(System.Object obj) # GetHashCode Method int GetHashCode() # GetType Method type GetType() # ToString Method string ToString() # Drive Property System.Management.Automation.PSDriveInfo Drive {get;} # Path Property string Path {get;} # Provider Property System.Management.Automation.ProviderInfo Provider {get;} # ProviderPath Property string ProviderPath {get;}","title":"Commands to variables"},{"location":"shells/#undoredo","text":"Yes, ctrl+z/ctrl+y works on the command-line, similar to a text-editor.","title":"Undo/Redo"},{"location":"shells/#ctrlspace","text":"You can list commands from a partial entry with ctrl+space.","title":"Ctrl+Space"},{"location":"shells/#send-to-clipboard","text":"PS> get-process | clip And ctrl+v to paste.","title":"Send to Clipboard"},{"location":"shells/#navigate-registry-and-environment-like-files","text":"Apparently, PS doesn't distinguish between what is a filesystem and what is an environment or registry, each referred to as a \"drive\". PS> cd c : PS> cd hkcu : PS> cd env : PS> pwd Path ---- Env : \\ PS> Get-PSDrive Name Used (GB) Free (GB) Provider Root ---- --------- --------- -------- ---- Alias Alias C 460.97 13.79 FileSystem C : \\ Cert Certificate \\ Env Environment Function Function HKCU Registry HKEY_CURRENT_USER HKLM Registry HKEY_LOCAL_MACHINE Variable Variable WSMan WSMan","title":"Navigate registry and environment like files"},{"location":"shells/#get-startup-environment-from-running-process","text":"PS> $maya = get-process -name maya PS> $si = $maya.startupinfo PS> $si.environment[ \"PATH\" ] C : \\Program Files\\Docker\\Docker\\Resources\\bin;C : \\WINDOWS\\system32;C : \\WINDOWS;C : \\WINDOWS\\System32\\Wbem;C : \\WINDOWS\\System32\\WindowsPowerShell\\v1.0\\;C : \\Program Files\\Git\\cmd;C : \\Program Files\\Git\\mingw64\\bin;C : \\Program Files\\Git\\usr\\bin;C : \\WINDOWS\\System32\\OpenSSH\\","title":"Get startup environment from running process"},{"location":"shells/#cmd","text":"Things to be aware of when using Rez with cmd .","title":"cmd"},{"location":"shells/#long-environment-variables","text":"cmd.exe is both familiar and available on every Windows machine dating back to Windows 95. It does however suffer from one major limitation; environment variables are limited in length to 2,000 characters . It isn't quite as simple as that, as there is a limit in the Windows API, another limit in conhost.exe and yet another in cmd.exe . When using Rez with cmd.exe , it is this limit you must take into consideration, and it is the most limiting of them all. Why does the cmd.exe limit apply? It's because whenever you execute_shell or enter into a context using rez env , Rez is creating a .bat script with a series of commands that look like this. set PATH = c: \\s ome \\p ath ; %PATH% set PATH = c: \\s ome \\o ther \\p ath ; %PATH% set PATH = c: \\y et \\a nother \\p ath ; %PATH% ... With one line of set for every call to env from within your package.py:commands() function. And this is where the problem lies, for you see launching cmd with a environment containing values longer than 2,000 characters work fine. import subprocess subprocess . Popen( \"cmd\" , env = { \"a\" : \"really\" , \"long\" : \"environment\" }) # Works But cmd.exe itself has issues handling anything longer than 2,000 characters which is why one of those lines of set will eventually stop growing.","title":"Long Environment Variables"},{"location":"shells/#command-line-history","text":"A normal Rez context generates a deep process hierarchy . Under normal circumstances, Rez is made available as rez.exe , generated by pip install into a virtual environment. This executable calls another executable python.exe from that same install Which in turn calls the parent Python process from which your virtual environment was made, e.g. c:\\python37\\python.exe From here, Rez instantiates your REZ_DEFAULT_SHELL , e.g. cmd That's 4 layers of processes, one calling the next. It just so happens that 4 is the default number of buffers the windows ConHost.exe is configured to keep track of, which means that when you launch a 5 th layer you lose history. To account for this, configure your shell to keep track of 5 or more buffers.","title":"Command-line history"},{"location":"shells/#alias","text":"The use of alias() in packages with cmd.exe has a few quicks worth considering. Utilises doskey , which works similar to alias on Linux Does not work with rez env -- arbitrary command Does not carry across shell, e.g. start Does not respect cmd.exe scope, e.g. cmd /Q /K doskey python=c:\\python27\\python.exe $* affects parent too","title":"Alias"},{"location":"shells/#bash","text":"The default shell on Linux and MacOS. Aliases are created as function()","title":"bash"},{"location":"windows/","text":"Both Allzpark and Rez are cross-platform, but each platform has a few gotchas to keep in mind. Here's a quick primer on how to make the most out of Allzpark and Rez on the Windows operating system. Long File Paths Windows has a max path length of 260 characters, which can become an issue for packages on a long repository path and multiple variants. Problem # Repository root \\\\ mylongstudioaddress.local \\m ain \\c ommon \\u tilities \\p ackages \\i nternal # Package \\m aya_essentials \\1 .42.5beta \\p latform-windows \\a rch-AMD64 \\o s-windows-10.0.1803 # Payload \\p ython \\m aya_essentials \\u tilities \\_ _init__.py 188 characters That's a relatively common path to a Python package, packaged with Rez, and we're already close to the 260 character limit. Now take backslashes into account, and that Python and friends escape those prior to using them. There are 16 backslashes in there, which adds another 16 characters. # Before \\l ong \\p ath # After \\\\ long \\\\ path 204 characters We still haven't changed the path, and yet the length has increased. Now take into account some libraries taking extra precautions and escapes even estaped backslashes. # Before \\\\ long \\\\ path # After \\\\\\\\ long \\\\\\\\ path That adds yet another 32 characters. 236 characters And again, we haven't changed our path, and yet this is what some tools will be working with, leaving you with very little room. Solution You've got at least three options here. Patch your paths Patch Rez Patch Windows Patch Paths The most straightforward, but likely difficult, thing to do is to avoid long paths altogether. Use a short hostname Use a short repository path Abbreviate Python libraries Don't use Python packages from PyPI with long names But a lot of this is not practical, and merely postpones the issue. Patch Rez I've investigated what it would take to make changes to Rez that facilitate longer paths, and found that there is a prefix you can use for paths that will \"force\" Windows to interpret paths longer than 260 characters. # Before c: \\l ong \\p ath.exe # After \\\\ ? \\c : \\l ong \\p ath.exe Since paths are entirely managed by Rez, it wouldn't be unreasonable to wrap any path creation call to prefix the results with \\\\?\\ if the user was running Windows. But I couldn't find a single-point-of-entry for these, as paths were generated all over the place. Rightly so; it would be borderline overengineering to wrap all calls to e.g. os.path.join or os.getcwd into a \"prefixer\" just for this occasion. It would however have helped in this particular case. Furthermore, this would only really apply to Windows 10 and above, since from what I gather this (poorly documented) feature is only available there; possibly related to this next feature. Patch Windows You wouldn't think this is an option, but it just might be. This technically doesn't count as patching Windows, but because we're changing a fundamental component of the OS - something each applications has till now taken for granted - it may cause all sorts of havok for applications that depend on the 260 character limit. Relevant comic https://xkcd.com/1172/ Since June 20 th 2017, users of Windows 10 1607 have had the ability to enable support for \"long paths\". # From an administrator PowerShell session Set-ItemProperty -Path HKLM : \\SYSTEM\\CurrentControlSet\\Control\\FileSystem -Name LongPathsEnabled -Value 1 -Type DWord This would effectively prepend \\\\?\\ to every path \"under the hood\", solving the issue. But at what cost? Let the community know if you encounter any issues by making an issue . Process Tree Virtualenv is one way of using Rez on Windows, and if you do then the rez.exe executable is generated during pip install and works by spawning a python.exe process, also generated by pip , which in turn calls on your system python.exe . Here's what spawning your own Python session from within a Rez context looks like. Maya and Quicktime Typically, playblasting to .mp4 or .mov with Maya requires a recent install of Quicktime on the local machine. Let's have a look at how to approach this with Rez. How does one approach this with Rez? Submit a PR today!","title":"Windows"},{"location":"windows/#long-file-paths","text":"Windows has a max path length of 260 characters, which can become an issue for packages on a long repository path and multiple variants.","title":"Long File Paths"},{"location":"windows/#problem","text":"# Repository root \\\\ mylongstudioaddress.local \\m ain \\c ommon \\u tilities \\p ackages \\i nternal # Package \\m aya_essentials \\1 .42.5beta \\p latform-windows \\a rch-AMD64 \\o s-windows-10.0.1803 # Payload \\p ython \\m aya_essentials \\u tilities \\_ _init__.py 188 characters That's a relatively common path to a Python package, packaged with Rez, and we're already close to the 260 character limit. Now take backslashes into account, and that Python and friends escape those prior to using them. There are 16 backslashes in there, which adds another 16 characters. # Before \\l ong \\p ath # After \\\\ long \\\\ path 204 characters We still haven't changed the path, and yet the length has increased. Now take into account some libraries taking extra precautions and escapes even estaped backslashes. # Before \\\\ long \\\\ path # After \\\\\\\\ long \\\\\\\\ path That adds yet another 32 characters. 236 characters And again, we haven't changed our path, and yet this is what some tools will be working with, leaving you with very little room.","title":"Problem"},{"location":"windows/#solution","text":"You've got at least three options here. Patch your paths Patch Rez Patch Windows Patch Paths The most straightforward, but likely difficult, thing to do is to avoid long paths altogether. Use a short hostname Use a short repository path Abbreviate Python libraries Don't use Python packages from PyPI with long names But a lot of this is not practical, and merely postpones the issue. Patch Rez I've investigated what it would take to make changes to Rez that facilitate longer paths, and found that there is a prefix you can use for paths that will \"force\" Windows to interpret paths longer than 260 characters. # Before c: \\l ong \\p ath.exe # After \\\\ ? \\c : \\l ong \\p ath.exe Since paths are entirely managed by Rez, it wouldn't be unreasonable to wrap any path creation call to prefix the results with \\\\?\\ if the user was running Windows. But I couldn't find a single-point-of-entry for these, as paths were generated all over the place. Rightly so; it would be borderline overengineering to wrap all calls to e.g. os.path.join or os.getcwd into a \"prefixer\" just for this occasion. It would however have helped in this particular case. Furthermore, this would only really apply to Windows 10 and above, since from what I gather this (poorly documented) feature is only available there; possibly related to this next feature. Patch Windows You wouldn't think this is an option, but it just might be. This technically doesn't count as patching Windows, but because we're changing a fundamental component of the OS - something each applications has till now taken for granted - it may cause all sorts of havok for applications that depend on the 260 character limit. Relevant comic https://xkcd.com/1172/ Since June 20 th 2017, users of Windows 10 1607 have had the ability to enable support for \"long paths\". # From an administrator PowerShell session Set-ItemProperty -Path HKLM : \\SYSTEM\\CurrentControlSet\\Control\\FileSystem -Name LongPathsEnabled -Value 1 -Type DWord This would effectively prepend \\\\?\\ to every path \"under the hood\", solving the issue. But at what cost? Let the community know if you encounter any issues by making an issue .","title":"Solution"},{"location":"windows/#process-tree","text":"Virtualenv is one way of using Rez on Windows, and if you do then the rez.exe executable is generated during pip install and works by spawning a python.exe process, also generated by pip , which in turn calls on your system python.exe . Here's what spawning your own Python session from within a Rez context looks like.","title":"Process Tree"},{"location":"windows/#maya-and-quicktime","text":"Typically, playblasting to .mp4 or .mov with Maya requires a recent install of Quicktime on the local machine. Let's have a look at how to approach this with Rez. How does one approach this with Rez? Submit a PR today!","title":"Maya and Quicktime"},{"location":"workflow/","text":"This page is dedicated to best practices for working with Rez and Allzpark. Development Workflow Whether you are writing a C++ or Python library, the general workflow goes something like this. Edit source Call rez build --install Reload library (e.g. Maya module or plug-in) Test the library Goto (1) until satisfied Where rez build --install operates in two steps. Create an internal build\\ directory with everything going into the installed package Copy the build\\ directory into your REZ_LOCAL_PACKAGES_PATH as the specified version This operation is destructive, in that it will overwrite what was already there. This is what allows you to keep rebuilding and testing your package, without having to increment the version for each line of source code changed. Release Workflow One of the strenghts of Rez is that, whilst Git enables you to version control changes to code, Rez enables version control released software onto the floor. Once you're happy with an update or newly created package, it's time to release it. cd my_package rez build --install --release This command will perform an identical operation to rez build --install , except packages written to REZ_RELEASE_PACKAGES_PATH . Like --install , this operation is destructive, and most of the time you wouldn't want released packages to change. There are at least two methods for preventing that, both of which involve the use of Git . Limit use of --release to a server-side application, like GitLab. For example, once your changes have been pushed and tagged, a CI pipeline could trigger a call to --release whereby the GitLab runner is the only one with write-access to the REZ_RELEASE_PACKAGES_PATH . Use rez release which does something similar, except locally. It creates a tag identical to the proposed package version, pushed it to the currently set up Git remote.","title":"Workflow"},{"location":"workflow/#development-workflow","text":"Whether you are writing a C++ or Python library, the general workflow goes something like this. Edit source Call rez build --install Reload library (e.g. Maya module or plug-in) Test the library Goto (1) until satisfied Where rez build --install operates in two steps. Create an internal build\\ directory with everything going into the installed package Copy the build\\ directory into your REZ_LOCAL_PACKAGES_PATH as the specified version This operation is destructive, in that it will overwrite what was already there. This is what allows you to keep rebuilding and testing your package, without having to increment the version for each line of source code changed.","title":"Development Workflow"},{"location":"workflow/#release-workflow","text":"One of the strenghts of Rez is that, whilst Git enables you to version control changes to code, Rez enables version control released software onto the floor. Once you're happy with an update or newly created package, it's time to release it. cd my_package rez build --install --release This command will perform an identical operation to rez build --install , except packages written to REZ_RELEASE_PACKAGES_PATH . Like --install , this operation is destructive, and most of the time you wouldn't want released packages to change. There are at least two methods for preventing that, both of which involve the use of Git . Limit use of --release to a server-side application, like GitLab. For example, once your changes have been pushed and tagged, a CI pipeline could trigger a call to --release whereby the GitLab runner is the only one with write-access to the REZ_RELEASE_PACKAGES_PATH . Use rez release which does something similar, except locally. It creates a tag identical to the proposed package version, pushed it to the currently set up Git remote.","title":"Release Workflow"}]}