{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Allzpark Powerful application launcher with reproducible software environments , for visual effects, feature animation and AAA-games productions. Learn more Download Blog Package Based Libraries, applications, projects.. package everything! Allzpark is a package-based launcher, which means that everything related to a project is encapsulated into individual, version controlled and dependency managed \"packages\" . Establish complex relationships between software, applications and projects with bleeding-rez , the underlying framework powering Allzpark . Dual Representation Allzpark is but a shell. Anything done via the GUI is available via the command-line, using standard Rez commands. $ rez env alita maya -q > $ echo \"Hello Rez!\" Hello Rez! Environment Management Preview the environment, prior to launching an application. Make changes interactively as you develop or debug complex dependency chains. Process Management Organise your many running processes in a compact way. Give each instance of Maya a unique name, group them, color them, bring-to-front and mass-kill instances to establish available memory in a hurry. Customisation Full theming support with pre-made color palettes to choose from. Interactively edit the underlying CSS and store them as your own. Drag panels around, establish a super-layout with everything visible at once. Allzpark Allzpark is free and open source (LGPL) Let's get this show on the road Learn more Download","title":"Home"},{"location":"about/","text":"This section outlines the rationale behind Allzpark, to help you determine whether or not it is of use to you. Story time When Hannah - working at ILM, Weta, MPC, Framestore, Goodbye Kansas or Double Negative - arrives at work in the morning, she typically types something like this into her console. go gravity maya What this does is put Hannah in the \"context\" of the gravity project. The subsequent call to maya then launches a given application, in this case Autodesk Maya. But which version? And why does it matter? A closer look To better understand what's happening here, let's take a closer look at what these commands do. Following the command go gravity , a few things happen. The argument gravity is correlated to a project (either on disk or database) The project is associated with metadata, detailing what software and versions are in use maya-2015 arnold-4.12 mgear-2.4 fbake-4.1 fasset-1.14 ... The associated software is loaded into command-line environment At this point, the subsequent command maya unambiguously refers to maya-2015 , which is how Framestore - and virtually every visual effects, feature animation, commercial and games facility - is able to tie a specific version of each set of software to a given project. Why is this important? The answer lies in interoperability . You see, whatever comes out of Hannah's department must interoperate with subsequent departments. Like an assembly line, the pace of the line remains consistent till the end, and every tool depends on the output of whatever came before it. This holds true for individual applications, like Maya or Visual Studio, but also sub-components of applications - plug-ins. Take arnold-4.12 as an example. This particular version needs to interoperate with maya-2015 . 2015 2016 2017 2018 2019 maya |--------------------------| arnold-1 |-------| arnold-2 |-----------| arnold-3 |-----------| arnold-4 |----------| In order to leverage maya-2015 for a given project, your choice of arnold is limited to those that support it, or vice versa. interoperable slice maya |-----------------|------|---| arnold-1 |-------| | | arnold-2 |-----------| | | arnold-3 |------|------| arnold-4 |-|------|---| | | This issue is compounded by the number of libraries and plug-ins you use for a given project. Consider openimageio , qt , ilmbase and other off-the-shelf projects you may want to employ in a given project, and you can start to get some idea of how narrow It is then further compounded by in-house development projects, such as your pipeline . None of this would have been a problem, if you were able to say: We will ever only work on a single project at a time We know which versions to use We don't develop any new software ourselves In which case you could simply install each of these applications and get to work. But more often than not, things change. And in order to facilitate this change, there needs to be a system in place to help manage the combinatorial complexity of applications, software, and projects.","title":"About"},{"location":"about/#story-time","text":"When Hannah - working at ILM, Weta, MPC, Framestore, Goodbye Kansas or Double Negative - arrives at work in the morning, she typically types something like this into her console. go gravity maya What this does is put Hannah in the \"context\" of the gravity project. The subsequent call to maya then launches a given application, in this case Autodesk Maya. But which version? And why does it matter?","title":"Story time"},{"location":"about/#a-closer-look","text":"To better understand what's happening here, let's take a closer look at what these commands do. Following the command go gravity , a few things happen. The argument gravity is correlated to a project (either on disk or database) The project is associated with metadata, detailing what software and versions are in use maya-2015 arnold-4.12 mgear-2.4 fbake-4.1 fasset-1.14 ... The associated software is loaded into command-line environment At this point, the subsequent command maya unambiguously refers to maya-2015 , which is how Framestore - and virtually every visual effects, feature animation, commercial and games facility - is able to tie a specific version of each set of software to a given project. Why is this important? The answer lies in interoperability . You see, whatever comes out of Hannah's department must interoperate with subsequent departments. Like an assembly line, the pace of the line remains consistent till the end, and every tool depends on the output of whatever came before it. This holds true for individual applications, like Maya or Visual Studio, but also sub-components of applications - plug-ins. Take arnold-4.12 as an example. This particular version needs to interoperate with maya-2015 . 2015 2016 2017 2018 2019 maya |--------------------------| arnold-1 |-------| arnold-2 |-----------| arnold-3 |-----------| arnold-4 |----------| In order to leverage maya-2015 for a given project, your choice of arnold is limited to those that support it, or vice versa. interoperable slice maya |-----------------|------|---| arnold-1 |-------| | | arnold-2 |-----------| | | arnold-3 |------|------| arnold-4 |-|------|---| | | This issue is compounded by the number of libraries and plug-ins you use for a given project. Consider openimageio , qt , ilmbase and other off-the-shelf projects you may want to employ in a given project, and you can start to get some idea of how narrow It is then further compounded by in-house development projects, such as your pipeline . None of this would have been a problem, if you were able to say: We will ever only work on a single project at a time We know which versions to use We don't develop any new software ourselves In which case you could simply install each of these applications and get to work. But more often than not, things change. And in order to facilitate this change, there needs to be a system in place to help manage the combinatorial complexity of applications, software, and projects.","title":"A closer look"},{"location":"examples/","text":"Learn Allzpark by example. This assumes you've already accumulated the knowledge from the guides chapter. Examples This page contains a series of solutions to specific problems. Command Shorthand Use rez env to establish a context, and --command to immediately run a command within that context. rez env --command= \"echo Hello\" Instead of using --command , you can also use -- . rez env -- echo Hello Note that you didn't need quotation marks or an = sign for this to work, and that it's a little easier on the eyes. We use this syntax extensively throughout this guide. External Packages With Rez you can package almost anything, but sometimes there are packages already made for you to benefit from. Install from PyPI Managing external projects is no fun unless you can benefit from what package authors in neighboring ecosystems have been working on. PyPI is such an ecosystem and you can install any package from PyPI as a Rez package using rez-pipz . git clone https://github.com/mottosso/rez-pipz.git cd rez-pipz rez build --install Here's how you use it. rez env pipz -- install six See rez-pipz for details. Install from Scoop Scoop is a package manager for Windows. It's akin to Chocolatey , except packages are portable and doesn't require adminstrative access, which makes it a perfect fit for Rez. git clone https://github.com/mottosso/rez-scoopz.git cd rez-scoopz rez build --install Here's how you use it. rez env scoopz -- install python See rez-scoopz for details. Windows Gotchas Here are a few things to keep in mind when working with Rez on Windows. Package version and Python Every package containing a payload typically involves two version numbers. Version of the package Version of the payload Preferably, these would always line up, but how can you expose the version of a package to Python? package.py name = \"my_library\" version = \"1.0\" my_library/python/my_library.py version = \"?\" 1. Package to Python What if Python was the one defining a version, and package.py picking this up instead? You certainly can, except it moves complexity away from your library and into your package.py , which is generally not a good idea. package.py Option 1, plain-text name = \"my_library\" with open( \"python\\my_library.py\" ) as f: for line in f: if line . startswith( \"version = \" ): _, version = line . rstrip() . split( \" = \" ) break This works, but makes a few fragile assumptions about how the version is formatted in the file. Option 2. import os name = \"my_library\" cwd = os . getcwd() os . chmod( \"python\" ) import my_library version = my_library . version This is a little ugly, but works. The assumption made is that whatever is being executed in the imported module doesn't have any side effects or negatively impacts performance. Some modules, for example, establish database connections or temporary directories on import. 2. Embedded This next approach addresses the above concerns in a more compact manner. In order to use a package, it must first be built. We can leverage this build step to modify a Python library and embed the package version. my_library/ init .py try : from . import __version__ version = __version__ . version except ImportError : version = \"dev\" At this point, version will read \"dev\" until the module __version__.py has been written into the library. We can write this file during build. package.py name = \"my_library\" version = \"1.0\" build_command = \"python {root}/install.py\" install.py import os import shutil root = os . path . dirname(__file__) build_dir = os . environ[ \"REZ_BUILD_PATH\" ] # Copy library shutil . copytree(os . path . join(root, \"my_library\" ), os . path . join(build_dir, \"my_library\" )) # Inject version version_fname = os . path . join(build_dir, \"my_library\" , \"__version__.py\" ) version = os . getenv( \"REZ_BUILD_PROJECT_VERSION\" ) with open(version_fname, \"w\" ) as f: f . write( \"version = \\\" %s \\\" \" % version) And there you go. Now the version will read \"dev\" unless the package has been built, in which case it would read \"1.0\" .","title":"Examples"},{"location":"examples/#examples","text":"This page contains a series of solutions to specific problems.","title":"Examples"},{"location":"examples/#command-shorthand","text":"Use rez env to establish a context, and --command to immediately run a command within that context. rez env --command= \"echo Hello\" Instead of using --command , you can also use -- . rez env -- echo Hello Note that you didn't need quotation marks or an = sign for this to work, and that it's a little easier on the eyes. We use this syntax extensively throughout this guide.","title":"Command Shorthand"},{"location":"examples/#external-packages","text":"With Rez you can package almost anything, but sometimes there are packages already made for you to benefit from.","title":"External Packages"},{"location":"examples/#install-from-pypi","text":"Managing external projects is no fun unless you can benefit from what package authors in neighboring ecosystems have been working on. PyPI is such an ecosystem and you can install any package from PyPI as a Rez package using rez-pipz . git clone https://github.com/mottosso/rez-pipz.git cd rez-pipz rez build --install Here's how you use it. rez env pipz -- install six See rez-pipz for details.","title":"Install from PyPI"},{"location":"examples/#install-from-scoop","text":"Scoop is a package manager for Windows. It's akin to Chocolatey , except packages are portable and doesn't require adminstrative access, which makes it a perfect fit for Rez. git clone https://github.com/mottosso/rez-scoopz.git cd rez-scoopz rez build --install Here's how you use it. rez env scoopz -- install python See rez-scoopz for details.","title":"Install from Scoop"},{"location":"examples/#windows-gotchas","text":"Here are a few things to keep in mind when working with Rez on Windows.","title":"Windows Gotchas"},{"location":"examples/#package-version-and-python","text":"Every package containing a payload typically involves two version numbers. Version of the package Version of the payload Preferably, these would always line up, but how can you expose the version of a package to Python? package.py name = \"my_library\" version = \"1.0\" my_library/python/my_library.py version = \"?\"","title":"Package version and Python"},{"location":"examples/#1-package-to-python","text":"What if Python was the one defining a version, and package.py picking this up instead? You certainly can, except it moves complexity away from your library and into your package.py , which is generally not a good idea. package.py Option 1, plain-text name = \"my_library\" with open( \"python\\my_library.py\" ) as f: for line in f: if line . startswith( \"version = \" ): _, version = line . rstrip() . split( \" = \" ) break This works, but makes a few fragile assumptions about how the version is formatted in the file. Option 2. import os name = \"my_library\" cwd = os . getcwd() os . chmod( \"python\" ) import my_library version = my_library . version This is a little ugly, but works. The assumption made is that whatever is being executed in the imported module doesn't have any side effects or negatively impacts performance. Some modules, for example, establish database connections or temporary directories on import.","title":"1. Package to Python"},{"location":"examples/#2-embedded","text":"This next approach addresses the above concerns in a more compact manner. In order to use a package, it must first be built. We can leverage this build step to modify a Python library and embed the package version. my_library/ init .py try : from . import __version__ version = __version__ . version except ImportError : version = \"dev\" At this point, version will read \"dev\" until the module __version__.py has been written into the library. We can write this file during build. package.py name = \"my_library\" version = \"1.0\" build_command = \"python {root}/install.py\" install.py import os import shutil root = os . path . dirname(__file__) build_dir = os . environ[ \"REZ_BUILD_PATH\" ] # Copy library shutil . copytree(os . path . join(root, \"my_library\" ), os . path . join(build_dir, \"my_library\" )) # Inject version version_fname = os . path . join(build_dir, \"my_library\" , \"__version__.py\" ) version = os . getenv( \"REZ_BUILD_PROJECT_VERSION\" ) with open(version_fname, \"w\" ) as f: f . write( \"version = \\\" %s \\\" \" % version) And there you go. Now the version will read \"dev\" unless the package has been built, in which case it would read \"1.0\" .","title":"2. Embedded"},{"location":"guides/","text":"The starting point to using and understanding Allzpark. In development Allzpark is currently being developed and is not yet ready for use. If you're interested in early-access to collaborate and or contribute, get in touch . A 1.0 is scheduled for release in early August 2019. Goal Estimated reading time: 20 mins By the time you're done with this chapter, you'll be able to call the below command, and understand what it does. rez env allzpark bleeding_rez-2.31+ pyside2 python-3 -- allzpark Package Management Allzpark isn't just a pretty face, it's the backbone of any competent production studio working in visual effects, feature animation, commercials or games. That backbone is made up of packages . What is a package? A package is a group of files with some metadata attached, declaring a name, version and its relationship to other packages. When one package requires another, a requirement hierarchy is formed. For example, consider this requirement. requires = [\"maya-2019\", \"arnold\", \"cmuscle\"] From looking at this, you'd expect a version of arnold and cmuscle compatible with maya-2019 (note that we didn't request a particular version of these). Because only a subset of versions of arnold are compatible with maya-2019 what happens is a resolve . Resolve Resolving a request means solving the equation of a requirements hierarchy until exact versions of each package in a request is found, and goes something like this. iteration 01 # maya-2019 arnold cmuscle iteration 02 # maya-2019.0.3 arnold-4.12 cmuscle-1.4 iteration 03 # maya-2019.0.3 arnold-4.12 cmuscle-1.4 libpng-12 libtiff-1 qt-5.12 iteration 04 # maya-2019.0.3 arnold-4.9 cmuscle-1.4 libpng-12 libtiff-1 qt-5.12 qtbase-5.12 qtgui-5-12 openiio-3.41 complete In this example, the first iteration is your original request. The second iteration expands on this request to include specific versions of arnold and cmuscle ; both of which are deemed compatible with maya-2019 . Now things start to get interesting, where did libpng-12 come from?! Well, that's a requirement of arnold-4.12 , so if we want arnold we're going to have to get its other requirements too. But see, now things get even more interesting. arnold-4.12 was just downgraded to arnold-4.9 ! That's because openiio was a requirement of qt and conflicts with arnold-4.12 . As a result, an older version of arnold was picked, one that is compatible with openiio-3.41 . Fun fact That last step is one of the thing that separates Rez from package managers like pip and conda ; the retroactive downgrading of a version to conform to a given constraint. This is one of the things that makes Rez more capable and safer than your typical resolver. As you can see, the number of iterations and complexity therein can grow significantly. It is not uncommon for the number of packages involved to grow into the hundreds and run for dozens to hundreds of iterations per solve, with both off-the-shelf software like above and internally developed projects intermingled. Think about what you would have to go through to solve such a hierarchy yourself - which many do. Prerequisities To resolve requirements, we'll utilise bleeding-rez . pip install bleeding-rez rez bind --quickstart rez --version # bleeding-rez 2.33.1 Troubleshooting pip not found It's possible you have pip installed, just not on your PATH . Try this. python -m pip install bleeding-rez If this doesn't work, let's install pip. Reference curl https://bootstrap.pypa.io/get-pip.py -o get-pip.py python get-pip.py Permission denied The above command assumes admin/sudo access to your machine which isn't always the case. If so, you can install Rez using a virtual environment. $ python -m pip install virtualenv $ python -m virtualenv rez-install $ rez-install \\S cripts \\a ctivate ( rez-install ) $ pip install bleeding-rez rez not found If installation went successfully, but you aren't able to call rez then odds are the Python executable path isn't on your PATH . On Windows, this directory is typically at c:\\python37\\scripts but may vary depending on how Python was installed, and varies across platforms. Following the installation of rez , you should have gotten a message about which path was missing from your PATH , you can either add this yourself, or use the virtualenv method from the above Permission denied box. This will make rez available via the command-line and establish a few default \"packages\" in your ~/packages directory, which we'll talk about later. Your first project In order launch an application in the context of a project using Allzpark, we must create one. Spiderman Your project will be a directory with a file inside called package.py . mkdir spiderman cd spiderman touch package.py This will create a new file called package.py in your newly created spiderman directory. Edit this file with the following. package.py name = \"spiderman\" version = \"1.0\" build_command = False Now we can \"build\" and make use of it. rez build --install $ rez env spiderman > $ The > character denotes that you are in a Rez \"context\", which is its virtual environment. Environment Let's keep going package.py name = \"spiderman\" version = \"1.1\" build_command = False def commands (): global env env[ \"PROJECT_NAME\" ] = \"Spiderman\" Now what happens? > $ exit $ rez build --install $ rez env spiderman > $ Write-Host $env:PROJECT_NAME Spiderman Requirements Great, we're now in control over the environment of this package. What about requirements? package.py name = \"spiderman\" version = \"1.2\" build_command = False requires = [ \"texteditor\" ] def commands (): global env env[ \"PROJECT_NAME\" ] = \"Spiderman\" Now spiderman requires texteditor in order to run. Let's build it. > $ exit $ rez build --install 09 :15:46 ERROR PackageFamilyNotFoundError: package family not found: texteditor Your first application Woops! We haven't got a package for texteditor , let's make one. > $ exit $ cd .. $ mkdir texteditor $ cd texteditor $ touch package.py texteditor/package.py name = \"texteditor\" version = \"1.0\" build_command = False def commands (): import os global alias if os . name == \"nt\" : alias( \"texteditor\" , \"notepad\" ) else : alias( \"texteditor\" , \"nano\" ) Now let's build and use this package. $ rez build --install $ rez env spiderman > $ texteditor Viola, a platform-dependent text editor, tied to a given project. This is one way of tying applications to a project, but we'll look at some more as we go along. In general, you'll want to keep packages self-contained and portable, such that you can deploy them elsewhere. In this case, we utilised a widely accessible application we can expect to exist on almost any workstation. But we aren't always so lucky. Another application Let's make another one to illustrate this point. > $ exit $ cd .. $ mkdir maya $ cd maya $ touch package.py maya/package.py name = \"maya\" version = \"2018.0\" build_command = False def commands (): import os global alias if os . name == \"nt\" : alias( \"maya\" , r\"c:\\program files\\autodesk\\maya2018\\bin\\maya.exe\" ) else : alias( \"maya\" , \"/usr/autodesk/maya2018/bin/maya.bin\" ) In this example, we're making some assumptions that may or may not be appropriate for your environment. If you are in control over workstations and installation paths, then this is fine. But if you can't make that guarantee, you'll care about portability which we'll cover a little later. Exercise Before we move on, make another package for maya-2019 as well in a similar fashion. We'll need this for later. Weak References Let's now update our project to require maya and see what we end up with. spiderman/package.py name = \"spiderman\" version = \"1.3\" build_command = False requires = [ \"texteditor-1\" , \"maya-2018\" ] def commands (): global env env[ \"PROJECT_NAME\" ] = \"Spiderman\" To run it.. $ rez env spiderman > $ maya > $ texteditor As you can see, you now have both maya and texteditor available, at the same time. This typically is not what you want, and comes with a few gotchas. Consider for example if texteditor had a requirement for another project, such as msvcrt<=2011 , and that maya has a similar but conflicting requirement, such as msvcrt>=2013 . In isolation, this isn't a problem, because you can happily run texteditor without requiring maya and vice versa. But because these are both requirements of spiderman , you've now made spiderman impossible to use. To account for this, we need to use \"weak\" references for both texteditor and maya . spiderman/package.py name = \"spiderman\" version = \"1.4\" build_command = False requires = [ \"~texteditor-1\" , \"~maya-2018\" ] def commands (): global env env[ \"PROJECT_NAME\" ] = \"Spiderman\" Now when spiderman is requested, neither maya nor texteditor is included. ~/spiderman $ rez build --install ~/spiderman $ rez env spiderman > ~/spiderman $ maya # Unrecognised command Instead, you ask for them as part of your request. > spiderman/ $ exit spiderman/ $ rez env spiderman maya # resolved packages: # maya-2018.0 ~\\packages\\maya\\2018.0 But then, what was the point of making these requirements of spiderman if they weren't going to become part of the resolve unless? Surely you can just leave them out, and include maya in the request? If you notice above, the resolved package was maya-2018 . If it wasn't for this weak reference, Rez would have picked the latest version, maya-2019 . This is how you can tie applications to your project, without including each of them into the same context. Think about how chaotic this would be if your project involved dozens of applications! Allzpark So you've made a project and given it a unique environment and applications. What's stopping you from launching these applications directly from the command-line? Why do you need Allzpark? You don't! Every command we've typed so far has been entirely in the hands of Rez and you can safely run productions in this way. What Allzpark does is put a face on this system, something for the less technical-minded artists to wrap their heads around, and establish a few ground-rules about how to make the most out of Rez. We'll get into these rules a little later, but for now, let's see what Allzpark looks like on your machine. For this next part, we'll need git . git --verison # git version 2.16.1 git not found Git is required in later chapters, so you may as well get it up and running right away. https://git-scm.com/ Allzpark is a Python package, and whilst we could install it like any other Python package, what we're going to do instead is install it as another Rez package. For that, we'll need pipz . git clone https : //github.com/mottosso/rez-pipz.git cd rez-pipz rez build --install pipz is a wrapper around pip for use with Rez. It can take any request pip can, and turn it into a Rez package. This saves from having to create a Rez package ourselves, when it's already a Python package. Neat! To test out the installation, let's install six as Rez package. rez env pipz -- install six -y This is the equivalent of pip install six . Now let's try it with Allzpark. git clone https : //github.com/mottosso/allzpark.git rez env pipz -- install ./allzpark In this case, we'll install Allzpark from the cloned repository directly (as it isn't yet on PyPI). We'll also need a Qt binding. Any binding will do, in this example we'll use PySide2. rez env pipz -- install pyside2 -y And there you have it. We are now ready to launch Allzpark. rez env allzpark python pyside2 -- allzpark --root ~/packages Under Development Shared Packages One of the thing that separates Res from other package managers like virtualenv and conda is that packages you install are shared . Not only can they be shared across multiple machines, but also across multiple operating systems. Once a package has been installed, you'll never have to install it again. It is permanent, immutable in fact. This is how you can build up a personal- or studio-repository of packages that you can build a pipeline upon, making strong and controlled assumptions about what packages are available, which version they are at, and that they are compatible with each other. So far, we've installed all packages into their default location, which is ~/packages . ls $env :USERPROFILE/packages # With PowerShell ls $HOME /packages # With Bash Loading Order If your graphical application depends on Qt.py, then Qt.py needs to be loaded before your application. This is where loading order comes in. By establishing a requirements hierarchy, the order in which libraries load is included for free. Package Path The recommended layout for Rez packages are as follows. int/ Internal projects, such as core_pipeline . You develop and release new versions internally. ext/ External projects, such as pyblish and Qt.py , you typically install these with rez env pipz -- install td/ Packages developed by TDs themselves, such as small utility scripts proj/ Project such as ATC and MST3 app/ Applications, such as maya and nuke converted/ Automatically converted packages from the old Template-based system There are two additional paths. ~/packages Your local development packages, from your home directory ~/.packages Your localised packages Pip Any package from PyPI can be installed using a utility package called pipz . $ rez env pipz -- install pyblish-base --release See rez-pipz for details. Scoop Any package from Scoop can be installed using another utility package called scoopz . $ rez env scoopz -- install python python27 git See rez-scoopz for details. Localisation For greater performance, any package may be localised to your local disk. See rez-localz for details. Example $ rez env pyside2 allzpark bleeding_rez -- python -m allzpark ============================== allzpark (1.1.79) ============================== - Loading Rez.. ok - 0.75s - Loading Qt.. ok - 6.14s - Loading allzpark.. ok - 0.53s - Loading preferences.. ok - 0.00s ------------------------------ Notice how long it took to load Qt , let's localise this. $ rez env localz -- localise PySide2 Now try launching again. $ rez env pyside2 allzpark bleeding_rez -- python -m allzpark rez env pyside2 allzpark bleeding_rez -- python -m allzpark ============================== allzpark (1.1.79) ============================== - Loading Rez.. ok - 0.91s - Loading Qt.. ok - 0.36s - Loading allzpark.. ok - 0.70s - Loading preferences.. ok - 0.00s ------------------------------ That's much better. Disk Space To save disk space, you can delete any or all localised packages from your ~/.packages path. start % USERPROFILE%\\.packages Overrides Packages, like Python modules, are discovered from a list of paths. If there are identical packages on two or more paths, the first one is picked. We can leverage this behavior to override one package with another. Requirements Overriding requirements enable you to test new packages, or packages of different versions, in an existing project and works like this. Copy project onto local development directory Edit Install If the version remains the same or higher then your edited project is now picked up in place of the original, providing final control over which packages are used in a given project. Environment Overriding environment variables can be achieved in a similar fashion to requirements , but is even more flexible. Packages with regards to environment variables act akin to CSS, or Cascading Style Sheets, from the world wide web in that every change augments - or cascades - a previous change. a/package.py def commands (): global env env[ \"PYTHONPATH\" ] . append( \"/a\" ) b/package.py requires = [ \"a\" ] def commands (): global env env[ \"PYTHONPATH\" ] . append( \"/b\" ) In this example, the package b augments an existing PYTHONPATH created by package a . It does so by appending the value \"/b\" . You can also prepend and overwrite by assigning it directly. env[].append(\"\") env[].prepend(\"\") env[] = \"\" Example - Legacy Viewport We can leverage this behavior to override the behavior of a program using dedicated \"override packages\". maya_legacy_viewport/package.py name = \"maya_legacy_viewport\" version = \"1.0\" requires = [ \"maya\" ] def commands (): global env env[ \"MAYA_ENABLE_LEGACY_VIEWPORT\" ] = \"1\" Including this package in your resolve results in Maya exposing the Legacy Viewport option, to circumvent that pesky Viewport 2.0.","title":"Guide"},{"location":"guides/#in-development","text":"Allzpark is currently being developed and is not yet ready for use. If you're interested in early-access to collaborate and or contribute, get in touch . A 1.0 is scheduled for release in early August 2019.","title":"In development"},{"location":"guides/#goal","text":"Estimated reading time: 20 mins By the time you're done with this chapter, you'll be able to call the below command, and understand what it does. rez env allzpark bleeding_rez-2.31+ pyside2 python-3 -- allzpark","title":"Goal"},{"location":"guides/#package-management","text":"Allzpark isn't just a pretty face, it's the backbone of any competent production studio working in visual effects, feature animation, commercials or games. That backbone is made up of packages .","title":"Package Management"},{"location":"guides/#what-is-a-package","text":"A package is a group of files with some metadata attached, declaring a name, version and its relationship to other packages. When one package requires another, a requirement hierarchy is formed. For example, consider this requirement. requires = [\"maya-2019\", \"arnold\", \"cmuscle\"] From looking at this, you'd expect a version of arnold and cmuscle compatible with maya-2019 (note that we didn't request a particular version of these). Because only a subset of versions of arnold are compatible with maya-2019 what happens is a resolve .","title":"What is a package?"},{"location":"guides/#resolve","text":"Resolving a request means solving the equation of a requirements hierarchy until exact versions of each package in a request is found, and goes something like this. iteration 01 # maya-2019 arnold cmuscle iteration 02 # maya-2019.0.3 arnold-4.12 cmuscle-1.4 iteration 03 # maya-2019.0.3 arnold-4.12 cmuscle-1.4 libpng-12 libtiff-1 qt-5.12 iteration 04 # maya-2019.0.3 arnold-4.9 cmuscle-1.4 libpng-12 libtiff-1 qt-5.12 qtbase-5.12 qtgui-5-12 openiio-3.41 complete In this example, the first iteration is your original request. The second iteration expands on this request to include specific versions of arnold and cmuscle ; both of which are deemed compatible with maya-2019 . Now things start to get interesting, where did libpng-12 come from?! Well, that's a requirement of arnold-4.12 , so if we want arnold we're going to have to get its other requirements too. But see, now things get even more interesting. arnold-4.12 was just downgraded to arnold-4.9 ! That's because openiio was a requirement of qt and conflicts with arnold-4.12 . As a result, an older version of arnold was picked, one that is compatible with openiio-3.41 . Fun fact That last step is one of the thing that separates Rez from package managers like pip and conda ; the retroactive downgrading of a version to conform to a given constraint. This is one of the things that makes Rez more capable and safer than your typical resolver. As you can see, the number of iterations and complexity therein can grow significantly. It is not uncommon for the number of packages involved to grow into the hundreds and run for dozens to hundreds of iterations per solve, with both off-the-shelf software like above and internally developed projects intermingled. Think about what you would have to go through to solve such a hierarchy yourself - which many do.","title":"Resolve"},{"location":"guides/#prerequisities","text":"To resolve requirements, we'll utilise bleeding-rez . pip install bleeding-rez rez bind --quickstart rez --version # bleeding-rez 2.33.1 Troubleshooting pip not found It's possible you have pip installed, just not on your PATH . Try this. python -m pip install bleeding-rez If this doesn't work, let's install pip. Reference curl https://bootstrap.pypa.io/get-pip.py -o get-pip.py python get-pip.py Permission denied The above command assumes admin/sudo access to your machine which isn't always the case. If so, you can install Rez using a virtual environment. $ python -m pip install virtualenv $ python -m virtualenv rez-install $ rez-install \\S cripts \\a ctivate ( rez-install ) $ pip install bleeding-rez rez not found If installation went successfully, but you aren't able to call rez then odds are the Python executable path isn't on your PATH . On Windows, this directory is typically at c:\\python37\\scripts but may vary depending on how Python was installed, and varies across platforms. Following the installation of rez , you should have gotten a message about which path was missing from your PATH , you can either add this yourself, or use the virtualenv method from the above Permission denied box. This will make rez available via the command-line and establish a few default \"packages\" in your ~/packages directory, which we'll talk about later.","title":"Prerequisities"},{"location":"guides/#your-first-project","text":"In order launch an application in the context of a project using Allzpark, we must create one.","title":"Your first project"},{"location":"guides/#spiderman","text":"Your project will be a directory with a file inside called package.py . mkdir spiderman cd spiderman touch package.py This will create a new file called package.py in your newly created spiderman directory. Edit this file with the following. package.py name = \"spiderman\" version = \"1.0\" build_command = False Now we can \"build\" and make use of it. rez build --install $ rez env spiderman > $ The > character denotes that you are in a Rez \"context\", which is its virtual environment.","title":"Spiderman"},{"location":"guides/#environment","text":"Let's keep going package.py name = \"spiderman\" version = \"1.1\" build_command = False def commands (): global env env[ \"PROJECT_NAME\" ] = \"Spiderman\" Now what happens? > $ exit $ rez build --install $ rez env spiderman > $ Write-Host $env:PROJECT_NAME Spiderman","title":"Environment"},{"location":"guides/#requirements","text":"Great, we're now in control over the environment of this package. What about requirements? package.py name = \"spiderman\" version = \"1.2\" build_command = False requires = [ \"texteditor\" ] def commands (): global env env[ \"PROJECT_NAME\" ] = \"Spiderman\" Now spiderman requires texteditor in order to run. Let's build it. > $ exit $ rez build --install 09 :15:46 ERROR PackageFamilyNotFoundError: package family not found: texteditor","title":"Requirements"},{"location":"guides/#your-first-application","text":"Woops! We haven't got a package for texteditor , let's make one. > $ exit $ cd .. $ mkdir texteditor $ cd texteditor $ touch package.py texteditor/package.py name = \"texteditor\" version = \"1.0\" build_command = False def commands (): import os global alias if os . name == \"nt\" : alias( \"texteditor\" , \"notepad\" ) else : alias( \"texteditor\" , \"nano\" ) Now let's build and use this package. $ rez build --install $ rez env spiderman > $ texteditor Viola, a platform-dependent text editor, tied to a given project. This is one way of tying applications to a project, but we'll look at some more as we go along. In general, you'll want to keep packages self-contained and portable, such that you can deploy them elsewhere. In this case, we utilised a widely accessible application we can expect to exist on almost any workstation. But we aren't always so lucky.","title":"Your first application"},{"location":"guides/#another-application","text":"Let's make another one to illustrate this point. > $ exit $ cd .. $ mkdir maya $ cd maya $ touch package.py maya/package.py name = \"maya\" version = \"2018.0\" build_command = False def commands (): import os global alias if os . name == \"nt\" : alias( \"maya\" , r\"c:\\program files\\autodesk\\maya2018\\bin\\maya.exe\" ) else : alias( \"maya\" , \"/usr/autodesk/maya2018/bin/maya.bin\" ) In this example, we're making some assumptions that may or may not be appropriate for your environment. If you are in control over workstations and installation paths, then this is fine. But if you can't make that guarantee, you'll care about portability which we'll cover a little later. Exercise Before we move on, make another package for maya-2019 as well in a similar fashion. We'll need this for later.","title":"Another application"},{"location":"guides/#weak-references","text":"Let's now update our project to require maya and see what we end up with. spiderman/package.py name = \"spiderman\" version = \"1.3\" build_command = False requires = [ \"texteditor-1\" , \"maya-2018\" ] def commands (): global env env[ \"PROJECT_NAME\" ] = \"Spiderman\" To run it.. $ rez env spiderman > $ maya > $ texteditor As you can see, you now have both maya and texteditor available, at the same time. This typically is not what you want, and comes with a few gotchas. Consider for example if texteditor had a requirement for another project, such as msvcrt<=2011 , and that maya has a similar but conflicting requirement, such as msvcrt>=2013 . In isolation, this isn't a problem, because you can happily run texteditor without requiring maya and vice versa. But because these are both requirements of spiderman , you've now made spiderman impossible to use. To account for this, we need to use \"weak\" references for both texteditor and maya . spiderman/package.py name = \"spiderman\" version = \"1.4\" build_command = False requires = [ \"~texteditor-1\" , \"~maya-2018\" ] def commands (): global env env[ \"PROJECT_NAME\" ] = \"Spiderman\" Now when spiderman is requested, neither maya nor texteditor is included. ~/spiderman $ rez build --install ~/spiderman $ rez env spiderman > ~/spiderman $ maya # Unrecognised command Instead, you ask for them as part of your request. > spiderman/ $ exit spiderman/ $ rez env spiderman maya # resolved packages: # maya-2018.0 ~\\packages\\maya\\2018.0 But then, what was the point of making these requirements of spiderman if they weren't going to become part of the resolve unless? Surely you can just leave them out, and include maya in the request? If you notice above, the resolved package was maya-2018 . If it wasn't for this weak reference, Rez would have picked the latest version, maya-2019 . This is how you can tie applications to your project, without including each of them into the same context. Think about how chaotic this would be if your project involved dozens of applications!","title":"Weak References"},{"location":"guides/#allzpark","text":"So you've made a project and given it a unique environment and applications. What's stopping you from launching these applications directly from the command-line? Why do you need Allzpark? You don't! Every command we've typed so far has been entirely in the hands of Rez and you can safely run productions in this way. What Allzpark does is put a face on this system, something for the less technical-minded artists to wrap their heads around, and establish a few ground-rules about how to make the most out of Rez. We'll get into these rules a little later, but for now, let's see what Allzpark looks like on your machine. For this next part, we'll need git . git --verison # git version 2.16.1 git not found Git is required in later chapters, so you may as well get it up and running right away. https://git-scm.com/ Allzpark is a Python package, and whilst we could install it like any other Python package, what we're going to do instead is install it as another Rez package. For that, we'll need pipz . git clone https : //github.com/mottosso/rez-pipz.git cd rez-pipz rez build --install pipz is a wrapper around pip for use with Rez. It can take any request pip can, and turn it into a Rez package. This saves from having to create a Rez package ourselves, when it's already a Python package. Neat! To test out the installation, let's install six as Rez package. rez env pipz -- install six -y This is the equivalent of pip install six . Now let's try it with Allzpark. git clone https : //github.com/mottosso/allzpark.git rez env pipz -- install ./allzpark In this case, we'll install Allzpark from the cloned repository directly (as it isn't yet on PyPI). We'll also need a Qt binding. Any binding will do, in this example we'll use PySide2. rez env pipz -- install pyside2 -y And there you have it. We are now ready to launch Allzpark. rez env allzpark python pyside2 -- allzpark --root ~/packages","title":"Allzpark"},{"location":"guides/#under-development","text":"","title":"Under Development"},{"location":"guides/#shared-packages","text":"One of the thing that separates Res from other package managers like virtualenv and conda is that packages you install are shared . Not only can they be shared across multiple machines, but also across multiple operating systems. Once a package has been installed, you'll never have to install it again. It is permanent, immutable in fact. This is how you can build up a personal- or studio-repository of packages that you can build a pipeline upon, making strong and controlled assumptions about what packages are available, which version they are at, and that they are compatible with each other. So far, we've installed all packages into their default location, which is ~/packages . ls $env :USERPROFILE/packages # With PowerShell ls $HOME /packages # With Bash","title":"Shared Packages"},{"location":"guides/#loading-order","text":"If your graphical application depends on Qt.py, then Qt.py needs to be loaded before your application. This is where loading order comes in. By establishing a requirements hierarchy, the order in which libraries load is included for free.","title":"Loading Order"},{"location":"guides/#package-path","text":"The recommended layout for Rez packages are as follows. int/ Internal projects, such as core_pipeline . You develop and release new versions internally. ext/ External projects, such as pyblish and Qt.py , you typically install these with rez env pipz -- install td/ Packages developed by TDs themselves, such as small utility scripts proj/ Project such as ATC and MST3 app/ Applications, such as maya and nuke converted/ Automatically converted packages from the old Template-based system There are two additional paths. ~/packages Your local development packages, from your home directory ~/.packages Your localised packages","title":"Package Path"},{"location":"guides/#pip","text":"Any package from PyPI can be installed using a utility package called pipz . $ rez env pipz -- install pyblish-base --release See rez-pipz for details.","title":"Pip"},{"location":"guides/#scoop","text":"Any package from Scoop can be installed using another utility package called scoopz . $ rez env scoopz -- install python python27 git See rez-scoopz for details.","title":"Scoop"},{"location":"guides/#localisation","text":"For greater performance, any package may be localised to your local disk. See rez-localz for details. Example $ rez env pyside2 allzpark bleeding_rez -- python -m allzpark ============================== allzpark (1.1.79) ============================== - Loading Rez.. ok - 0.75s - Loading Qt.. ok - 6.14s - Loading allzpark.. ok - 0.53s - Loading preferences.. ok - 0.00s ------------------------------ Notice how long it took to load Qt , let's localise this. $ rez env localz -- localise PySide2 Now try launching again. $ rez env pyside2 allzpark bleeding_rez -- python -m allzpark rez env pyside2 allzpark bleeding_rez -- python -m allzpark ============================== allzpark (1.1.79) ============================== - Loading Rez.. ok - 0.91s - Loading Qt.. ok - 0.36s - Loading allzpark.. ok - 0.70s - Loading preferences.. ok - 0.00s ------------------------------ That's much better. Disk Space To save disk space, you can delete any or all localised packages from your ~/.packages path. start % USERPROFILE%\\.packages","title":"Localisation"},{"location":"guides/#overrides","text":"Packages, like Python modules, are discovered from a list of paths. If there are identical packages on two or more paths, the first one is picked. We can leverage this behavior to override one package with another.","title":"Overrides"},{"location":"guides/#requirements_1","text":"Overriding requirements enable you to test new packages, or packages of different versions, in an existing project and works like this. Copy project onto local development directory Edit Install If the version remains the same or higher then your edited project is now picked up in place of the original, providing final control over which packages are used in a given project.","title":"Requirements"},{"location":"guides/#environment_1","text":"Overriding environment variables can be achieved in a similar fashion to requirements , but is even more flexible. Packages with regards to environment variables act akin to CSS, or Cascading Style Sheets, from the world wide web in that every change augments - or cascades - a previous change. a/package.py def commands (): global env env[ \"PYTHONPATH\" ] . append( \"/a\" ) b/package.py requires = [ \"a\" ] def commands (): global env env[ \"PYTHONPATH\" ] . append( \"/b\" ) In this example, the package b augments an existing PYTHONPATH created by package a . It does so by appending the value \"/b\" . You can also prepend and overwrite by assigning it directly. env[].append(\"\") env[].prepend(\"\") env[] = \"\"","title":"Environment"},{"location":"guides/#example-legacy-viewport","text":"We can leverage this behavior to override the behavior of a program using dedicated \"override packages\". maya_legacy_viewport/package.py name = \"maya_legacy_viewport\" version = \"1.0\" requires = [ \"maya\" ] def commands (): global env env[ \"MAYA_ENABLE_LEGACY_VIEWPORT\" ] = \"1\" Including this package in your resolve results in Maya exposing the Legacy Viewport option, to circumvent that pesky Viewport 2.0.","title":"Example - Legacy Viewport"},{"location":"localisation/","text":"Shared packages","title":"Localisation"},{"location":"reference/","text":"Short bite-sized snippets of information. This builds on information provided in the guides chapter. allzparkconfig.py Configure allzpark using the allzparkconfig.py . touch ~/allzparkconfig.py Store in your $HOME directory allzpark --config-file path/to/allzparkconfig.py Or pass directly ALLZPARK_CONFIG_FILE Or pass via environment variable All available keys and their default values can be found here. allzparkconfig.py Styling All of the Allzpark graphical user interface can be styled interactively using CSS. Custom styles are stored on the local machine, and can be shared and saved with copy/paste over e.g. chat or email. See style.css for examples and documentation Naming Convention Requests are split between name<operator><version> Where <operator> is e.g. - or == or >= And <version> is an alphanumeric string, e.g. 1.0 or latest or 2.b2 Example rez env my_package-1 # package `my_package`, version `1` or above rez env my-package-1 # package `my`, version `package-1` or above rez env my_package_1 # package `my_package_1`, latest version rez env my_package == 1 # package `my_package_1`, version `1` exactly See wiki for details. Automatic Environment Variables Every package part of a resolve is given a series of environment variables. REZ_(PKG)_BASE REZ_(PKG)_ROOT REZ_(PKG)_VERSION REZ_(PKG)_MAJOR_VERSION REZ_(PKG)_MINOR_VERSION REZ_(PKG)_PATCH_VERSION You can reference these from other packages, using the {env.NAME} notation, where env refers to the system environment, prior to packages having an effect. Example # package.py name = \"my_package\" version = \"1.0\" requires = [ \"my_package-1.0\" ] def commands (): global env env[ \"MY_VARIABLE\" ] = r\"c:\\path\\{env.REZ_MY_PACKAGE_VERSION}\\scripts\" See wiki for details. Platform Specific Packages A package can target a given platform using \"variants\". my_package/package.py name = \"my_package\" version = \"1.0\" build_command = False variants = [ [ \"platform-windows\" ], [ \"platform-linux\" ], ] Requesting this package on windows would result in a version specific to Windows, and likewise for Linux. Building of this package happens twice ; once per \"variant\". Building Per Platform $ cd my_package $ rez build Building variant 0 ( 1 /2 ) ... Invoking custom build system... Building variant 0 ( 2 /2 ) ... The following package conflicts occurred: ( platform-linux <--!--> ~platform == windows ) Since you cannot build a Linux package from Windows, nor vice versa, you can specify which variant to build using the --variants argument. $ rez build --variants 0 Where 0 indicates the 0 th index in the package.py:variants = [] list. See wiki for details See rez build --help for details Options You can reference any package and version as a variant, but generally you'll only need the platform specific ones, which come defined in rezconfig.py per default. rezconfig.py implicit_packages = [ \"~platform=={system.platform}\" , \"~arch=={system.arch}\" , \"~os=={system.os}\" , ] See rez config implicit_packages for available options along with their values. rez config implicit_packages - ~platform == windows - ~arch == AMD64 - ~os == windows-10 Multiple Application Versions Applications such as Python, Autodesk Maya and Adobe Photoshop can get packaged in one of two ways. maya-2018.1.0 i.e. \"Serial\" maya2018-1.0 i.e. \"Parallel\" Let's refer to these as \"serial\" and \"parallel\" respectively. Which should you use, and why? Uniform In this example, there is only one package \"family\" for the Autodesk Maya software, whereby every revision of Maya is released as a new Rez package version; including \"service packs\" and \"hotfixes\" etc. The advantage is that a package can then create a requirement on a range of maya versions. name = \"mgear\" version = \"1.0.0\" requires = [ \"maya>=2015,<2020\" ] The disadvantage however is that you cannot resolve an environment with both maya-2018 and maya-2019 , as one would conflict with the other. Furthermore, if you did force this resolve, what should you expect to have happen in a situation like this? $ rez env python-2 python-3 > $ python --version Python ?.?.? Parallel Conversely, you can perform a \"parallel\" version. maya2018/package.py name = \"maya2018\" version = \"1.0\" maya2019/package.py name = \"maya2019\" version = \"1.0\" In which case you are able to resolve an environment like this. $ rez env maya2018 maya2019-1.0 > $ To work around the aforementioned issue of knowing which python - or in this case maya - is actually called, you can use an alias() . maya2019/package.py name = \"maya2019\" version = \"1.0\" def commands (): global alias alias( \"maya2019\" , \"{root}/bin/maya.exe\" ) At which point you can call.. $ rez env maya2018 maya2019 > $ maya2018 # Launching Maya 2018.. However it isn't clear how you can make a requirement on a range of Maya versions with a parallel package. Consider the mgear package. mgear/package.py name = \"mgear\" version = \"1.0\" requires = [ \"maya2018-1.0\" ] # What about Maya 2019? :( Rez currently does not support optional or \"any\"-style packages and so this approach would not be well suited for these types of requirements. Packages and Version Control Work in progress If you got this far, and know more or want more, feel free to submit an issue . Release with GitLab Once you've created a package, it's often a good idea to version control it. mkdir my_package cd my_package echo \"name = `\" my_package `\" \" >> package.py echo \"version = `\" 1.0.0 `\" \" >> package.py echo \"build_command = False\" >> package.py git init git add --all git commit -m \"Initial version\" git remote add-url https : //gitlab.mycompany.com/username/my_package.git git push Next we'll configure GitLab to release a package alongside a new tag being made. .gitlab-ci.yml release: environment: - REZ_CONFIG_FILE=/packages/rezconfig.py script: - rez build --release only: - tags Work in progress If you got this far, and know more or want more, feel free to submit an issue . Multiple Packages in a Single Git Repository Sometimes, dedicating a Git repository or GitLab project for every package is too heavy-handed. Sometimes you have many small packages that all need version control, but not necessarily independently, such as project packages. In this example, we'll create a Git repository containing 3 projects. Alita Spiderman Hulk These projects are all released as individual Rez packages, but are managed in one Git repository. mkdir my_projects cd my_projects mkdir alita mkdir spiderman mkdir hulk Create a package.py in each project subdirectory, with something along the lines of: name = \"alita\" version = \"1.0.0\" build_command = False Now we can commit and push these to, for example, your locally hosted GitLab instance. git init git add --all git commit -m \"Initial version\" git remote add-url https://gitlab.mycompany.com/username/my_projects.git git push When it's time to release, simply cd into a package of interest, and --release . cd alita rez build --install --release --clean Render on Farm Typically, a context is resolved locally and work performed therein, and then further computation is submitted to a remote destination, such as a \"render farm\" or distributed compute network. In this case, it can be necessary to replicate a context remotely, in exactly the same configuration as locally. But, you cannot assume: Where packages are stored, because a remote computer may have different mount points What OS the remote destination is running, because it may be e.g. Windows or Linux Raw Environment Because of the above, simply saving the environment as-is and restoring it elsewhere is rarely enough. import os import json # Not enough.. with open( \"environment.json\" , \"w\" ) as f: json . dump(f, dict(os . environ)) RXT You may consider storing the resolved context to a file, for example.. rez env packageA packageB --output context.rxt # Machine A rez env --input context.rxt # Machine B Alternatively.. rez env packageA packageB > Get-Content $env :REZ_RXT_FILE > context.rxt > exit rez env --input context.rxt But an exported context embeds absolute paths to where packages can be found, which may not be true on the remote end - such as a local render farm or remote cloud. REZ_USED_RESOLVE In this case, you may consider exporting the exact request, like this. rez env packageA packageB --exclude *.beta > $env :REZ_USED_RESOLVE # packageA-2.33.3 packageB-5.12.3 However this may not be precise enough. The - indicator locks the included parts of a version, such as 5.12.3 , but doesn't exclude the possibility of a 5.12.3.beta package, which takes precendence over 5.12.3 . rez env packageA-2.33.3 packageB-5.12.3 > $env :REZ_USED_RESOLVE # packageA-2.33.3 packageB-5.12.3.beta Notice the .beta towards the end. Here's another example. rez env packageA # packageA-1.0.0.beta rez env packageA-1.0.0 # packageA-1.0.0.beta rez env packageA-1.0.0.beta # packageA-1.0.0.beta For that reason, passing REZ_USED_RESOLVE to rez env may not be enough to accurately reproduce a given environment. Inherit Filter So then what you could do, is pass along whatever filer you used to the remote end. Local rez env packageA packageB --exclude *.beta -- echo $env :REZ_USED_RESOLVE # packageA-2.33.3 packageB-5.12.3 Remote rez env packageA-2.33.3 packageB-5.12.3 --exclude *.beta And presto, an identical environment.. but wait! What about --patch ed environments. rez env packageA packageB --exclude *.beta > rez env packageB-5.12.3.beta >> $env :REZ_USED_RESOLVE # packageA-2.33.3 packageB-5.12.3.beta Now the final \"used resolve\" is incompatible with this filter, as --exclude *.beta would hide the beta version of packageB , resulting in.. 12 :18:12 ERROR PackageNotFoundError: Package could not be found: packageB == 5 .12.3.beta resolved_packages So what is the solution? In a nutshell.. Resolve a context Serialise ResolvedContext.resolved_packages to {name}=={version} used_resolve.py from rez.status import status # Use `status` to fetch an instance of ResolvedContext # from within our current environment. print ( \" \" . join([ \"%s==%s\" % (pkg . name, pkg . version) for pkg in status . context . resolved_packages ])) Resulting in.. rez env python packageA packageB --exclude *.beta -- python used_resolve.py # packageA==2.33.3 packageB==5.12.3 And presto, an accurate depiction of a given context, suitable for use again on the same machine, on a local render farm or remote cloud rendering environment. Testing Packages Like any software projects, you need good tests. Software packaged with Rez is no exception, and doesn't necessarily change how you normally approach test. There are a few ways to exercise your package. Local Build and Run The most useful and common approach is to build and run your package locally. cd my_package rez build --install This will install the package into your local ~/packages directory, overridden by REZ_LOCAL_PACKAGES_PATH . From there, you can test a package as though it was deployed globally, until it's ready for an audience. rez build --install --release This command on the other hand installs a package into ~/.rez , overridden by REZ_RELEASE_PACKAGES_PATH . Test on Release The above is a good start, but it's still possible for bugs to make their way into a deployed package unless you have a solid test suite. cd my_package nosetests2 # Testing.. For a Python project, tests can be written as though Rez was not involved, using any relevant test framework. But having tests means nothing unless they are actually exercised, and that's when setting up a \"release hook\" can help maintain consistency. Work in progress If you got this far, and know more or want more, feel free to submit an issue .","title":"Reference"},{"location":"reference/#allzparkconfigpy","text":"Configure allzpark using the allzparkconfig.py . touch ~/allzparkconfig.py Store in your $HOME directory allzpark --config-file path/to/allzparkconfig.py Or pass directly ALLZPARK_CONFIG_FILE Or pass via environment variable All available keys and their default values can be found here. allzparkconfig.py","title":"allzparkconfig.py"},{"location":"reference/#styling","text":"All of the Allzpark graphical user interface can be styled interactively using CSS. Custom styles are stored on the local machine, and can be shared and saved with copy/paste over e.g. chat or email. See style.css for examples and documentation","title":"Styling"},{"location":"reference/#naming-convention","text":"Requests are split between name<operator><version> Where <operator> is e.g. - or == or >= And <version> is an alphanumeric string, e.g. 1.0 or latest or 2.b2 Example rez env my_package-1 # package `my_package`, version `1` or above rez env my-package-1 # package `my`, version `package-1` or above rez env my_package_1 # package `my_package_1`, latest version rez env my_package == 1 # package `my_package_1`, version `1` exactly See wiki for details.","title":"Naming Convention"},{"location":"reference/#automatic-environment-variables","text":"Every package part of a resolve is given a series of environment variables. REZ_(PKG)_BASE REZ_(PKG)_ROOT REZ_(PKG)_VERSION REZ_(PKG)_MAJOR_VERSION REZ_(PKG)_MINOR_VERSION REZ_(PKG)_PATCH_VERSION You can reference these from other packages, using the {env.NAME} notation, where env refers to the system environment, prior to packages having an effect. Example # package.py name = \"my_package\" version = \"1.0\" requires = [ \"my_package-1.0\" ] def commands (): global env env[ \"MY_VARIABLE\" ] = r\"c:\\path\\{env.REZ_MY_PACKAGE_VERSION}\\scripts\" See wiki for details.","title":"Automatic Environment Variables"},{"location":"reference/#platform-specific-packages","text":"A package can target a given platform using \"variants\". my_package/package.py name = \"my_package\" version = \"1.0\" build_command = False variants = [ [ \"platform-windows\" ], [ \"platform-linux\" ], ] Requesting this package on windows would result in a version specific to Windows, and likewise for Linux. Building of this package happens twice ; once per \"variant\".","title":"Platform Specific Packages"},{"location":"reference/#building-per-platform","text":"$ cd my_package $ rez build Building variant 0 ( 1 /2 ) ... Invoking custom build system... Building variant 0 ( 2 /2 ) ... The following package conflicts occurred: ( platform-linux <--!--> ~platform == windows ) Since you cannot build a Linux package from Windows, nor vice versa, you can specify which variant to build using the --variants argument. $ rez build --variants 0 Where 0 indicates the 0 th index in the package.py:variants = [] list. See wiki for details See rez build --help for details","title":"Building Per Platform"},{"location":"reference/#options","text":"You can reference any package and version as a variant, but generally you'll only need the platform specific ones, which come defined in rezconfig.py per default. rezconfig.py implicit_packages = [ \"~platform=={system.platform}\" , \"~arch=={system.arch}\" , \"~os=={system.os}\" , ] See rez config implicit_packages for available options along with their values. rez config implicit_packages - ~platform == windows - ~arch == AMD64 - ~os == windows-10","title":"Options"},{"location":"reference/#multiple-application-versions","text":"Applications such as Python, Autodesk Maya and Adobe Photoshop can get packaged in one of two ways. maya-2018.1.0 i.e. \"Serial\" maya2018-1.0 i.e. \"Parallel\" Let's refer to these as \"serial\" and \"parallel\" respectively. Which should you use, and why?","title":"Multiple Application Versions"},{"location":"reference/#uniform","text":"In this example, there is only one package \"family\" for the Autodesk Maya software, whereby every revision of Maya is released as a new Rez package version; including \"service packs\" and \"hotfixes\" etc. The advantage is that a package can then create a requirement on a range of maya versions. name = \"mgear\" version = \"1.0.0\" requires = [ \"maya>=2015,<2020\" ] The disadvantage however is that you cannot resolve an environment with both maya-2018 and maya-2019 , as one would conflict with the other. Furthermore, if you did force this resolve, what should you expect to have happen in a situation like this? $ rez env python-2 python-3 > $ python --version Python ?.?.?","title":"Uniform"},{"location":"reference/#parallel","text":"Conversely, you can perform a \"parallel\" version. maya2018/package.py name = \"maya2018\" version = \"1.0\" maya2019/package.py name = \"maya2019\" version = \"1.0\" In which case you are able to resolve an environment like this. $ rez env maya2018 maya2019-1.0 > $ To work around the aforementioned issue of knowing which python - or in this case maya - is actually called, you can use an alias() . maya2019/package.py name = \"maya2019\" version = \"1.0\" def commands (): global alias alias( \"maya2019\" , \"{root}/bin/maya.exe\" ) At which point you can call.. $ rez env maya2018 maya2019 > $ maya2018 # Launching Maya 2018.. However it isn't clear how you can make a requirement on a range of Maya versions with a parallel package. Consider the mgear package. mgear/package.py name = \"mgear\" version = \"1.0\" requires = [ \"maya2018-1.0\" ] # What about Maya 2019? :( Rez currently does not support optional or \"any\"-style packages and so this approach would not be well suited for these types of requirements.","title":"Parallel"},{"location":"reference/#packages-and-version-control","text":"Work in progress If you got this far, and know more or want more, feel free to submit an issue .","title":"Packages and Version Control"},{"location":"reference/#release-with-gitlab","text":"Once you've created a package, it's often a good idea to version control it. mkdir my_package cd my_package echo \"name = `\" my_package `\" \" >> package.py echo \"version = `\" 1.0.0 `\" \" >> package.py echo \"build_command = False\" >> package.py git init git add --all git commit -m \"Initial version\" git remote add-url https : //gitlab.mycompany.com/username/my_package.git git push Next we'll configure GitLab to release a package alongside a new tag being made. .gitlab-ci.yml release: environment: - REZ_CONFIG_FILE=/packages/rezconfig.py script: - rez build --release only: - tags Work in progress If you got this far, and know more or want more, feel free to submit an issue .","title":"Release with GitLab"},{"location":"reference/#multiple-packages-in-a-single-git-repository","text":"Sometimes, dedicating a Git repository or GitLab project for every package is too heavy-handed. Sometimes you have many small packages that all need version control, but not necessarily independently, such as project packages. In this example, we'll create a Git repository containing 3 projects. Alita Spiderman Hulk These projects are all released as individual Rez packages, but are managed in one Git repository. mkdir my_projects cd my_projects mkdir alita mkdir spiderman mkdir hulk Create a package.py in each project subdirectory, with something along the lines of: name = \"alita\" version = \"1.0.0\" build_command = False Now we can commit and push these to, for example, your locally hosted GitLab instance. git init git add --all git commit -m \"Initial version\" git remote add-url https://gitlab.mycompany.com/username/my_projects.git git push When it's time to release, simply cd into a package of interest, and --release . cd alita rez build --install --release --clean","title":"Multiple Packages in a Single Git Repository"},{"location":"reference/#render-on-farm","text":"Typically, a context is resolved locally and work performed therein, and then further computation is submitted to a remote destination, such as a \"render farm\" or distributed compute network. In this case, it can be necessary to replicate a context remotely, in exactly the same configuration as locally. But, you cannot assume: Where packages are stored, because a remote computer may have different mount points What OS the remote destination is running, because it may be e.g. Windows or Linux","title":"Render on Farm"},{"location":"reference/#raw-environment","text":"Because of the above, simply saving the environment as-is and restoring it elsewhere is rarely enough. import os import json # Not enough.. with open( \"environment.json\" , \"w\" ) as f: json . dump(f, dict(os . environ))","title":"Raw Environment"},{"location":"reference/#rxt","text":"You may consider storing the resolved context to a file, for example.. rez env packageA packageB --output context.rxt # Machine A rez env --input context.rxt # Machine B Alternatively.. rez env packageA packageB > Get-Content $env :REZ_RXT_FILE > context.rxt > exit rez env --input context.rxt But an exported context embeds absolute paths to where packages can be found, which may not be true on the remote end - such as a local render farm or remote cloud.","title":"RXT"},{"location":"reference/#rez_used_resolve","text":"In this case, you may consider exporting the exact request, like this. rez env packageA packageB --exclude *.beta > $env :REZ_USED_RESOLVE # packageA-2.33.3 packageB-5.12.3 However this may not be precise enough. The - indicator locks the included parts of a version, such as 5.12.3 , but doesn't exclude the possibility of a 5.12.3.beta package, which takes precendence over 5.12.3 . rez env packageA-2.33.3 packageB-5.12.3 > $env :REZ_USED_RESOLVE # packageA-2.33.3 packageB-5.12.3.beta Notice the .beta towards the end. Here's another example. rez env packageA # packageA-1.0.0.beta rez env packageA-1.0.0 # packageA-1.0.0.beta rez env packageA-1.0.0.beta # packageA-1.0.0.beta For that reason, passing REZ_USED_RESOLVE to rez env may not be enough to accurately reproduce a given environment.","title":"REZ_USED_RESOLVE"},{"location":"reference/#inherit-filter","text":"So then what you could do, is pass along whatever filer you used to the remote end. Local rez env packageA packageB --exclude *.beta -- echo $env :REZ_USED_RESOLVE # packageA-2.33.3 packageB-5.12.3 Remote rez env packageA-2.33.3 packageB-5.12.3 --exclude *.beta And presto, an identical environment.. but wait! What about --patch ed environments. rez env packageA packageB --exclude *.beta > rez env packageB-5.12.3.beta >> $env :REZ_USED_RESOLVE # packageA-2.33.3 packageB-5.12.3.beta Now the final \"used resolve\" is incompatible with this filter, as --exclude *.beta would hide the beta version of packageB , resulting in.. 12 :18:12 ERROR PackageNotFoundError: Package could not be found: packageB == 5 .12.3.beta","title":"Inherit Filter"},{"location":"reference/#resolved_packages","text":"So what is the solution? In a nutshell.. Resolve a context Serialise ResolvedContext.resolved_packages to {name}=={version} used_resolve.py from rez.status import status # Use `status` to fetch an instance of ResolvedContext # from within our current environment. print ( \" \" . join([ \"%s==%s\" % (pkg . name, pkg . version) for pkg in status . context . resolved_packages ])) Resulting in.. rez env python packageA packageB --exclude *.beta -- python used_resolve.py # packageA==2.33.3 packageB==5.12.3 And presto, an accurate depiction of a given context, suitable for use again on the same machine, on a local render farm or remote cloud rendering environment.","title":"resolved_packages"},{"location":"reference/#testing-packages","text":"Like any software projects, you need good tests. Software packaged with Rez is no exception, and doesn't necessarily change how you normally approach test. There are a few ways to exercise your package.","title":"Testing Packages"},{"location":"reference/#local-build-and-run","text":"The most useful and common approach is to build and run your package locally. cd my_package rez build --install This will install the package into your local ~/packages directory, overridden by REZ_LOCAL_PACKAGES_PATH . From there, you can test a package as though it was deployed globally, until it's ready for an audience. rez build --install --release This command on the other hand installs a package into ~/.rez , overridden by REZ_RELEASE_PACKAGES_PATH .","title":"Local Build and Run"},{"location":"reference/#test-on-release","text":"The above is a good start, but it's still possible for bugs to make their way into a deployed package unless you have a solid test suite. cd my_package nosetests2 # Testing.. For a Python project, tests can be written as though Rez was not involved, using any relevant test framework. But having tests means nothing unless they are actually exercised, and that's when setting up a \"release hook\" can help maintain consistency. Work in progress If you got this far, and know more or want more, feel free to submit an issue .","title":"Test on Release"},{"location":"rez/","text":"Below you'll find a series of tutorials-by-example of increasing complexity, utilising more of Rez's functionality as we go, solving more and more specific problems. Basics Let's start with the basics. Shortest Possible Example Create and use a new package from scratch in under 40 seconds. mkdir mypackage # Name of your Git project cd mypackage # Rez definition \"name = `\" mypackage `\" \" | Add-Content package.py # Rez package name \"version = `\" 1.0 `\" \" | Add-Content package.py # Rez package version \"build_command = False\" | Add-Content package.py # Called on building package rez build --install # Build package rez env mypackage # Use package > $ # A new environment with your package The > symbol means you are in a Rez \"context\". Type exit to exit the context. Environment Variables Most packages will modify their environment in some way. package.py name = \"mypackage\" version = \"1.1\" build_command = False def commands (): global env # Global variable available to `commands()` env[ \"MYVARIABLE\" ] = \"Yes\" This package will assign \"Yes\" to MYVARIABLE. env A global Python variable representing the environment env[\"MYVARIABLE\"] - An environment variable env.MYVARIABLE - This is also OK $ rez build --install $ rez env mypackage > $ echo % MYVARIABLE% Yes Environment Paths A package can also modify paths, like PATH and PYTHONPATH , without removing what was there before. package.py name = \"mypackage\" version = \"1.2\" build_command = False def commands (): global env env[ \"PYTHONPATH\" ] . prepend( \"{root}\" ) env[ \"PYTHONPATH\" ] . prepend( \"{root}/python\" ) This package will assign \"{root}\" to PYTHONPATH . {root} expands to the absolute path to the installed package env[\"PYTHONPATH\"].prepend() - Prepend a value to this variable env[\"PYTHONPATH\"].append() - Append a value to this variable $ rez build --install $ rez env mypackage > $ echo % PYTHONPATH% \\\\server\\packages\\mypackage\\1.2;\\\\server\\packages\\int\\mypackage\\1.2\\python Requirements Most packages will depend on another package. cd mypackage cd .. mkdir mypackage2 touch mypackage2/package.py mypackage2/package.py name = \"mypackage2\" version = \"1.0\" build_command = False requires = [ \"python-3\" , \"mypackage-1.2\" ] This package now requires python-3 and mypackage-1.2 . $ rez build --install $ rez env mypackage2 resolved by manima@toy, on Thu Jun 27 11 : 12 : 18 2019, using Rez v2.32.1 requested packages : mypackage2 ~platform==windows (implicit) ~arch==AMD64 (implicit) ~os==windows-10.0.18362.SP0 (implicit) resolved packages : arch-AMD64 C : \\Users\\manima\\packages\\arch\\AMD64 (local) mypackage-1.3 C : \\Users\\manima\\packages\\mypackage\\1.3 (local) mypackage2-1.0 C : \\Users\\manima\\packages\\mypackage2\\1.0 (local) platform-windows C : \\Users\\manima\\packages\\platform\\windows (local) python-3.7.3 C : \\Users\\manima\\packages\\python\\3.7.3\\platform-windows\\arch-AMD64 (local) > $ Payload Most packages will have additional files, such as Python modules. This is where build_command comes in. $ cd mypackage $ touch install.py # Additional script for build $ mkdir python # Payload directory $ cd python # $ echo print( \"Hello World!\" ) >> mymodule.py # Python payload shipped alongside package package.py name = \"mypackage\" version = \"1.3\" build_command = \"python {root}/install.py\" # Run this command on `rez build` requires = [ \"python-3\" ] def commands (): global env env[ \"PYTHONPATH\" ] . prepend( \"{root}/python\" ) # Add payload to environment install.py # This script is called on `rez build` import os import shutil print ( \"Running install.py...\" ) root = os . path . dirname(__file__) build_dir = os . environ[ \"REZ_BUILD_PATH\" ] install_dir = os . environ[ \"REZ_BUILD_INSTALL_PATH\" ] print ( \"Copying payload to %s..\" % build_dir) shutil . copytree( os . path . join(root, \"python\" ), os . path . join(build_dir, \"python\" ), ignore = shutil . ignore_patterns( \"*.pyc\" , \"__pycache__\" ) ) if int(os . getenv( \"REZ_BUILD_INSTALL\" )): # This part is called with `rez build --install` print ( \"Installing payload to %s...\" % install_dir) shutil . copytree( os . path . join(build_dir, \"python\" ), os . path . join(install_dir, \"python\" ), ) Now let's build it. $ rez build --install $ rez env mypackage > $ python -m mymodule Hello World!","title":"Packaging"},{"location":"rez/#basics","text":"Let's start with the basics.","title":"Basics"},{"location":"rez/#shortest-possible-example","text":"Create and use a new package from scratch in under 40 seconds. mkdir mypackage # Name of your Git project cd mypackage # Rez definition \"name = `\" mypackage `\" \" | Add-Content package.py # Rez package name \"version = `\" 1.0 `\" \" | Add-Content package.py # Rez package version \"build_command = False\" | Add-Content package.py # Called on building package rez build --install # Build package rez env mypackage # Use package > $ # A new environment with your package The > symbol means you are in a Rez \"context\". Type exit to exit the context.","title":"Shortest Possible Example"},{"location":"rez/#environment-variables","text":"Most packages will modify their environment in some way. package.py name = \"mypackage\" version = \"1.1\" build_command = False def commands (): global env # Global variable available to `commands()` env[ \"MYVARIABLE\" ] = \"Yes\" This package will assign \"Yes\" to MYVARIABLE. env A global Python variable representing the environment env[\"MYVARIABLE\"] - An environment variable env.MYVARIABLE - This is also OK $ rez build --install $ rez env mypackage > $ echo % MYVARIABLE% Yes","title":"Environment Variables"},{"location":"rez/#environment-paths","text":"A package can also modify paths, like PATH and PYTHONPATH , without removing what was there before. package.py name = \"mypackage\" version = \"1.2\" build_command = False def commands (): global env env[ \"PYTHONPATH\" ] . prepend( \"{root}\" ) env[ \"PYTHONPATH\" ] . prepend( \"{root}/python\" ) This package will assign \"{root}\" to PYTHONPATH . {root} expands to the absolute path to the installed package env[\"PYTHONPATH\"].prepend() - Prepend a value to this variable env[\"PYTHONPATH\"].append() - Append a value to this variable $ rez build --install $ rez env mypackage > $ echo % PYTHONPATH% \\\\server\\packages\\mypackage\\1.2;\\\\server\\packages\\int\\mypackage\\1.2\\python","title":"Environment Paths"},{"location":"rez/#requirements","text":"Most packages will depend on another package. cd mypackage cd .. mkdir mypackage2 touch mypackage2/package.py mypackage2/package.py name = \"mypackage2\" version = \"1.0\" build_command = False requires = [ \"python-3\" , \"mypackage-1.2\" ] This package now requires python-3 and mypackage-1.2 . $ rez build --install $ rez env mypackage2 resolved by manima@toy, on Thu Jun 27 11 : 12 : 18 2019, using Rez v2.32.1 requested packages : mypackage2 ~platform==windows (implicit) ~arch==AMD64 (implicit) ~os==windows-10.0.18362.SP0 (implicit) resolved packages : arch-AMD64 C : \\Users\\manima\\packages\\arch\\AMD64 (local) mypackage-1.3 C : \\Users\\manima\\packages\\mypackage\\1.3 (local) mypackage2-1.0 C : \\Users\\manima\\packages\\mypackage2\\1.0 (local) platform-windows C : \\Users\\manima\\packages\\platform\\windows (local) python-3.7.3 C : \\Users\\manima\\packages\\python\\3.7.3\\platform-windows\\arch-AMD64 (local) > $","title":"Requirements"},{"location":"rez/#payload","text":"Most packages will have additional files, such as Python modules. This is where build_command comes in. $ cd mypackage $ touch install.py # Additional script for build $ mkdir python # Payload directory $ cd python # $ echo print( \"Hello World!\" ) >> mymodule.py # Python payload shipped alongside package package.py name = \"mypackage\" version = \"1.3\" build_command = \"python {root}/install.py\" # Run this command on `rez build` requires = [ \"python-3\" ] def commands (): global env env[ \"PYTHONPATH\" ] . prepend( \"{root}/python\" ) # Add payload to environment install.py # This script is called on `rez build` import os import shutil print ( \"Running install.py...\" ) root = os . path . dirname(__file__) build_dir = os . environ[ \"REZ_BUILD_PATH\" ] install_dir = os . environ[ \"REZ_BUILD_INSTALL_PATH\" ] print ( \"Copying payload to %s..\" % build_dir) shutil . copytree( os . path . join(root, \"python\" ), os . path . join(build_dir, \"python\" ), ignore = shutil . ignore_patterns( \"*.pyc\" , \"__pycache__\" ) ) if int(os . getenv( \"REZ_BUILD_INSTALL\" )): # This part is called with `rez build --install` print ( \"Installing payload to %s...\" % install_dir) shutil . copytree( os . path . join(build_dir, \"python\" ), os . path . join(install_dir, \"python\" ), ) Now let's build it. $ rez build --install $ rez env mypackage > $ python -m mymodule Hello World!","title":"Payload"},{"location":"shells/","text":"Rez provides support for a number of shells on Windows, Linux and MacOS. Each of which operate almost identically, some having their own special powers. Supported shells Windows PowerShell cmd bash PowerShell On Windows, you'll likely want to use PowerShell. Note that \"Windows Powershell\" is different from PowerShell 6 and above which is cross-platform but not yet supported by Rez. Aliases are created as function () Resources Scoop Package Manager Why PowerShell Getting Started PowerShell Masterclass Process Management PowerShell, like Python, works with objects rather than text like cmd and bash . PS> $fx = get-process -name firefox PS> $fx.path # C:\\Program Files\\Mozilla Firefox\\firefox.exe PS> $fx.workingset / 1mb # 414.23828125 PS> $fx.kill() Aliases PS> ls # # Directory: C:\\Users\\marcus\\.ssh # # Mode LastWriteTime Length Name # ---- ------------- ------ ---- # -a---- 11/02/2018 15:52 1766 id_rsa # -a---- 18/02/2018 11:30 1486 id_rsa.ppk # -a---- 11/02/2018 15:52 392 id_rsa.pub # -a---- 18/03/2019 08:05 3514 known_hosts PS> get-alias clear # CommandType Name Version Source # ----------- ---- ------- ------ # Alias cls -> Clear-Host Working with processes Get-Member is akin to Python's dir() . PS> $notepad = start-process notepad -passthru PS> $notepad | get-member # TypeName: System.Diagnostics.Process # # Name MemberType Definition # ---- ---------- ---------- # ... # Name AliasProperty Name = ProcessName # Company ScriptProperty System.Object Company # {get=$this.Mainmodule.FileVersionInfo.CompanyName;} # ... # Path ScriptProperty System.Object Path {get=$this.Mainmodule.FileName;} # WorkingSet Property int WorkingSet {get;} # Kill Method void Kill() # Refresh Method void Refresh() # Start Method bool Start() # ToString Method string ToString() # ... PS> $notepad.company # Microsoft Corporation .bashrc on PowerShell Also found out that PowerShell has a startup script like Bash does; that's amazing. It means you can store not just environment variables \"globally\" but also functions and aliases like with Bash. PS> $profile # C:\\Users\\marcus\\Documents\\WindowsPowerShell\\Microsoft.PowerShell_profile.ps1 PS> echo 'set-alias -name eco -value echo' >> $profile Run with double-click Normally, .ps1 scripts, unlike .bat , open with notepad. Here's how you can change that. This time you do need to be admin, unless there's another variable for the local user? PS> reg add \"HKEY_CLASSES_ROOT\\Microsoft.PowerShellScript.1\\Shell\\Open\\Command\" /d \"\\ `\" C:\\Windows\\System32\\WindowsPowerShell\\v1.0\\powershell.exe\\ `\" -noLogo -ExecutionPolicy unrestricted -file \\ `\" %1\\ `\" \" # Value exists, overwrite(Yes/No)? yes # The operation completed successfully. The interesting bit being ExecutionPolicy unrestricted . Running PS scripts are not allowed per default on Windows. You can either allow it per invokation like this, or globally like this: Set-ExecutionPolicy unrestricted -scope CurrentUser Commands to variables Like Bash, the result of a command can be passed to a variable. PS> $cd = \" $(pwd) \" This example is particularly important, as $(pwd) in Bash returns a string (Bash doesn't have types) whereas in PS it returns an object. Wrapping it in \" is akin to str() in that it converts the object to its string representation. $ mkdir temp $ cd \" $(pwd) \\temp\" The cool thing about an object is that it's got properties and methods. :) PS> $(pwd) | Get-Member # # TypeName: System.Management.Automation.PathInfo # # Name MemberType Definition # ---- ---------- ---------- # Equals Method bool Equals(System.Object obj) # GetHashCode Method int GetHashCode() # GetType Method type GetType() # ToString Method string ToString() # Drive Property System.Management.Automation.PSDriveInfo Drive {get;} # Path Property string Path {get;} # Provider Property System.Management.Automation.ProviderInfo Provider {get;} # ProviderPath Property string ProviderPath {get;} Undo/Redo Yes, ctrl+z/ctrl+y works on the command-line, similar to a text-editor. Ctrl+Space You can list commands from a partial entry with ctrl+space. Send to Clipboard PS> get-process | clip And ctrl+v to paste. Navigate registry and environment like files Apparently, PS doesn't distinguish between what is a filesystem and what is an environment or registry, each referred to as a \"drive\". PS> cd c : PS> cd hkcu : PS> cd env : PS> pwd Path ---- Env : \\ PS> Get-PSDrive Name Used (GB) Free (GB) Provider Root ---- --------- --------- -------- ---- Alias Alias C 460.97 13.79 FileSystem C : \\ Cert Certificate \\ Env Environment Function Function HKCU Registry HKEY_CURRENT_USER HKLM Registry HKEY_LOCAL_MACHINE Variable Variable WSMan WSMan Get startup environment from running process PS> $maya = get-process -name maya PS> $si = $maya.startupinfo PS> $si.environment[ \"PATH\" ] C : \\Program Files\\Docker\\Docker\\Resources\\bin;C : \\WINDOWS\\system32;C : \\WINDOWS;C : \\WINDOWS\\System32\\Wbem;C : \\WINDOWS\\System32\\WindowsPowerShell\\v1.0\\;C : \\Program Files\\Git\\cmd;C : \\Program Files\\Git\\mingw64\\bin;C : \\Program Files\\Git\\usr\\bin;C : \\WINDOWS\\System32\\OpenSSH\\ cmd Things to be aware of when using Rez with cmd . Long Environment Variables cmd.exe is both familiar and available on every Windows machine dating back to Windows 95. It does however suffer from one major limitation; environment variables are limited in length to 2,000 characters . It isn't quite as simple as that, as there is a limit in the Windows API, another limit in conhost.exe and yet another in cmd.exe . When using Rez with cmd.exe , it is this limit you must take into consideration, and it is the most limiting of them all. History A normal Rez context generates a deep process hierarchy . Under normal circumstances, Rez is made available as rez.exe , generated by pip install into a virtual environment. This executable calls another executable python.exe from that same install Which in turn calls the parent Python process from which your virtual environment was made, e.g. c:\\python37\\python.exe From here, Rez instantiates your REZ_DEFAULT_SHELL , e.g. cmd That's 4 layers of processes, one calling the next. It just so happens that 4 is the default number of buffers the windows ConHost.exe is configured to keep track of, which means that when you launch a 5 th layer you lose history. To account for this, configure your shell to keep track of 5 or more buffers. Alias The use of alias() in packages with cmd.exe has a few quicks worth considering. Utilises doskey , which works similar to alias on Linux Does not work with rez env -- arbitrary command Does not carry across shell, e.g. start Does not respect cmd.exe scope, e.g. cmd /Q /K doskey python=c:\\python27\\python.exe $* affects parent too bash The default shell on Linux and MacOS. Aliases are created as function()","title":"Shells"},{"location":"shells/#powershell","text":"On Windows, you'll likely want to use PowerShell. Note that \"Windows Powershell\" is different from PowerShell 6 and above which is cross-platform but not yet supported by Rez. Aliases are created as function () Resources Scoop Package Manager Why PowerShell Getting Started PowerShell Masterclass","title":"PowerShell"},{"location":"shells/#process-management","text":"PowerShell, like Python, works with objects rather than text like cmd and bash . PS> $fx = get-process -name firefox PS> $fx.path # C:\\Program Files\\Mozilla Firefox\\firefox.exe PS> $fx.workingset / 1mb # 414.23828125 PS> $fx.kill()","title":"Process Management"},{"location":"shells/#aliases","text":"PS> ls # # Directory: C:\\Users\\marcus\\.ssh # # Mode LastWriteTime Length Name # ---- ------------- ------ ---- # -a---- 11/02/2018 15:52 1766 id_rsa # -a---- 18/02/2018 11:30 1486 id_rsa.ppk # -a---- 11/02/2018 15:52 392 id_rsa.pub # -a---- 18/03/2019 08:05 3514 known_hosts PS> get-alias clear # CommandType Name Version Source # ----------- ---- ------- ------ # Alias cls -> Clear-Host","title":"Aliases"},{"location":"shells/#working-with-processes","text":"Get-Member is akin to Python's dir() . PS> $notepad = start-process notepad -passthru PS> $notepad | get-member # TypeName: System.Diagnostics.Process # # Name MemberType Definition # ---- ---------- ---------- # ... # Name AliasProperty Name = ProcessName # Company ScriptProperty System.Object Company # {get=$this.Mainmodule.FileVersionInfo.CompanyName;} # ... # Path ScriptProperty System.Object Path {get=$this.Mainmodule.FileName;} # WorkingSet Property int WorkingSet {get;} # Kill Method void Kill() # Refresh Method void Refresh() # Start Method bool Start() # ToString Method string ToString() # ... PS> $notepad.company # Microsoft Corporation","title":"Working with processes"},{"location":"shells/#bashrc-on-powershell","text":"Also found out that PowerShell has a startup script like Bash does; that's amazing. It means you can store not just environment variables \"globally\" but also functions and aliases like with Bash. PS> $profile # C:\\Users\\marcus\\Documents\\WindowsPowerShell\\Microsoft.PowerShell_profile.ps1 PS> echo 'set-alias -name eco -value echo' >> $profile","title":".bashrc on PowerShell"},{"location":"shells/#run-with-double-click","text":"Normally, .ps1 scripts, unlike .bat , open with notepad. Here's how you can change that. This time you do need to be admin, unless there's another variable for the local user? PS> reg add \"HKEY_CLASSES_ROOT\\Microsoft.PowerShellScript.1\\Shell\\Open\\Command\" /d \"\\ `\" C:\\Windows\\System32\\WindowsPowerShell\\v1.0\\powershell.exe\\ `\" -noLogo -ExecutionPolicy unrestricted -file \\ `\" %1\\ `\" \" # Value exists, overwrite(Yes/No)? yes # The operation completed successfully. The interesting bit being ExecutionPolicy unrestricted . Running PS scripts are not allowed per default on Windows. You can either allow it per invokation like this, or globally like this: Set-ExecutionPolicy unrestricted -scope CurrentUser","title":"Run with double-click"},{"location":"shells/#commands-to-variables","text":"Like Bash, the result of a command can be passed to a variable. PS> $cd = \" $(pwd) \" This example is particularly important, as $(pwd) in Bash returns a string (Bash doesn't have types) whereas in PS it returns an object. Wrapping it in \" is akin to str() in that it converts the object to its string representation. $ mkdir temp $ cd \" $(pwd) \\temp\" The cool thing about an object is that it's got properties and methods. :) PS> $(pwd) | Get-Member # # TypeName: System.Management.Automation.PathInfo # # Name MemberType Definition # ---- ---------- ---------- # Equals Method bool Equals(System.Object obj) # GetHashCode Method int GetHashCode() # GetType Method type GetType() # ToString Method string ToString() # Drive Property System.Management.Automation.PSDriveInfo Drive {get;} # Path Property string Path {get;} # Provider Property System.Management.Automation.ProviderInfo Provider {get;} # ProviderPath Property string ProviderPath {get;}","title":"Commands to variables"},{"location":"shells/#undoredo","text":"Yes, ctrl+z/ctrl+y works on the command-line, similar to a text-editor.","title":"Undo/Redo"},{"location":"shells/#ctrlspace","text":"You can list commands from a partial entry with ctrl+space.","title":"Ctrl+Space"},{"location":"shells/#send-to-clipboard","text":"PS> get-process | clip And ctrl+v to paste.","title":"Send to Clipboard"},{"location":"shells/#navigate-registry-and-environment-like-files","text":"Apparently, PS doesn't distinguish between what is a filesystem and what is an environment or registry, each referred to as a \"drive\". PS> cd c : PS> cd hkcu : PS> cd env : PS> pwd Path ---- Env : \\ PS> Get-PSDrive Name Used (GB) Free (GB) Provider Root ---- --------- --------- -------- ---- Alias Alias C 460.97 13.79 FileSystem C : \\ Cert Certificate \\ Env Environment Function Function HKCU Registry HKEY_CURRENT_USER HKLM Registry HKEY_LOCAL_MACHINE Variable Variable WSMan WSMan","title":"Navigate registry and environment like files"},{"location":"shells/#get-startup-environment-from-running-process","text":"PS> $maya = get-process -name maya PS> $si = $maya.startupinfo PS> $si.environment[ \"PATH\" ] C : \\Program Files\\Docker\\Docker\\Resources\\bin;C : \\WINDOWS\\system32;C : \\WINDOWS;C : \\WINDOWS\\System32\\Wbem;C : \\WINDOWS\\System32\\WindowsPowerShell\\v1.0\\;C : \\Program Files\\Git\\cmd;C : \\Program Files\\Git\\mingw64\\bin;C : \\Program Files\\Git\\usr\\bin;C : \\WINDOWS\\System32\\OpenSSH\\","title":"Get startup environment from running process"},{"location":"shells/#cmd","text":"Things to be aware of when using Rez with cmd .","title":"cmd"},{"location":"shells/#long-environment-variables","text":"cmd.exe is both familiar and available on every Windows machine dating back to Windows 95. It does however suffer from one major limitation; environment variables are limited in length to 2,000 characters . It isn't quite as simple as that, as there is a limit in the Windows API, another limit in conhost.exe and yet another in cmd.exe . When using Rez with cmd.exe , it is this limit you must take into consideration, and it is the most limiting of them all.","title":"Long Environment Variables"},{"location":"shells/#history","text":"A normal Rez context generates a deep process hierarchy . Under normal circumstances, Rez is made available as rez.exe , generated by pip install into a virtual environment. This executable calls another executable python.exe from that same install Which in turn calls the parent Python process from which your virtual environment was made, e.g. c:\\python37\\python.exe From here, Rez instantiates your REZ_DEFAULT_SHELL , e.g. cmd That's 4 layers of processes, one calling the next. It just so happens that 4 is the default number of buffers the windows ConHost.exe is configured to keep track of, which means that when you launch a 5 th layer you lose history. To account for this, configure your shell to keep track of 5 or more buffers.","title":"History"},{"location":"shells/#alias","text":"The use of alias() in packages with cmd.exe has a few quicks worth considering. Utilises doskey , which works similar to alias on Linux Does not work with rez env -- arbitrary command Does not carry across shell, e.g. start Does not respect cmd.exe scope, e.g. cmd /Q /K doskey python=c:\\python27\\python.exe $* affects parent too","title":"Alias"},{"location":"shells/#bash","text":"The default shell on Linux and MacOS. Aliases are created as function()","title":"bash"},{"location":"windows/","text":"Both Allzpark and Rez are cross-platform, but each platform has a few gotchas to keep in mind. Here's a quick primer on how to make the most out of Allzpark and Rez on the Windows operating system. Long File Paths Windows has a max path length of 260 characters, which can become an issue for packages on a long repository path and multiple variants. Problem # Repository root \\\\ mylongstudioaddress.local \\m ain \\c ommon \\u tilities \\p ackages \\i nternal # Package \\m aya_essentials \\1 .42.5beta \\p latform-windows \\a rch-AMD64 \\o s-windows-10.0.1803 # Payload \\p ython \\m aya_essentials \\u tilities \\_ _init__.py 188 characters That's a relatively common path to a Python package, packaged with Rez, and we're already close to the 260 character limit. Now take backslashes into account, and that Python and friends escape those prior to using them. There are 16 backslashes in there, which adds another 16 characters. # Before \\l ong \\p ath # After \\\\ long \\\\ path 204 characters We still haven't changed the path, and yet the length has increased. Now take into account some libraries taking extra precautions and escapes even estaped backslashes. # Before \\\\ long \\\\ path # After \\\\\\\\ long \\\\\\\\ path That adds yet another 32 characters. 236 characters And again, we haven't changed our path, and yet this is what some tools will be working with, leaving you with very little room. Solution You've got at least three options here. Patch your paths Patch Rez Patch Windows Patch Paths The most straightforward, but likely difficult, thing to do is to avoid long paths altogether. Use a short hostname Use a short repository path Abbreviate Python libraries Don't use Python packages from PyPI with long names But a lot of this is not practical, and merely postpones the issue. Patch Rez I've investigated what it would take to make changes to Rez that facilitate longer paths, and found that there is a prefix you can use for paths that will \"force\" Windows to interpret paths longer than 260 characters. # Before c: \\l ong \\p ath.exe # After \\\\ ? \\c : \\l ong \\p ath.exe Since paths are entirely managed by Rez, it wouldn't be unreasonable to wrap any path creation call to prefix the results with \\\\?\\ if the user was running Windows. But I couldn't find a single-point-of-entry for these, as paths were generated all over the place. Rightly so; it would be borderline overengineering to wrap all calls to e.g. os.path.join or os.getcwd into a \"prefixer\" just for this occasion. It would however have helped in this particular case. Furthermore, this would only really apply to Windows 10 and above, since from what I gather this (poorly documented) feature is only available there; possibly related to this next feature. Patch Windows You wouldn't think this is an option, but it just might be. This technically doesn't count as patching Windows, but because we're changing a fundamental component of the OS - something each applications has till now taken for granted - it may cause all sorts of havok for applications that depend on the 260 character limit. Relevant comic https://xkcd.com/1172/ Since June 20 th 2017, users of Windows 10 1607 have had the ability to enable support for \"long paths\". # From an administrator PowerShell session Set-ItemProperty -Path HKLM : \\SYSTEM\\CurrentControlSet\\Control\\FileSystem -Name LongPathsEnabled -Value 1 -Type DWord This would effectively prepend \\\\?\\ to every path \"under the hood\", solving the issue. But at what cost? Let the community know if you encounter any issues by making an issue . Long Environment Variables See Shells for things to keep an eye on with regards to environment variables. To work around this issue, it is recommended that you use PowerShell on Windows. Environment variable REZ_DEFAULT_SHELL=powershell rezconfig.py default_shell = \"powershell\" Advanced Why does the cmd.exe limit apply? It's because whenever you execute_shell or enter into a context using rez env , Rez is creating a .bat script with a series of commands that look like this. set PATH = c: \\s ome \\p ath ; %PATH% set PATH = c: \\s ome \\o ther \\p ath ; %PATH% set PATH = c: \\y et \\a nother \\p ath ; %PATH% ... With one line of set for every call to env from within your package.py:commands() function. And this is where the problem lies, for you see launching cmd with a environment containing values longer than 2,000 characters work fine. import subprocess subprocess . Popen( \"cmd\" , env = { \"a\" : \"really\" , \"long\" : \"environment\" }) # Works But cmd.exe itself has issues handling anything longer than 2,000 characters which is why one of those lines of set will eventually stop growing. Platform map You'll want to use a brutal platform_map for your Windows setup, because of stunts like this. Machine A $ C: \\U sers \\m arcus \\D esktop>systeminfo | findstr /B /C: \"OS Name\" /C: \"OS Version\" OS Name: Microsoft Windows 10 Pro OS Version: 10 .0.17134 N/A Build 17134 $ python >>> import platform >>> platform.platform () 'Windows-8-6.2.9200' >>> from rez.utils.platform_ import platform_ >>> platform_.os 'windows-6.2.9200' Machine B $ C: \\U sers \\m arcus \\D esktop>systeminfo | findstr /B /C: \"OS Name\" /C: \"OS Version\" OS Name: Microsoft Windows 10 Pro OS Version: 10 .0.18362 N/A Build 18362 $ python >>> import platform >>> platform.platform () 'Windows-10-10.0.18362' >>> from rez.utils.platform_ import platform_ >>> platform_.os 'windows-10.0.18362.SP0' rezconfig.py For a platform_map , try this. It'll make any modern version of Windows (8-10) look like Windows 10. platform_map = { \"os\" : { r\"windows-6(.*)\" : r\"windows-10\" , r\"windows-10(.*)\" : r\"windows-10\" , }, } This then applies to rez env and friends whenever the implict ~os package is requested. Sadly, this has to happen early in your package repository authoring days, as variants being created also use this value. If a variant has been created using os-windows-10.0.1803 then that value will have been made into a physical folder on disk that cannot (or should not) change. If the implicit request is then changed to os-windows-10 , then none of your existing packages with this variants will work. Related issue Process Tree Virtualenv is one way of using Rez on Windows, and if you do then the rez.exe executable is generated during pip install and works by spawning a python.exe process, also generated by pip , which in turn calls on your system python.exe . Here's what spawning your own Python session from within a Rez context looks like. Maya and Quicktime Typically, playblasting to .mp4 or .mov with Maya requires a recent install of Quicktime on the local machine. Let's have a look at how to approach this with Rez. How does one approach this with Rez? Submit a PR today!","title":"Windows"},{"location":"windows/#long-file-paths","text":"Windows has a max path length of 260 characters, which can become an issue for packages on a long repository path and multiple variants.","title":"Long File Paths"},{"location":"windows/#problem","text":"# Repository root \\\\ mylongstudioaddress.local \\m ain \\c ommon \\u tilities \\p ackages \\i nternal # Package \\m aya_essentials \\1 .42.5beta \\p latform-windows \\a rch-AMD64 \\o s-windows-10.0.1803 # Payload \\p ython \\m aya_essentials \\u tilities \\_ _init__.py 188 characters That's a relatively common path to a Python package, packaged with Rez, and we're already close to the 260 character limit. Now take backslashes into account, and that Python and friends escape those prior to using them. There are 16 backslashes in there, which adds another 16 characters. # Before \\l ong \\p ath # After \\\\ long \\\\ path 204 characters We still haven't changed the path, and yet the length has increased. Now take into account some libraries taking extra precautions and escapes even estaped backslashes. # Before \\\\ long \\\\ path # After \\\\\\\\ long \\\\\\\\ path That adds yet another 32 characters. 236 characters And again, we haven't changed our path, and yet this is what some tools will be working with, leaving you with very little room.","title":"Problem"},{"location":"windows/#solution","text":"You've got at least three options here. Patch your paths Patch Rez Patch Windows Patch Paths The most straightforward, but likely difficult, thing to do is to avoid long paths altogether. Use a short hostname Use a short repository path Abbreviate Python libraries Don't use Python packages from PyPI with long names But a lot of this is not practical, and merely postpones the issue. Patch Rez I've investigated what it would take to make changes to Rez that facilitate longer paths, and found that there is a prefix you can use for paths that will \"force\" Windows to interpret paths longer than 260 characters. # Before c: \\l ong \\p ath.exe # After \\\\ ? \\c : \\l ong \\p ath.exe Since paths are entirely managed by Rez, it wouldn't be unreasonable to wrap any path creation call to prefix the results with \\\\?\\ if the user was running Windows. But I couldn't find a single-point-of-entry for these, as paths were generated all over the place. Rightly so; it would be borderline overengineering to wrap all calls to e.g. os.path.join or os.getcwd into a \"prefixer\" just for this occasion. It would however have helped in this particular case. Furthermore, this would only really apply to Windows 10 and above, since from what I gather this (poorly documented) feature is only available there; possibly related to this next feature. Patch Windows You wouldn't think this is an option, but it just might be. This technically doesn't count as patching Windows, but because we're changing a fundamental component of the OS - something each applications has till now taken for granted - it may cause all sorts of havok for applications that depend on the 260 character limit. Relevant comic https://xkcd.com/1172/ Since June 20 th 2017, users of Windows 10 1607 have had the ability to enable support for \"long paths\". # From an administrator PowerShell session Set-ItemProperty -Path HKLM : \\SYSTEM\\CurrentControlSet\\Control\\FileSystem -Name LongPathsEnabled -Value 1 -Type DWord This would effectively prepend \\\\?\\ to every path \"under the hood\", solving the issue. But at what cost? Let the community know if you encounter any issues by making an issue .","title":"Solution"},{"location":"windows/#long-environment-variables","text":"See Shells for things to keep an eye on with regards to environment variables. To work around this issue, it is recommended that you use PowerShell on Windows. Environment variable REZ_DEFAULT_SHELL=powershell rezconfig.py default_shell = \"powershell\"","title":"Long Environment Variables"},{"location":"windows/#advanced","text":"Why does the cmd.exe limit apply? It's because whenever you execute_shell or enter into a context using rez env , Rez is creating a .bat script with a series of commands that look like this. set PATH = c: \\s ome \\p ath ; %PATH% set PATH = c: \\s ome \\o ther \\p ath ; %PATH% set PATH = c: \\y et \\a nother \\p ath ; %PATH% ... With one line of set for every call to env from within your package.py:commands() function. And this is where the problem lies, for you see launching cmd with a environment containing values longer than 2,000 characters work fine. import subprocess subprocess . Popen( \"cmd\" , env = { \"a\" : \"really\" , \"long\" : \"environment\" }) # Works But cmd.exe itself has issues handling anything longer than 2,000 characters which is why one of those lines of set will eventually stop growing.","title":"Advanced"},{"location":"windows/#platform-map","text":"You'll want to use a brutal platform_map for your Windows setup, because of stunts like this. Machine A $ C: \\U sers \\m arcus \\D esktop>systeminfo | findstr /B /C: \"OS Name\" /C: \"OS Version\" OS Name: Microsoft Windows 10 Pro OS Version: 10 .0.17134 N/A Build 17134 $ python >>> import platform >>> platform.platform () 'Windows-8-6.2.9200' >>> from rez.utils.platform_ import platform_ >>> platform_.os 'windows-6.2.9200' Machine B $ C: \\U sers \\m arcus \\D esktop>systeminfo | findstr /B /C: \"OS Name\" /C: \"OS Version\" OS Name: Microsoft Windows 10 Pro OS Version: 10 .0.18362 N/A Build 18362 $ python >>> import platform >>> platform.platform () 'Windows-10-10.0.18362' >>> from rez.utils.platform_ import platform_ >>> platform_.os 'windows-10.0.18362.SP0' rezconfig.py For a platform_map , try this. It'll make any modern version of Windows (8-10) look like Windows 10. platform_map = { \"os\" : { r\"windows-6(.*)\" : r\"windows-10\" , r\"windows-10(.*)\" : r\"windows-10\" , }, } This then applies to rez env and friends whenever the implict ~os package is requested. Sadly, this has to happen early in your package repository authoring days, as variants being created also use this value. If a variant has been created using os-windows-10.0.1803 then that value will have been made into a physical folder on disk that cannot (or should not) change. If the implicit request is then changed to os-windows-10 , then none of your existing packages with this variants will work. Related issue","title":"Platform map"},{"location":"windows/#process-tree","text":"Virtualenv is one way of using Rez on Windows, and if you do then the rez.exe executable is generated during pip install and works by spawning a python.exe process, also generated by pip , which in turn calls on your system python.exe . Here's what spawning your own Python session from within a Rez context looks like.","title":"Process Tree"},{"location":"windows/#maya-and-quicktime","text":"Typically, playblasting to .mp4 or .mov with Maya requires a recent install of Quicktime on the local machine. Let's have a look at how to approach this with Rez. How does one approach this with Rez? Submit a PR today!","title":"Maya and Quicktime"}]}